09:38:15.149 [][][Slf4jLogger] INFO  Slf4jLogger started
09:38:15.175 [ScalaTest-running-SettingsParserSpec][EventStream(akka://deepdive)][EventStream] DEBUG logger log1-Slf4jLogger started
09:38:15.177 [ScalaTest-running-SettingsParserSpec][EventStream(akka://deepdive)][EventStream] DEBUG Default Loggers started
09:38:15.178 [ScalaTest-running-SettingsParserSpec][SettingsParser$(akka://deepdive)][SettingsParser$] DEBUG samplerArgs: -i 1000
09:38:15.182 [ScalaTest-running-SettingsParserSpec][SettingsParser$(akka://deepdive)][SettingsParser$] INFO  Detected OS: Mac OS X
09:38:15.182 [ScalaTest-running-SettingsParserSpec][SettingsParser$(akka://deepdive)][SettingsParser$] DEBUG samplerArgs: -l 500 -i 500 -s 1 --alpha 0.1 --diminish 0.99 --quiet
09:38:15.258 [][][Slf4jLogger] INFO  Slf4jLogger started
09:38:15.259 [pool-4-thread-6][EventStream(akka://SamplerSpec)][EventStream] DEBUG logger log1-Slf4jLogger started
09:38:15.259 [pool-4-thread-6][EventStream(akka://SamplerSpec)][EventStream] DEBUG Default Loggers started
09:38:15.298 [][][Slf4jLogger] INFO  Slf4jLogger started
09:38:15.299 [pool-4-thread-6][EventStream(akka://ExtractionManagerSpec)][EventStream] DEBUG logger log1-Slf4jLogger started
09:38:15.299 [pool-4-thread-6][EventStream(akka://ExtractionManagerSpec)][EventStream] DEBUG Default Loggers started
09:38:15.350 [ScalaTest-running-ExtractionManagerSpec][akka://ExtractionManagerSpec/user/$$a][ExtractionManagerSpec$MemoryExtractionManager] INFO  starting
09:38:15.352 [ScalaTest-running-ExtractionManagerSpec][akka://ExtractionManagerSpec/user/$$a][ExtractionManagerSpec$MemoryExtractionManager] INFO  Adding task_name=e1
09:38:15.353 [ScalaTest-running-ExtractionManagerSpec][akka://ExtractionManagerSpec/user/$$a][ExtractionManagerSpec$MemoryExtractionManager] INFO  executing extractorName=e1
09:38:15.478 [ScalaTest-running-ExtractionManagerSpec][akka://ExtractionManagerSpec/user/$$b][ExtractionManagerSpec$MemoryExtractionManager] INFO  starting
09:38:15.479 [ScalaTest-running-ExtractionManagerSpec][akka://ExtractionManagerSpec/user/$$b][ExtractionManagerSpec$MemoryExtractionManager] INFO  Adding task_name=e1
09:38:15.479 [ScalaTest-running-ExtractionManagerSpec][akka://ExtractionManagerSpec/user/$$b][ExtractionManagerSpec$MemoryExtractionManager] INFO  executing extractorName=e1
09:38:15.479 [ScalaTest-running-ExtractionManagerSpec][akka://ExtractionManagerSpec/user/$$b][ExtractionManagerSpec$MemoryExtractionManager] INFO  Adding task_name=e2
09:38:15.485 [ScalaTest-running-ExtractionManagerSpec][akka://ExtractionManagerSpec/user/$$b][ExtractionManagerSpec$MemoryExtractionManager] INFO  Adding task_name=e3
09:38:15.582 [ExtractionManagerSpec-akka.actor.default-dispatcher-4][akka://ExtractionManagerSpec/user/$$b][ExtractionManagerSpec$MemoryExtractionManager] INFO  executing extractorName=e3
09:38:15.683 [ExtractionManagerSpec-akka.actor.default-dispatcher-2][akka://ExtractionManagerSpec/user/$$b][ExtractionManagerSpec$MemoryExtractionManager] INFO  executing extractorName=e2
09:38:15.785 [ScalaTest-running-ExtractionManagerSpec][akka://ExtractionManagerSpec/user/$$c][ExtractionManagerSpec$MemoryExtractionManager] INFO  starting
09:38:15.786 [ScalaTest-running-ExtractionManagerSpec][akka://ExtractionManagerSpec/user/$$c][ExtractionManagerSpec$MemoryExtractionManager] INFO  Adding task_name=e1
09:38:15.786 [ScalaTest-running-ExtractionManagerSpec][akka://ExtractionManagerSpec/user/$$c][ExtractionManagerSpec$MemoryExtractionManager] INFO  executing extractorName=e1
09:38:15.786 [ScalaTest-running-ExtractionManagerSpec][akka://ExtractionManagerSpec/user/$$c][ExtractionManagerSpec$MemoryExtractionManager] INFO  Adding task_name=e2
09:38:15.787 [ScalaTest-running-ExtractionManagerSpec][akka://ExtractionManagerSpec/user/$$c][ExtractionManagerSpec$MemoryExtractionManager] INFO  executing extractorName=e2
09:38:15.787 [ScalaTest-running-ExtractionManagerSpec][akka://ExtractionManagerSpec/user/$$c][ExtractionManagerSpec$MemoryExtractionManager] INFO  Adding task_name=e3
09:38:15.787 [ScalaTest-running-ExtractionManagerSpec][akka://ExtractionManagerSpec/user/$$c][ExtractionManagerSpec$MemoryExtractionManager] INFO  executing extractorName=e3
09:38:16.104 [ScalaTest-running-PostgresInferenceDataStoreSpec][JdbcDataStore$(akka://deepdive)][JdbcDataStore$] INFO  Intializing all JDBC data stores
09:38:16.437 [ScalaTest-running-PostgresInferenceDataStoreSpec][JdbcDataStore$(akka://deepdive)][JdbcDataStore$] INFO  Closing all JDBC data stores
09:38:16.439 [ScalaTest-running-PostgresInferenceDataStoreSpec][JdbcDataStore$(akka://deepdive)][JdbcDataStore$] INFO  Intializing all JDBC data stores
09:38:16.736 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing SQL with callback... 
    SELECT version() LIKE '%Greenplum%';
  
09:38:16.739 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP SEQUENCE IF EXISTS dd_variable_sequence CASCADE
09:38:16.741 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE SEQUENCE dd_variable_sequence MINVALUE -1 START 0
09:38:16.744 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: UPDATE t1 SET id =  nextval('dd_variable_sequence')
09:38:16.745 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: UPDATE t2 SET id =  nextval('dd_variable_sequence')
09:38:16.745 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: UPDATE t3 SET id =  nextval('dd_variable_sequence')
09:38:16.781 [ScalaTest-running-PostgresInferenceDataStoreSpec][JdbcDataStore$(akka://deepdive)][JdbcDataStore$] INFO  Closing all JDBC data stores
09:38:16.781 [ScalaTest-running-PostgresInferenceDataStoreSpec][JdbcDataStore$(akka://deepdive)][JdbcDataStore$] INFO  Intializing all JDBC data stores
09:38:16.925 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing SQL with callback... 
    SELECT version() LIKE '%Greenplum%';
  
09:38:16.926 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  Using Greenplum = false
09:38:16.926 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  Datastore type = psql
09:38:16.926 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  Parallel grounding = false
09:38:16.927 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] DEBUG Grounding Path = /Users/jackywang/Desktop/341/project/deepdive/out
09:38:16.927 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing SQL with callback... 
    SELECT version() LIKE '%Greenplum%';
  
09:38:16.927 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP SEQUENCE IF EXISTS dd_variable_sequence CASCADE
09:38:16.927 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE SEQUENCE dd_variable_sequence MINVALUE -1 START 0
09:38:16.929 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: UPDATE r1 SET id =  nextval('dd_variable_sequence')
09:38:16.931 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_graph_variables_holdout CASCADE
09:38:16.932 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_graph_variables_holdout(variable_id bigint primary key)
09:38:16.934 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_graph_variables_observation CASCADE
09:38:16.935 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_graph_variables_observation(variable_id bigint primary key)
09:38:16.938 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: INSERT INTO dd_graph_variables_holdout
            SELECT id FROM r1
            WHERE RANDOM() < 0.0 AND is_correct IS NOT NULL
09:38:16.940 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS r1_is_correct_cardinality CASCADE
09:38:16.940 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE r1_is_correct_cardinality(cardinality text)
09:38:16.942 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: INSERT INTO r1_is_correct_cardinality VALUES ('00001')
09:38:16.943 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS r1_vtype CASCADE
09:38:16.944 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE r1_vtype AS
        SELECT t0.id, CASE WHEN t2.variable_id IS NOT NULL AND is_correct IS NOT NULL THEN 2
                           WHEN t1.variable_id IS NOT NULL THEN 0
                           WHEN is_correct IS NOT NULL THEN 1
                           ELSE 0
                      END as __dd_variable_type__
        FROM r1 t0 LEFT OUTER JOIN dd_graph_variables_holdout t1 
        ON t0.id=t1.variable_id LEFT OUTER JOIN dd_graph_variables_observation t2 ON t0.id=t2.variable_id
09:38:16.950 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] DEBUG Executing queries by file: psql  -d deepdive_test  -U jackywang  -p 5432  -h localhost  -c 'COPY (SELECT t0.id, t1.__dd_variable_type__,
        CASE WHEN t1.__dd_variable_type__ = 0 THEN 0 ELSE is_correct::int::float END AS initvalue,
        0 AS type, 2 AS cardinality
        FROM r1 t0, r1_vtype t1
        WHERE t0.id=t1.id) TO STDOUT;'   > /Users/jackywang/Desktop/341/project/deepdive/out/dd_variables_r1
09:38:16.950 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/exec_sql9086158246872682990.sh" 
09:38:17.019 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_graph_factormeta CASCADE
09:38:17.019 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_graph_factormeta (name text, funcid int, sign text)
09:38:17.023 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: INSERT INTO dd_graph_factormeta VALUES ('testFactor', 4, 'true')
09:38:17.024 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] DEBUG Executing queries by file: psql  -d deepdive_test  -U jackywang  -p 5432  -h localhost  -c 'COPY (SELECT * FROM dd_graph_factormeta) TO STDOUT;'   > /Users/jackywang/Desktop/341/project/deepdive/out/dd_factormeta
09:38:17.024 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/exec_sql5902810163985466328.sh" 
09:38:17.056 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_graph_weights CASCADE
09:38:17.056 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_graph_weights (id bigint, isfixed int, initvalue real, 
      cardinality text, description text)
09:38:17.059 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP SEQUENCE IF EXISTS dd_weight_sequence CASCADE
09:38:17.059 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE SEQUENCE dd_weight_sequence MINVALUE -1 START 0
09:38:17.061 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP SEQUENCE IF EXISTS dd_factor_sequence CASCADE
09:38:17.062 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE SEQUENCE dd_factor_sequence MINVALUE -1 START 0
09:38:17.063 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_feature_statistics_support CASCADE
09:38:17.063 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_feature_statistics_support(
            description text, 
            pos_examples bigint, 
            neg_examples bigint, 
            queries bigint)
09:38:17.068 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_query_testFactor CASCADE
09:38:17.068 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_query_testFactor AS SELECT id AS "r1.id", is_correct AS "r1.is_correct" FROM r1
09:38:17.071 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: ALTER TABLE dd_query_testFactor ADD COLUMN id bigint
09:38:17.072 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: UPDATE dd_query_testFactor SET id =  nextval('dd_factor_sequence')
09:38:17.075 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing SQL with callback... SELECT COUNT(*) FROM dd_query_testFactor;
09:38:17.078 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_weights_testFactor CASCADE
09:38:17.078 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_weights_testFactor AS
              SELECT true::int AS isfixed, 0.37::float AS initvalue, 
                0::bigint AS id
09:38:17.080 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: UPDATE dd_weights_testFactor SET id =  nextval('dd_weight_sequence')
09:38:17.083 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing SQL with callback... SELECT COUNT(*) FROM dd_weights_testFactor;
09:38:17.084 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: INSERT INTO dd_graph_weights(id, isfixed, initvalue, description) 
            SELECT id, isfixed, initvalue, 'weight_prefix-'  FROM dd_weights_testFactor
09:38:17.086 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] DEBUG Executing queries by file: psql  -d deepdive_test  -U jackywang  -p 5432  -h localhost  -c 'COPY (SELECT t0.id AS factor_id, t1.id AS weight_id,  "r1.id"
             FROM dd_query_testFactor t0, dd_weights_testFactor t1) TO STDOUT;'   > /Users/jackywang/Desktop/341/project/deepdive/out/dd_factors_testFactor_out
09:38:17.086 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/exec_sql8669525401972347548.sh" 
09:38:17.119 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: INSERT INTO dd_feature_statistics_support
        SELECT 'weight_prefix-'  as description,
               count(CASE WHEN  "r1.is_correct" =TRUE THEN 1 ELSE NULL END) AS pos_examples,
               count(CASE WHEN  "r1.is_correct" =FALSE THEN 1 ELSE NULL END) AS neg_examples,
               count(CASE WHEN  "r1.is_correct"  IS NULL THEN 1 ELSE NULL END) AS queries
        FROM dd_query_testFactor
09:38:17.120 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: ANALYZE dd_feature_statistics_support
09:38:17.122 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] DEBUG Executing queries by file: psql  -d deepdive_test  -U jackywang  -p 5432  -h localhost  -c 'COPY (SELECT id, isfixed, COALESCE(initvalue, 0) FROM dd_graph_weights) TO STDOUT;'   > /Users/jackywang/Desktop/341/project/deepdive/out/dd_weights
09:38:17.122 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/exec_sql2567453394842847366.sh" 
09:38:17.154 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_inference_result_variables CASCADE
09:38:17.155 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_inference_result_variables(
      id bigint, 
      category bigint, 
      expectation double precision)
09:38:17.156 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_inference_result_weights CASCADE
09:38:17.156 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_inference_result_weights(
      id bigint primary key, 
      weight double precision)
09:38:17.158 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  Converting grounding file format...
09:38:17.159 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] DEBUG Executing: python /Users/jackywang/Desktop/341/project/deepdive/util/tobinary.py /Users/jackywang/Desktop/341/project/deepdive/out /Users/jackywang/Desktop/341/project/deepdive/util/format_converter_mac /Users/jackywang/Desktop/341/project/deepdive/out
09:38:20.731 [Thread-15][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  SPLITTING testFactor ...
09:38:20.732 [Thread-15][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  BINARIZE  testFactor ...
09:38:20.732 [Thread-15][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  SPLITTING dd_variables_r1 ...
09:38:20.732 [Thread-15][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  BINARIZE  dd_variables_r1 ...
09:38:20.732 [Thread-15][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  BINARIZE  weights ...
09:38:20.732 [Thread-15][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  COUNTING variables ...
09:38:20.732 [Thread-15][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  COUNTING factors ...
09:38:20.732 [Thread-15][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  COUNTING weights ...
09:38:20.733 [Thread-15][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  CONCATENATING FILES...
09:38:20.733 [Thread-15][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  Cleaning up files
09:38:20.741 [ScalaTest-running-PostgresInferenceDataStoreSpec][JdbcDataStore$(akka://deepdive)][JdbcDataStore$] INFO  Closing all JDBC data stores
09:38:20.742 [ScalaTest-running-PostgresInferenceDataStoreSpec][JdbcDataStore$(akka://deepdive)][JdbcDataStore$] INFO  Intializing all JDBC data stores
09:38:20.880 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing SQL with callback... 
    SELECT version() LIKE '%Greenplum%';
  
09:38:20.881 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  Using Greenplum = false
09:38:20.881 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  Datastore type = psql
09:38:20.881 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  Parallel grounding = false
09:38:20.881 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] DEBUG Grounding Path = /Users/jackywang/Desktop/341/project/deepdive/out
09:38:20.881 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing SQL with callback... 
    SELECT version() LIKE '%Greenplum%';
  
09:38:20.881 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP SEQUENCE IF EXISTS dd_variable_sequence CASCADE
09:38:20.882 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE SEQUENCE dd_variable_sequence MINVALUE -1 START 0
09:38:20.883 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: UPDATE r1 SET id =  nextval('dd_variable_sequence')
09:38:20.885 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_graph_variables_holdout CASCADE
09:38:20.885 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_graph_variables_holdout(variable_id bigint primary key)
09:38:20.887 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_graph_variables_observation CASCADE
09:38:20.888 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_graph_variables_observation(variable_id bigint primary key)
09:38:20.890 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: INSERT INTO dd_graph_variables_holdout
            SELECT id FROM r1
            WHERE RANDOM() < 0.0 AND is_correct IS NOT NULL
09:38:20.891 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS r1_is_correct_cardinality CASCADE
09:38:20.891 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE r1_is_correct_cardinality(cardinality text)
09:38:20.893 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: INSERT INTO r1_is_correct_cardinality VALUES ('00001')
09:38:20.894 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS r1_vtype CASCADE
09:38:20.895 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE r1_vtype AS
        SELECT t0.id, CASE WHEN t2.variable_id IS NOT NULL AND is_correct IS NOT NULL THEN 2
                           WHEN t1.variable_id IS NOT NULL THEN 0
                           WHEN is_correct IS NOT NULL THEN 1
                           ELSE 0
                      END as __dd_variable_type__
        FROM r1 t0 LEFT OUTER JOIN dd_graph_variables_holdout t1 
        ON t0.id=t1.variable_id LEFT OUTER JOIN dd_graph_variables_observation t2 ON t0.id=t2.variable_id
09:38:20.901 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] DEBUG Executing queries by file: psql  -d deepdive_test  -U jackywang  -p 5432  -h localhost  -c 'COPY (SELECT t0.id, t1.__dd_variable_type__,
        CASE WHEN t1.__dd_variable_type__ = 0 THEN 0 ELSE is_correct::int::float END AS initvalue,
        0 AS type, 2 AS cardinality
        FROM r1 t0, r1_vtype t1
        WHERE t0.id=t1.id) TO STDOUT;'   > /Users/jackywang/Desktop/341/project/deepdive/out/dd_variables_r1
09:38:20.901 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/exec_sql3811296676600622982.sh" 
09:38:20.935 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_graph_factormeta CASCADE
09:38:20.935 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_graph_factormeta (name text, funcid int, sign text)
09:38:20.938 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: INSERT INTO dd_graph_factormeta VALUES ('testFactor', 4, 'true')
09:38:20.939 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] DEBUG Executing queries by file: psql  -d deepdive_test  -U jackywang  -p 5432  -h localhost  -c 'COPY (SELECT * FROM dd_graph_factormeta) TO STDOUT;'   > /Users/jackywang/Desktop/341/project/deepdive/out/dd_factormeta
09:38:20.940 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/exec_sql1939766822452836743.sh" 
09:38:20.971 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_graph_weights CASCADE
09:38:20.972 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_graph_weights (id bigint, isfixed int, initvalue real, 
      cardinality text, description text)
09:38:20.974 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP SEQUENCE IF EXISTS dd_weight_sequence CASCADE
09:38:20.974 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE SEQUENCE dd_weight_sequence MINVALUE -1 START 0
09:38:20.976 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP SEQUENCE IF EXISTS dd_factor_sequence CASCADE
09:38:20.976 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE SEQUENCE dd_factor_sequence MINVALUE -1 START 0
09:38:20.978 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_feature_statistics_support CASCADE
09:38:20.978 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_feature_statistics_support(
            description text, 
            pos_examples bigint, 
            neg_examples bigint, 
            queries bigint)
09:38:20.980 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_query_testFactor CASCADE
09:38:20.980 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_query_testFactor AS SELECT id AS "r1.id", is_correct AS "r1.is_correct" FROM r1
09:38:20.982 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: ALTER TABLE dd_query_testFactor ADD COLUMN id bigint
09:38:20.983 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: UPDATE dd_query_testFactor SET id =  nextval('dd_factor_sequence')
09:38:20.985 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing SQL with callback... SELECT COUNT(*) FROM dd_query_testFactor;
09:38:20.986 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_weights_testFactor CASCADE
09:38:20.986 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_weights_testFactor AS
              SELECT false::int AS isfixed, 0.0::float AS initvalue, 
                0::bigint AS id
09:38:20.988 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: UPDATE dd_weights_testFactor SET id =  nextval('dd_weight_sequence')
09:38:20.990 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing SQL with callback... SELECT COUNT(*) FROM dd_weights_testFactor;
09:38:20.991 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: INSERT INTO dd_graph_weights(id, isfixed, initvalue, description) 
            SELECT id, isfixed, initvalue, 'weight_prefix-'  FROM dd_weights_testFactor
09:38:20.992 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] DEBUG Executing queries by file: psql  -d deepdive_test  -U jackywang  -p 5432  -h localhost  -c 'COPY (SELECT t0.id AS factor_id, t1.id AS weight_id,  "r1.id"
             FROM dd_query_testFactor t0, dd_weights_testFactor t1) TO STDOUT;'   > /Users/jackywang/Desktop/341/project/deepdive/out/dd_factors_testFactor_out
09:38:20.993 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/exec_sql9209136123864473591.sh" 
09:38:21.026 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: INSERT INTO dd_feature_statistics_support
        SELECT 'weight_prefix-'  as description,
               count(CASE WHEN  "r1.is_correct" =TRUE THEN 1 ELSE NULL END) AS pos_examples,
               count(CASE WHEN  "r1.is_correct" =FALSE THEN 1 ELSE NULL END) AS neg_examples,
               count(CASE WHEN  "r1.is_correct"  IS NULL THEN 1 ELSE NULL END) AS queries
        FROM dd_query_testFactor
09:38:21.027 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: ANALYZE dd_feature_statistics_support
09:38:21.029 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] DEBUG Executing queries by file: psql  -d deepdive_test  -U jackywang  -p 5432  -h localhost  -c 'COPY (SELECT id, isfixed, COALESCE(initvalue, 0) FROM dd_graph_weights) TO STDOUT;'   > /Users/jackywang/Desktop/341/project/deepdive/out/dd_weights
09:38:21.029 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/exec_sql4373002380490028807.sh" 
09:38:21.062 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_inference_result_variables CASCADE
09:38:21.062 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_inference_result_variables(
      id bigint, 
      category bigint, 
      expectation double precision)
09:38:21.063 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_inference_result_weights CASCADE
09:38:21.064 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_inference_result_weights(
      id bigint primary key, 
      weight double precision)
09:38:21.065 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  Converting grounding file format...
09:38:21.066 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] DEBUG Executing: python /Users/jackywang/Desktop/341/project/deepdive/util/tobinary.py /Users/jackywang/Desktop/341/project/deepdive/out /Users/jackywang/Desktop/341/project/deepdive/util/format_converter_mac /Users/jackywang/Desktop/341/project/deepdive/out
09:38:21.335 [Thread-30][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  SPLITTING testFactor ...
09:38:21.336 [Thread-30][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  BINARIZE  testFactor ...
09:38:21.337 [Thread-30][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  SPLITTING dd_variables_r1 ...
09:38:21.337 [Thread-30][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  BINARIZE  dd_variables_r1 ...
09:38:21.337 [Thread-30][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  BINARIZE  weights ...
09:38:21.337 [Thread-30][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  COUNTING variables ...
09:38:21.337 [Thread-30][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  COUNTING factors ...
09:38:21.337 [Thread-30][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  COUNTING weights ...
09:38:21.337 [Thread-30][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  CONCATENATING FILES...
09:38:21.337 [Thread-30][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  Cleaning up files
09:38:21.344 [ScalaTest-running-PostgresInferenceDataStoreSpec][JdbcDataStore$(akka://deepdive)][JdbcDataStore$] INFO  Closing all JDBC data stores
09:38:21.345 [ScalaTest-running-PostgresInferenceDataStoreSpec][JdbcDataStore$(akka://deepdive)][JdbcDataStore$] INFO  Intializing all JDBC data stores
09:38:21.498 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing SQL with callback... 
    SELECT version() LIKE '%Greenplum%';
  
09:38:21.499 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  Using Greenplum = false
09:38:21.499 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  Datastore type = psql
09:38:21.499 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  Parallel grounding = false
09:38:21.499 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] DEBUG Grounding Path = /Users/jackywang/Desktop/341/project/deepdive/out
09:38:21.499 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing SQL with callback... 
    SELECT version() LIKE '%Greenplum%';
  
09:38:21.499 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP SEQUENCE IF EXISTS dd_variable_sequence CASCADE
09:38:21.499 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE SEQUENCE dd_variable_sequence MINVALUE -1 START 0
09:38:21.501 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: UPDATE r1 SET id =  nextval('dd_variable_sequence')
09:38:21.503 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_graph_variables_holdout CASCADE
09:38:21.503 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_graph_variables_holdout(variable_id bigint primary key)
09:38:21.505 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_graph_variables_observation CASCADE
09:38:21.506 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_graph_variables_observation(variable_id bigint primary key)
09:38:21.510 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: INSERT INTO dd_graph_variables_holdout
            SELECT id FROM r1
            WHERE RANDOM() < 0.0 AND is_correct IS NOT NULL
09:38:21.511 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS r1_is_correct_cardinality CASCADE
09:38:21.512 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE r1_is_correct_cardinality(cardinality text)
09:38:21.514 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: INSERT INTO r1_is_correct_cardinality VALUES ('00001')
09:38:21.515 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS r1_vtype CASCADE
09:38:21.515 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE r1_vtype AS
        SELECT t0.id, CASE WHEN t2.variable_id IS NOT NULL AND is_correct IS NOT NULL THEN 2
                           WHEN t1.variable_id IS NOT NULL THEN 0
                           WHEN is_correct IS NOT NULL THEN 1
                           ELSE 0
                      END as __dd_variable_type__
        FROM r1 t0 LEFT OUTER JOIN dd_graph_variables_holdout t1 
        ON t0.id=t1.variable_id LEFT OUTER JOIN dd_graph_variables_observation t2 ON t0.id=t2.variable_id
09:38:21.521 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] DEBUG Executing queries by file: psql  -d deepdive_test  -U jackywang  -p 5432  -h localhost  -c 'COPY (SELECT t0.id, t1.__dd_variable_type__,
        CASE WHEN t1.__dd_variable_type__ = 0 THEN 0 ELSE is_correct::int::float END AS initvalue,
        0 AS type, 2 AS cardinality
        FROM r1 t0, r1_vtype t1
        WHERE t0.id=t1.id) TO STDOUT;'   > /Users/jackywang/Desktop/341/project/deepdive/out/dd_variables_r1
09:38:21.522 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/exec_sql7606289010774764498.sh" 
09:38:21.555 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_graph_factormeta CASCADE
09:38:21.556 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_graph_factormeta (name text, funcid int, sign text)
09:38:21.558 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: INSERT INTO dd_graph_factormeta VALUES ('testFactor', 4, 'true')
09:38:21.559 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] DEBUG Executing queries by file: psql  -d deepdive_test  -U jackywang  -p 5432  -h localhost  -c 'COPY (SELECT * FROM dd_graph_factormeta) TO STDOUT;'   > /Users/jackywang/Desktop/341/project/deepdive/out/dd_factormeta
09:38:21.559 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/exec_sql2757107466336510125.sh" 
09:38:21.591 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_graph_weights CASCADE
09:38:21.592 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_graph_weights (id bigint, isfixed int, initvalue real, 
      cardinality text, description text)
09:38:21.594 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP SEQUENCE IF EXISTS dd_weight_sequence CASCADE
09:38:21.594 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE SEQUENCE dd_weight_sequence MINVALUE -1 START 0
09:38:21.595 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP SEQUENCE IF EXISTS dd_factor_sequence CASCADE
09:38:21.596 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE SEQUENCE dd_factor_sequence MINVALUE -1 START 0
09:38:21.597 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_feature_statistics_support CASCADE
09:38:21.597 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_feature_statistics_support(
            description text, 
            pos_examples bigint, 
            neg_examples bigint, 
            queries bigint)
09:38:21.599 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_query_testFactor CASCADE
09:38:21.599 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_query_testFactor AS SELECT id AS "r1.id", weight AS "weight", is_correct AS "r1.is_correct" FROM r1
09:38:21.602 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: ALTER TABLE dd_query_testFactor ADD COLUMN id bigint
09:38:21.603 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: UPDATE dd_query_testFactor SET id =  nextval('dd_factor_sequence')
09:38:21.606 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing SQL with callback... SELECT COUNT(*) FROM dd_query_testFactor;
09:38:21.607 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_weights_testFactor CASCADE
09:38:21.607 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_weights_testFactor AS
              SELECT  "weight" , false::int AS isfixed, 0.0::float AS initvalue, 
                0::bigint AS id
              FROM dd_query_testFactor
              GROUP BY  "weight"
09:38:21.610 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: UPDATE dd_weights_testFactor SET id =  nextval('dd_weight_sequence')
09:38:21.613 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing SQL with callback... SELECT COUNT(*) FROM dd_weights_testFactor;
09:38:21.614 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: INSERT INTO dd_graph_weights(id, isfixed, initvalue, description) 
            SELECT id, isfixed, initvalue, 'weight_prefix-'  || (CASE WHEN "weight" IS NULL THEN '' ELSE "weight"::text END) FROM dd_weights_testFactor
09:38:21.616 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing SQL with callback... SELECT COUNT(*) FROM dd_query_testFactor WHERE  "weight" IS NULL 
09:38:21.617 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] DEBUG Executing queries by file: psql  -d deepdive_test  -U jackywang  -p 5432  -h localhost  -c 'COPY (SELECT t0.id AS factor_id, t1.id AS weight_id,  "r1.id"
             FROM dd_query_testFactor t0, dd_weights_testFactor t1
             WHERE  t0."weight" = t1."weight") TO STDOUT;'   > /Users/jackywang/Desktop/341/project/deepdive/out/dd_factors_testFactor_out
09:38:21.618 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/exec_sql5116438219929028931.sh" 
09:38:21.652 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: INSERT INTO dd_feature_statistics_support
        SELECT 'weight_prefix-'  || (CASE WHEN "weight" IS NULL THEN '' ELSE "weight"::text END) as description,
               count(CASE WHEN  "r1.is_correct" =TRUE THEN 1 ELSE NULL END) AS pos_examples,
               count(CASE WHEN  "r1.is_correct" =FALSE THEN 1 ELSE NULL END) AS neg_examples,
               count(CASE WHEN  "r1.is_correct"  IS NULL THEN 1 ELSE NULL END) AS queries
        FROM dd_query_testFactor
        GROUP BY  "weight"
09:38:21.654 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: ANALYZE dd_feature_statistics_support
09:38:21.657 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] DEBUG Executing queries by file: psql  -d deepdive_test  -U jackywang  -p 5432  -h localhost  -c 'COPY (SELECT id, isfixed, COALESCE(initvalue, 0) FROM dd_graph_weights) TO STDOUT;'   > /Users/jackywang/Desktop/341/project/deepdive/out/dd_weights
09:38:21.657 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/exec_sql5030239977465388140.sh" 
09:38:21.690 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_inference_result_variables CASCADE
09:38:21.691 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_inference_result_variables(
      id bigint, 
      category bigint, 
      expectation double precision)
09:38:21.692 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_inference_result_weights CASCADE
09:38:21.692 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_inference_result_weights(
      id bigint primary key, 
      weight double precision)
09:38:21.694 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  Converting grounding file format...
09:38:21.694 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] DEBUG Executing: python /Users/jackywang/Desktop/341/project/deepdive/util/tobinary.py /Users/jackywang/Desktop/341/project/deepdive/out /Users/jackywang/Desktop/341/project/deepdive/util/format_converter_mac /Users/jackywang/Desktop/341/project/deepdive/out
09:38:21.958 [Thread-45][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  SPLITTING testFactor ...
09:38:21.959 [Thread-45][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  BINARIZE  testFactor ...
09:38:21.959 [Thread-45][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  SPLITTING dd_variables_r1 ...
09:38:21.959 [Thread-45][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  BINARIZE  dd_variables_r1 ...
09:38:21.959 [Thread-45][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  BINARIZE  weights ...
09:38:21.959 [Thread-45][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  COUNTING variables ...
09:38:21.960 [Thread-45][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  COUNTING factors ...
09:38:21.960 [Thread-45][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  COUNTING weights ...
09:38:21.960 [Thread-45][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  CONCATENATING FILES...
09:38:21.960 [Thread-45][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  Cleaning up files
09:38:21.965 [ScalaTest-running-PostgresInferenceDataStoreSpec][JdbcDataStore$(akka://deepdive)][JdbcDataStore$] INFO  Closing all JDBC data stores
09:38:21.965 [ScalaTest-running-PostgresInferenceDataStoreSpec][JdbcDataStore$(akka://deepdive)][JdbcDataStore$] INFO  Intializing all JDBC data stores
09:38:22.118 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing SQL with callback... 
    SELECT version() LIKE '%Greenplum%';
  
09:38:22.119 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  Using Greenplum = false
09:38:22.119 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  Datastore type = psql
09:38:22.119 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  Parallel grounding = false
09:38:22.119 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] DEBUG Grounding Path = /Users/jackywang/Desktop/341/project/deepdive/out
09:38:22.119 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing SQL with callback... 
    SELECT version() LIKE '%Greenplum%';
  
09:38:22.120 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP SEQUENCE IF EXISTS dd_variable_sequence CASCADE
09:38:22.120 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE SEQUENCE dd_variable_sequence MINVALUE -1 START 0
09:38:22.123 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: UPDATE r1 SET id =  nextval('dd_variable_sequence')
09:38:22.125 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_graph_variables_holdout CASCADE
09:38:22.125 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_graph_variables_holdout(variable_id bigint primary key)
09:38:22.127 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: INSERT INTO dd_graph_variables_holdout(variable_id)
          SELECT id FROM r1 WHERE weight <= 10
09:38:22.130 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_graph_variables_observation CASCADE
09:38:22.130 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_graph_variables_observation(variable_id bigint primary key)
09:38:22.133 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS r1_is_correct_cardinality CASCADE
09:38:22.133 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE r1_is_correct_cardinality(cardinality text)
09:38:22.135 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: INSERT INTO r1_is_correct_cardinality VALUES ('00001')
09:38:22.136 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS r1_vtype CASCADE
09:38:22.136 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE r1_vtype AS
        SELECT t0.id, CASE WHEN t2.variable_id IS NOT NULL AND is_correct IS NOT NULL THEN 2
                           WHEN t1.variable_id IS NOT NULL THEN 0
                           WHEN is_correct IS NOT NULL THEN 1
                           ELSE 0
                      END as __dd_variable_type__
        FROM r1 t0 LEFT OUTER JOIN dd_graph_variables_holdout t1 
        ON t0.id=t1.variable_id LEFT OUTER JOIN dd_graph_variables_observation t2 ON t0.id=t2.variable_id
09:38:22.141 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] DEBUG Executing queries by file: psql  -d deepdive_test  -U jackywang  -p 5432  -h localhost  -c 'COPY (SELECT t0.id, t1.__dd_variable_type__,
        CASE WHEN t1.__dd_variable_type__ = 0 THEN 0 ELSE is_correct::int::float END AS initvalue,
        0 AS type, 2 AS cardinality
        FROM r1 t0, r1_vtype t1
        WHERE t0.id=t1.id) TO STDOUT;'   > /Users/jackywang/Desktop/341/project/deepdive/out/dd_variables_r1
09:38:22.141 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/exec_sql8999570146675102860.sh" 
09:38:22.177 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_graph_factormeta CASCADE
09:38:22.178 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_graph_factormeta (name text, funcid int, sign text)
09:38:22.180 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: INSERT INTO dd_graph_factormeta VALUES ('testFactor', 4, 'true')
09:38:22.181 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] DEBUG Executing queries by file: psql  -d deepdive_test  -U jackywang  -p 5432  -h localhost  -c 'COPY (SELECT * FROM dd_graph_factormeta) TO STDOUT;'   > /Users/jackywang/Desktop/341/project/deepdive/out/dd_factormeta
09:38:22.181 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/exec_sql8712022738079369553.sh" 
09:38:22.213 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_graph_weights CASCADE
09:38:22.213 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_graph_weights (id bigint, isfixed int, initvalue real, 
      cardinality text, description text)
09:38:22.215 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP SEQUENCE IF EXISTS dd_weight_sequence CASCADE
09:38:22.216 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE SEQUENCE dd_weight_sequence MINVALUE -1 START 0
09:38:22.217 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP SEQUENCE IF EXISTS dd_factor_sequence CASCADE
09:38:22.217 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE SEQUENCE dd_factor_sequence MINVALUE -1 START 0
09:38:22.218 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_feature_statistics_support CASCADE
09:38:22.219 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_feature_statistics_support(
            description text, 
            pos_examples bigint, 
            neg_examples bigint, 
            queries bigint)
09:38:22.222 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_query_testFactor CASCADE
09:38:22.222 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_query_testFactor AS SELECT id AS "r1.id", weight AS "weight", is_correct AS "r1.is_correct" FROM r1
09:38:22.224 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: ALTER TABLE dd_query_testFactor ADD COLUMN id bigint
09:38:22.225 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: UPDATE dd_query_testFactor SET id =  nextval('dd_factor_sequence')
09:38:22.228 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing SQL with callback... SELECT COUNT(*) FROM dd_query_testFactor;
09:38:22.229 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_weights_testFactor CASCADE
09:38:22.229 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_weights_testFactor AS
              SELECT  "weight" , false::int AS isfixed, 0.0::float AS initvalue, 
                0::bigint AS id
              FROM dd_query_testFactor
              GROUP BY  "weight"
09:38:22.231 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: UPDATE dd_weights_testFactor SET id =  nextval('dd_weight_sequence')
09:38:22.234 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing SQL with callback... SELECT COUNT(*) FROM dd_weights_testFactor;
09:38:22.235 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: INSERT INTO dd_graph_weights(id, isfixed, initvalue, description) 
            SELECT id, isfixed, initvalue, 'weight_prefix-'  || (CASE WHEN "weight" IS NULL THEN '' ELSE "weight"::text END) FROM dd_weights_testFactor
09:38:22.236 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing SQL with callback... SELECT COUNT(*) FROM dd_query_testFactor WHERE  "weight" IS NULL 
09:38:22.237 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] DEBUG Executing queries by file: psql  -d deepdive_test  -U jackywang  -p 5432  -h localhost  -c 'COPY (SELECT t0.id AS factor_id, t1.id AS weight_id,  "r1.id"
             FROM dd_query_testFactor t0, dd_weights_testFactor t1
             WHERE  t0."weight" = t1."weight") TO STDOUT;'   > /Users/jackywang/Desktop/341/project/deepdive/out/dd_factors_testFactor_out
09:38:22.237 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/exec_sql6807573129470618330.sh" 
09:38:22.270 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: INSERT INTO dd_feature_statistics_support
        SELECT 'weight_prefix-'  || (CASE WHEN "weight" IS NULL THEN '' ELSE "weight"::text END) as description,
               count(CASE WHEN  "r1.is_correct" =TRUE THEN 1 ELSE NULL END) AS pos_examples,
               count(CASE WHEN  "r1.is_correct" =FALSE THEN 1 ELSE NULL END) AS neg_examples,
               count(CASE WHEN  "r1.is_correct"  IS NULL THEN 1 ELSE NULL END) AS queries
        FROM dd_query_testFactor
        GROUP BY  "weight"
09:38:22.272 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: ANALYZE dd_feature_statistics_support
09:38:22.275 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] DEBUG Executing queries by file: psql  -d deepdive_test  -U jackywang  -p 5432  -h localhost  -c 'COPY (SELECT id, isfixed, COALESCE(initvalue, 0) FROM dd_graph_weights) TO STDOUT;'   > /Users/jackywang/Desktop/341/project/deepdive/out/dd_weights
09:38:22.275 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/exec_sql953689525936585490.sh" 
09:38:22.307 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_inference_result_variables CASCADE
09:38:22.307 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_inference_result_variables(
      id bigint, 
      category bigint, 
      expectation double precision)
09:38:22.308 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_inference_result_weights CASCADE
09:38:22.308 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_inference_result_weights(
      id bigint primary key, 
      weight double precision)
09:38:22.310 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  Converting grounding file format...
09:38:22.310 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] DEBUG Executing: python /Users/jackywang/Desktop/341/project/deepdive/util/tobinary.py /Users/jackywang/Desktop/341/project/deepdive/out /Users/jackywang/Desktop/341/project/deepdive/util/format_converter_mac /Users/jackywang/Desktop/341/project/deepdive/out
09:38:22.581 [Thread-60][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  SPLITTING testFactor ...
09:38:22.581 [Thread-60][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  BINARIZE  testFactor ...
09:38:22.581 [Thread-60][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  SPLITTING dd_variables_r1 ...
09:38:22.581 [Thread-60][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  BINARIZE  dd_variables_r1 ...
09:38:22.582 [Thread-60][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  BINARIZE  weights ...
09:38:22.582 [Thread-60][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  COUNTING variables ...
09:38:22.582 [Thread-60][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  COUNTING factors ...
09:38:22.582 [Thread-60][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  COUNTING weights ...
09:38:22.582 [Thread-60][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  CONCATENATING FILES...
09:38:22.583 [Thread-60][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  Cleaning up files
09:38:22.587 [ScalaTest-running-PostgresInferenceDataStoreSpec][JdbcDataStore$(akka://deepdive)][JdbcDataStore$] INFO  Closing all JDBC data stores
09:38:22.587 [ScalaTest-running-PostgresInferenceDataStoreSpec][JdbcDataStore$(akka://deepdive)][JdbcDataStore$] INFO  Intializing all JDBC data stores
09:38:22.736 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing SQL with callback... 
    SELECT version() LIKE '%Greenplum%';
  
09:38:22.737 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  Using Greenplum = false
09:38:22.737 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  Datastore type = psql
09:38:22.737 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  Parallel grounding = false
09:38:22.737 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] DEBUG Grounding Path = /Users/jackywang/Desktop/341/project/deepdive/out
09:38:22.737 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing SQL with callback... 
    SELECT version() LIKE '%Greenplum%';
  
09:38:22.737 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP SEQUENCE IF EXISTS dd_variable_sequence CASCADE
09:38:22.738 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE SEQUENCE dd_variable_sequence MINVALUE -1 START 0
09:38:22.740 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: UPDATE r1 SET id =  nextval('dd_variable_sequence')
09:38:22.741 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_graph_variables_holdout CASCADE
09:38:22.741 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_graph_variables_holdout(variable_id bigint primary key)
09:38:22.744 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_graph_variables_observation CASCADE
09:38:22.744 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_graph_variables_observation(variable_id bigint primary key)
09:38:22.746 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: INSERT INTO dd_graph_variables_observation(variable_id)
          SELECT id FROM r1 WHERE weight <= 10
09:38:22.749 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: INSERT INTO dd_graph_variables_holdout
            SELECT id FROM r1
            WHERE RANDOM() < 0.0 AND is_correct IS NOT NULL
09:38:22.750 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS r1_is_correct_cardinality CASCADE
09:38:22.751 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE r1_is_correct_cardinality(cardinality text)
09:38:22.753 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: INSERT INTO r1_is_correct_cardinality VALUES ('00001')
09:38:22.753 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS r1_vtype CASCADE
09:38:22.754 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE r1_vtype AS
        SELECT t0.id, CASE WHEN t2.variable_id IS NOT NULL AND is_correct IS NOT NULL THEN 2
                           WHEN t1.variable_id IS NOT NULL THEN 0
                           WHEN is_correct IS NOT NULL THEN 1
                           ELSE 0
                      END as __dd_variable_type__
        FROM r1 t0 LEFT OUTER JOIN dd_graph_variables_holdout t1 
        ON t0.id=t1.variable_id LEFT OUTER JOIN dd_graph_variables_observation t2 ON t0.id=t2.variable_id
09:38:22.759 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] DEBUG Executing queries by file: psql  -d deepdive_test  -U jackywang  -p 5432  -h localhost  -c 'COPY (SELECT t0.id, t1.__dd_variable_type__,
        CASE WHEN t1.__dd_variable_type__ = 0 THEN 0 ELSE is_correct::int::float END AS initvalue,
        0 AS type, 2 AS cardinality
        FROM r1 t0, r1_vtype t1
        WHERE t0.id=t1.id) TO STDOUT;'   > /Users/jackywang/Desktop/341/project/deepdive/out/dd_variables_r1
09:38:22.759 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/exec_sql7302607256671030133.sh" 
09:38:22.794 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_graph_factormeta CASCADE
09:38:22.794 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_graph_factormeta (name text, funcid int, sign text)
09:38:22.796 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: INSERT INTO dd_graph_factormeta VALUES ('testFactor', 4, 'true')
09:38:22.797 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] DEBUG Executing queries by file: psql  -d deepdive_test  -U jackywang  -p 5432  -h localhost  -c 'COPY (SELECT * FROM dd_graph_factormeta) TO STDOUT;'   > /Users/jackywang/Desktop/341/project/deepdive/out/dd_factormeta
09:38:22.797 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/exec_sql5918137517581242523.sh" 
09:38:22.829 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_graph_weights CASCADE
09:38:22.829 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_graph_weights (id bigint, isfixed int, initvalue real, 
      cardinality text, description text)
09:38:22.832 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP SEQUENCE IF EXISTS dd_weight_sequence CASCADE
09:38:22.832 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE SEQUENCE dd_weight_sequence MINVALUE -1 START 0
09:38:22.833 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP SEQUENCE IF EXISTS dd_factor_sequence CASCADE
09:38:22.833 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE SEQUENCE dd_factor_sequence MINVALUE -1 START 0
09:38:22.837 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_feature_statistics_support CASCADE
09:38:22.837 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_feature_statistics_support(
            description text, 
            pos_examples bigint, 
            neg_examples bigint, 
            queries bigint)
09:38:22.839 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_query_testFactor CASCADE
09:38:22.840 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_query_testFactor AS SELECT id AS "r1.id", weight AS "weight", is_correct AS "r1.is_correct" FROM r1
09:38:22.841 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: ALTER TABLE dd_query_testFactor ADD COLUMN id bigint
09:38:22.842 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: UPDATE dd_query_testFactor SET id =  nextval('dd_factor_sequence')
09:38:22.845 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing SQL with callback... SELECT COUNT(*) FROM dd_query_testFactor;
09:38:22.846 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_weights_testFactor CASCADE
09:38:22.846 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_weights_testFactor AS
              SELECT  "weight" , false::int AS isfixed, 0.0::float AS initvalue, 
                0::bigint AS id
              FROM dd_query_testFactor
              GROUP BY  "weight"
09:38:22.849 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: UPDATE dd_weights_testFactor SET id =  nextval('dd_weight_sequence')
09:38:22.852 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing SQL with callback... SELECT COUNT(*) FROM dd_weights_testFactor;
09:38:22.853 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: INSERT INTO dd_graph_weights(id, isfixed, initvalue, description) 
            SELECT id, isfixed, initvalue, 'weight_prefix-'  || (CASE WHEN "weight" IS NULL THEN '' ELSE "weight"::text END) FROM dd_weights_testFactor
09:38:22.854 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing SQL with callback... SELECT COUNT(*) FROM dd_query_testFactor WHERE  "weight" IS NULL 
09:38:22.855 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] DEBUG Executing queries by file: psql  -d deepdive_test  -U jackywang  -p 5432  -h localhost  -c 'COPY (SELECT t0.id AS factor_id, t1.id AS weight_id,  "r1.id"
             FROM dd_query_testFactor t0, dd_weights_testFactor t1
             WHERE  t0."weight" = t1."weight") TO STDOUT;'   > /Users/jackywang/Desktop/341/project/deepdive/out/dd_factors_testFactor_out
09:38:22.855 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/exec_sql2176002238534833646.sh" 
09:38:22.890 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: INSERT INTO dd_feature_statistics_support
        SELECT 'weight_prefix-'  || (CASE WHEN "weight" IS NULL THEN '' ELSE "weight"::text END) as description,
               count(CASE WHEN  "r1.is_correct" =TRUE THEN 1 ELSE NULL END) AS pos_examples,
               count(CASE WHEN  "r1.is_correct" =FALSE THEN 1 ELSE NULL END) AS neg_examples,
               count(CASE WHEN  "r1.is_correct"  IS NULL THEN 1 ELSE NULL END) AS queries
        FROM dd_query_testFactor
        GROUP BY  "weight"
09:38:22.891 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: ANALYZE dd_feature_statistics_support
09:38:22.894 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] DEBUG Executing queries by file: psql  -d deepdive_test  -U jackywang  -p 5432  -h localhost  -c 'COPY (SELECT id, isfixed, COALESCE(initvalue, 0) FROM dd_graph_weights) TO STDOUT;'   > /Users/jackywang/Desktop/341/project/deepdive/out/dd_weights
09:38:22.894 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/exec_sql4365437744868152953.sh" 
09:38:22.926 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_inference_result_variables CASCADE
09:38:22.926 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_inference_result_variables(
      id bigint, 
      category bigint, 
      expectation double precision)
09:38:22.927 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_inference_result_weights CASCADE
09:38:22.927 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_inference_result_weights(
      id bigint primary key, 
      weight double precision)
09:38:22.929 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  Converting grounding file format...
09:38:22.930 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] DEBUG Executing: python /Users/jackywang/Desktop/341/project/deepdive/util/tobinary.py /Users/jackywang/Desktop/341/project/deepdive/out /Users/jackywang/Desktop/341/project/deepdive/util/format_converter_mac /Users/jackywang/Desktop/341/project/deepdive/out
09:38:23.191 [Thread-75][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  SPLITTING testFactor ...
09:38:23.191 [Thread-75][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  BINARIZE  testFactor ...
09:38:23.191 [Thread-75][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  SPLITTING dd_variables_r1 ...
09:38:23.191 [Thread-75][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  BINARIZE  dd_variables_r1 ...
09:38:23.191 [Thread-75][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  BINARIZE  weights ...
09:38:23.191 [Thread-75][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  COUNTING variables ...
09:38:23.191 [Thread-75][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  COUNTING factors ...
09:38:23.192 [Thread-75][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  COUNTING weights ...
09:38:23.192 [Thread-75][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  CONCATENATING FILES...
09:38:23.192 [Thread-75][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  Cleaning up files
09:38:23.196 [ScalaTest-running-PostgresInferenceDataStoreSpec][JdbcDataStore$(akka://deepdive)][JdbcDataStore$] INFO  Closing all JDBC data stores
09:38:23.197 [ScalaTest-running-PostgresInferenceDataStoreSpec][JdbcDataStore$(akka://deepdive)][JdbcDataStore$] INFO  Intializing all JDBC data stores
09:38:23.351 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing SQL with callback... 
    SELECT version() LIKE '%Greenplum%';
  
09:38:23.352 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  Using Greenplum = false
09:38:23.352 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  Datastore type = psql
09:38:23.352 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  Parallel grounding = false
09:38:23.352 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] DEBUG Grounding Path = /Users/jackywang/Desktop/341/project/deepdive/out
09:38:23.352 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing SQL with callback... 
    SELECT version() LIKE '%Greenplum%';
  
09:38:23.352 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP SEQUENCE IF EXISTS dd_variable_sequence CASCADE
09:38:23.353 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE SEQUENCE dd_variable_sequence MINVALUE -1 START 0
09:38:23.355 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: UPDATE r1 SET id =  nextval('dd_variable_sequence')
09:38:23.357 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_graph_variables_holdout CASCADE
09:38:23.357 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_graph_variables_holdout(variable_id bigint primary key)
09:38:23.360 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_graph_variables_observation CASCADE
09:38:23.360 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_graph_variables_observation(variable_id bigint primary key)
09:38:23.362 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: INSERT INTO dd_graph_variables_observation(variable_id)
          SELECT id FROM r1 WHERE id < 10
09:38:23.364 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: INSERT INTO dd_graph_variables_holdout
            SELECT id FROM r1
            WHERE RANDOM() < 0.0 AND is_correct IS NOT NULL
09:38:23.365 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS r1_is_correct_cardinality CASCADE
09:38:23.365 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE r1_is_correct_cardinality(cardinality text)
09:38:23.368 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: INSERT INTO r1_is_correct_cardinality VALUES ('00001')
09:38:23.368 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS r1_vtype CASCADE
09:38:23.369 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE r1_vtype AS
        SELECT t0.id, CASE WHEN t2.variable_id IS NOT NULL AND is_correct IS NOT NULL THEN 2
                           WHEN t1.variable_id IS NOT NULL THEN 0
                           WHEN is_correct IS NOT NULL THEN 1
                           ELSE 0
                      END as __dd_variable_type__
        FROM r1 t0 LEFT OUTER JOIN dd_graph_variables_holdout t1 
        ON t0.id=t1.variable_id LEFT OUTER JOIN dd_graph_variables_observation t2 ON t0.id=t2.variable_id
09:38:23.373 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] DEBUG Executing queries by file: psql  -d deepdive_test  -U jackywang  -p 5432  -h localhost  -c 'COPY (SELECT t0.id, t1.__dd_variable_type__,
        CASE WHEN t1.__dd_variable_type__ = 0 THEN 0 ELSE is_correct::int::float END AS initvalue,
        0 AS type, 2 AS cardinality
        FROM r1 t0, r1_vtype t1
        WHERE t0.id=t1.id) TO STDOUT;'   > /Users/jackywang/Desktop/341/project/deepdive/out/dd_variables_r1
09:38:23.374 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/exec_sql835039647545274623.sh" 
09:38:23.408 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_graph_factormeta CASCADE
09:38:23.408 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_graph_factormeta (name text, funcid int, sign text)
09:38:23.410 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: INSERT INTO dd_graph_factormeta VALUES ('testFactor', 4, 'true')
09:38:23.411 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] DEBUG Executing queries by file: psql  -d deepdive_test  -U jackywang  -p 5432  -h localhost  -c 'COPY (SELECT * FROM dd_graph_factormeta) TO STDOUT;'   > /Users/jackywang/Desktop/341/project/deepdive/out/dd_factormeta
09:38:23.411 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/exec_sql5367197466577441746.sh" 
09:38:23.442 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_graph_weights CASCADE
09:38:23.443 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_graph_weights (id bigint, isfixed int, initvalue real, 
      cardinality text, description text)
09:38:23.447 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP SEQUENCE IF EXISTS dd_weight_sequence CASCADE
09:38:23.447 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE SEQUENCE dd_weight_sequence MINVALUE -1 START 0
09:38:23.448 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP SEQUENCE IF EXISTS dd_factor_sequence CASCADE
09:38:23.448 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE SEQUENCE dd_factor_sequence MINVALUE -1 START 0
09:38:23.449 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_feature_statistics_support CASCADE
09:38:23.450 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_feature_statistics_support(
            description text, 
            pos_examples bigint, 
            neg_examples bigint, 
            queries bigint)
09:38:23.451 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_query_testFactor CASCADE
09:38:23.452 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_query_testFactor AS SELECT id AS "r1.id", weight AS "weight", is_correct AS "r1.is_correct" FROM r1
09:38:23.455 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: ALTER TABLE dd_query_testFactor ADD COLUMN id bigint
09:38:23.455 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: UPDATE dd_query_testFactor SET id =  nextval('dd_factor_sequence')
09:38:23.459 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing SQL with callback... SELECT COUNT(*) FROM dd_query_testFactor;
09:38:23.460 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_weights_testFactor CASCADE
09:38:23.460 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_weights_testFactor AS
              SELECT  "weight" , false::int AS isfixed, 0.0::float AS initvalue, 
                0::bigint AS id
              FROM dd_query_testFactor
              GROUP BY  "weight"
09:38:23.463 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: UPDATE dd_weights_testFactor SET id =  nextval('dd_weight_sequence')
09:38:23.466 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing SQL with callback... SELECT COUNT(*) FROM dd_weights_testFactor;
09:38:23.467 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: INSERT INTO dd_graph_weights(id, isfixed, initvalue, description) 
            SELECT id, isfixed, initvalue, 'weight_prefix-'  || (CASE WHEN "weight" IS NULL THEN '' ELSE "weight"::text END) FROM dd_weights_testFactor
09:38:23.468 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing SQL with callback... SELECT COUNT(*) FROM dd_query_testFactor WHERE  "weight" IS NULL 
09:38:23.469 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] DEBUG Executing queries by file: psql  -d deepdive_test  -U jackywang  -p 5432  -h localhost  -c 'COPY (SELECT t0.id AS factor_id, t1.id AS weight_id,  "r1.id"
             FROM dd_query_testFactor t0, dd_weights_testFactor t1
             WHERE  t0."weight" = t1."weight") TO STDOUT;'   > /Users/jackywang/Desktop/341/project/deepdive/out/dd_factors_testFactor_out
09:38:23.469 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/exec_sql2981439336418981051.sh" 
09:38:23.505 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: INSERT INTO dd_feature_statistics_support
        SELECT 'weight_prefix-'  || (CASE WHEN "weight" IS NULL THEN '' ELSE "weight"::text END) as description,
               count(CASE WHEN  "r1.is_correct" =TRUE THEN 1 ELSE NULL END) AS pos_examples,
               count(CASE WHEN  "r1.is_correct" =FALSE THEN 1 ELSE NULL END) AS neg_examples,
               count(CASE WHEN  "r1.is_correct"  IS NULL THEN 1 ELSE NULL END) AS queries
        FROM dd_query_testFactor
        GROUP BY  "weight"
09:38:23.522 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: ANALYZE dd_feature_statistics_support
09:38:23.525 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] DEBUG Executing queries by file: psql  -d deepdive_test  -U jackywang  -p 5432  -h localhost  -c 'COPY (SELECT id, isfixed, COALESCE(initvalue, 0) FROM dd_graph_weights) TO STDOUT;'   > /Users/jackywang/Desktop/341/project/deepdive/out/dd_weights
09:38:23.525 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/exec_sql9222729082112957619.sh" 
09:38:23.557 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_inference_result_variables CASCADE
09:38:23.557 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_inference_result_variables(
      id bigint, 
      category bigint, 
      expectation double precision)
09:38:23.558 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_inference_result_weights CASCADE
09:38:23.558 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_inference_result_weights(
      id bigint primary key, 
      weight double precision)
09:38:23.572 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  Converting grounding file format...
09:38:23.572 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] DEBUG Executing: python /Users/jackywang/Desktop/341/project/deepdive/util/tobinary.py /Users/jackywang/Desktop/341/project/deepdive/out /Users/jackywang/Desktop/341/project/deepdive/util/format_converter_mac /Users/jackywang/Desktop/341/project/deepdive/out
09:38:23.838 [Thread-90][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  SPLITTING testFactor ...
09:38:23.838 [Thread-90][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  BINARIZE  testFactor ...
09:38:23.838 [Thread-90][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  SPLITTING dd_variables_r1 ...
09:38:23.838 [Thread-90][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  BINARIZE  dd_variables_r1 ...
09:38:23.838 [Thread-90][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  BINARIZE  weights ...
09:38:23.838 [Thread-90][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  COUNTING variables ...
09:38:23.838 [Thread-90][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  COUNTING factors ...
09:38:23.838 [Thread-90][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  COUNTING weights ...
09:38:23.839 [Thread-90][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  CONCATENATING FILES...
09:38:23.839 [Thread-90][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  Cleaning up files
09:38:23.843 [ScalaTest-running-PostgresInferenceDataStoreSpec][JdbcDataStore$(akka://deepdive)][JdbcDataStore$] INFO  Closing all JDBC data stores
09:38:23.843 [ScalaTest-running-PostgresInferenceDataStoreSpec][JdbcDataStore$(akka://deepdive)][JdbcDataStore$] INFO  Intializing all JDBC data stores
09:38:23.995 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing SQL with callback... 
    SELECT version() LIKE '%Greenplum%';
  
09:38:23.996 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  Using Greenplum = false
09:38:23.996 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  Datastore type = psql
09:38:23.996 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  Parallel grounding = false
09:38:23.996 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] DEBUG Grounding Path = /Users/jackywang/Desktop/341/project/deepdive/out
09:38:23.996 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing SQL with callback... 
    SELECT version() LIKE '%Greenplum%';
  
09:38:23.996 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP SEQUENCE IF EXISTS dd_variable_sequence CASCADE
09:38:23.997 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE SEQUENCE dd_variable_sequence MINVALUE -1 START 0
09:38:23.999 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: UPDATE r1 SET id =  nextval('dd_variable_sequence')
09:38:24.000 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_graph_variables_holdout CASCADE
09:38:24.000 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_graph_variables_holdout(variable_id bigint primary key)
09:38:24.002 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_graph_variables_observation CASCADE
09:38:24.003 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_graph_variables_observation(variable_id bigint primary key)
09:38:24.005 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: INSERT INTO dd_graph_variables_holdout
            SELECT id FROM r1
            WHERE RANDOM() < 0.0 AND is_correct IS NOT NULL
09:38:24.007 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS r1_is_correct_cardinality CASCADE
09:38:24.007 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE r1_is_correct_cardinality(cardinality text)
09:38:24.009 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: INSERT INTO r1_is_correct_cardinality VALUES ('00001')
09:38:24.010 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS r1_vtype CASCADE
09:38:24.010 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE r1_vtype AS
        SELECT t0.id, CASE WHEN t2.variable_id IS NOT NULL AND is_correct IS NOT NULL THEN 2
                           WHEN t1.variable_id IS NOT NULL THEN 0
                           WHEN is_correct IS NOT NULL THEN 1
                           ELSE 0
                      END as __dd_variable_type__
        FROM r1 t0 LEFT OUTER JOIN dd_graph_variables_holdout t1 
        ON t0.id=t1.variable_id LEFT OUTER JOIN dd_graph_variables_observation t2 ON t0.id=t2.variable_id
09:38:24.016 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] DEBUG Executing queries by file: psql  -d deepdive_test  -U jackywang  -p 5432  -h localhost  -c 'COPY (SELECT t0.id, t1.__dd_variable_type__,
        CASE WHEN t1.__dd_variable_type__ = 0 THEN 0 ELSE is_correct::int::float END AS initvalue,
        0 AS type, 2 AS cardinality
        FROM r1 t0, r1_vtype t1
        WHERE t0.id=t1.id) TO STDOUT;'   > /Users/jackywang/Desktop/341/project/deepdive/out/dd_variables_r1
09:38:24.016 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/exec_sql8297754493924304217.sh" 
09:38:24.053 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_graph_factormeta CASCADE
09:38:24.053 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_graph_factormeta (name text, funcid int, sign text)
09:38:24.056 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: INSERT INTO dd_graph_factormeta VALUES ('testFactor', 4, 'true')
09:38:24.058 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] DEBUG Executing queries by file: psql  -d deepdive_test  -U jackywang  -p 5432  -h localhost  -c 'COPY (SELECT * FROM dd_graph_factormeta) TO STDOUT;'   > /Users/jackywang/Desktop/341/project/deepdive/out/dd_factormeta
09:38:24.058 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/exec_sql3431851638941345740.sh" 
09:38:24.095 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_graph_weights CASCADE
09:38:24.095 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_graph_weights (id bigint, isfixed int, initvalue real, 
      cardinality text, description text)
09:38:24.097 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP SEQUENCE IF EXISTS dd_weight_sequence CASCADE
09:38:24.098 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE SEQUENCE dd_weight_sequence MINVALUE -1 START 0
09:38:24.099 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP SEQUENCE IF EXISTS dd_factor_sequence CASCADE
09:38:24.099 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE SEQUENCE dd_factor_sequence MINVALUE -1 START 0
09:38:24.100 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_feature_statistics_support CASCADE
09:38:24.100 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_feature_statistics_support(
            description text, 
            pos_examples bigint, 
            neg_examples bigint, 
            queries bigint)
09:38:24.102 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_query_testFactor CASCADE
09:38:24.103 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_query_testFactor AS SELECT id AS "r1.id", weight AS "weight", is_correct AS "r1.is_correct" FROM r1
09:38:24.105 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: ALTER TABLE dd_query_testFactor ADD COLUMN id bigint
09:38:24.106 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: UPDATE dd_query_testFactor SET id =  nextval('dd_factor_sequence')
09:38:24.109 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing SQL with callback... SELECT COUNT(*) FROM dd_query_testFactor;
09:38:24.110 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_weights_testFactor CASCADE
09:38:24.110 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_weights_testFactor AS
              SELECT  "weight" , false::int AS isfixed, 0.0::float AS initvalue, 
                0::bigint AS id
              FROM dd_query_testFactor
              GROUP BY  "weight"
09:38:24.114 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: UPDATE dd_weights_testFactor SET id =  nextval('dd_weight_sequence')
09:38:24.116 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing SQL with callback... SELECT COUNT(*) FROM dd_weights_testFactor;
09:38:24.117 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: INSERT INTO dd_graph_weights(id, isfixed, initvalue, description) 
            SELECT id, isfixed, initvalue, 'weight_prefix-'  || (CASE WHEN "weight" IS NULL THEN '' ELSE "weight"::text END) FROM dd_weights_testFactor
09:38:24.118 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing SQL with callback... SELECT COUNT(*) FROM dd_query_testFactor WHERE  "weight" IS NULL 
09:38:24.123 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] ERROR java.lang.RuntimeException: Weight variable has null values
09:38:24.123 [ScalaTest-running-PostgresInferenceDataStoreSpec][JdbcDataStore$(akka://deepdive)][JdbcDataStore$] INFO  Closing all JDBC data stores
09:38:24.123 [ScalaTest-running-PostgresInferenceDataStoreSpec][JdbcDataStore$(akka://deepdive)][JdbcDataStore$] INFO  Intializing all JDBC data stores
09:38:24.287 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing SQL with callback... 
    SELECT version() LIKE '%Greenplum%';
  
09:38:24.288 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  Using Greenplum = false
09:38:24.288 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  Datastore type = psql
09:38:24.288 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  Parallel grounding = false
09:38:24.288 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] DEBUG Grounding Path = /Users/jackywang/Desktop/341/project/deepdive/out
09:38:24.289 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing SQL with callback... 
    SELECT version() LIKE '%Greenplum%';
  
09:38:24.289 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP SEQUENCE IF EXISTS dd_variable_sequence CASCADE
09:38:24.289 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE SEQUENCE dd_variable_sequence MINVALUE -1 START 0
09:38:24.292 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: UPDATE r1 SET id =  nextval('dd_variable_sequence')
09:38:24.293 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: UPDATE r2 SET id =  nextval('dd_variable_sequence')
09:38:24.295 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_graph_variables_holdout CASCADE
09:38:24.295 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_graph_variables_holdout(variable_id bigint primary key)
09:38:24.298 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_graph_variables_observation CASCADE
09:38:24.298 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_graph_variables_observation(variable_id bigint primary key)
09:38:24.300 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: INSERT INTO dd_graph_variables_holdout
            SELECT id FROM r1
            WHERE RANDOM() < 0.0 AND is_correct IS NOT NULL
09:38:24.301 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS r1_is_correct_cardinality CASCADE
09:38:24.301 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE r1_is_correct_cardinality(cardinality text)
09:38:24.303 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: INSERT INTO r1_is_correct_cardinality VALUES ('00001')
09:38:24.305 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS r1_vtype CASCADE
09:38:24.305 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE r1_vtype AS
        SELECT t0.id, CASE WHEN t2.variable_id IS NOT NULL AND is_correct IS NOT NULL THEN 2
                           WHEN t1.variable_id IS NOT NULL THEN 0
                           WHEN is_correct IS NOT NULL THEN 1
                           ELSE 0
                      END as __dd_variable_type__
        FROM r1 t0 LEFT OUTER JOIN dd_graph_variables_holdout t1 
        ON t0.id=t1.variable_id LEFT OUTER JOIN dd_graph_variables_observation t2 ON t0.id=t2.variable_id
09:38:24.311 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] DEBUG Executing queries by file: psql  -d deepdive_test  -U jackywang  -p 5432  -h localhost  -c 'COPY (SELECT t0.id, t1.__dd_variable_type__,
        CASE WHEN t1.__dd_variable_type__ = 0 THEN 0 ELSE is_correct::int::float END AS initvalue,
        0 AS type, 2 AS cardinality
        FROM r1 t0, r1_vtype t1
        WHERE t0.id=t1.id) TO STDOUT;'   > /Users/jackywang/Desktop/341/project/deepdive/out/dd_variables_r1
09:38:24.311 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/exec_sql4821033830501821492.sh" 
09:38:24.347 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: INSERT INTO dd_graph_variables_holdout
            SELECT id FROM r2
            WHERE RANDOM() < 0.0 AND is_correct IS NOT NULL
09:38:24.348 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS r2_is_correct_cardinality CASCADE
09:38:24.348 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE r2_is_correct_cardinality(cardinality text)
09:38:24.350 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: INSERT INTO r2_is_correct_cardinality VALUES ('00001')
09:38:24.351 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS r2_vtype CASCADE
09:38:24.351 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE r2_vtype AS
        SELECT t0.id, CASE WHEN t2.variable_id IS NOT NULL AND is_correct IS NOT NULL THEN 2
                           WHEN t1.variable_id IS NOT NULL THEN 0
                           WHEN is_correct IS NOT NULL THEN 1
                           ELSE 0
                      END as __dd_variable_type__
        FROM r2 t0 LEFT OUTER JOIN dd_graph_variables_holdout t1 
        ON t0.id=t1.variable_id LEFT OUTER JOIN dd_graph_variables_observation t2 ON t0.id=t2.variable_id
09:38:24.354 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] DEBUG Executing queries by file: psql  -d deepdive_test  -U jackywang  -p 5432  -h localhost  -c 'COPY (SELECT t0.id, t1.__dd_variable_type__,
        CASE WHEN t1.__dd_variable_type__ = 0 THEN 0 ELSE is_correct::int::float END AS initvalue,
        0 AS type, 2 AS cardinality
        FROM r2 t0, r2_vtype t1
        WHERE t0.id=t1.id) TO STDOUT;'   > /Users/jackywang/Desktop/341/project/deepdive/out/dd_variables_r2
09:38:24.354 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/exec_sql5291906596358378578.sh" 
09:38:24.392 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_graph_factormeta CASCADE
09:38:24.392 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_graph_factormeta (name text, funcid int, sign text)
09:38:24.394 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: INSERT INTO dd_graph_factormeta VALUES ('testFactor', 2, 'true true')
09:38:24.395 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] DEBUG Executing queries by file: psql  -d deepdive_test  -U jackywang  -p 5432  -h localhost  -c 'COPY (SELECT * FROM dd_graph_factormeta) TO STDOUT;'   > /Users/jackywang/Desktop/341/project/deepdive/out/dd_factormeta
09:38:24.395 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/exec_sql1974178282570291571.sh" 
09:38:24.433 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_graph_weights CASCADE
09:38:24.434 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_graph_weights (id bigint, isfixed int, initvalue real, 
      cardinality text, description text)
09:38:24.436 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP SEQUENCE IF EXISTS dd_weight_sequence CASCADE
09:38:24.437 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE SEQUENCE dd_weight_sequence MINVALUE -1 START 0
09:38:24.440 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP SEQUENCE IF EXISTS dd_factor_sequence CASCADE
09:38:24.440 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE SEQUENCE dd_factor_sequence MINVALUE -1 START 0
09:38:24.441 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_feature_statistics_support CASCADE
09:38:24.442 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_feature_statistics_support(
            description text, 
            pos_examples bigint, 
            neg_examples bigint, 
            queries bigint)
09:38:24.445 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_query_testFactor CASCADE
09:38:24.445 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_query_testFactor AS SELECT r1.id AS "r1.id", r1.weight AS "weight", r1.is_correct AS "r1.is_correct",
          r2.id AS "r2.id", r2.is_correct AS "r2.is_correct" FROM r1, r2
          WHERE r1.id = (r2.id-100)
09:38:24.448 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: ALTER TABLE dd_query_testFactor ADD COLUMN id bigint
09:38:24.449 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: UPDATE dd_query_testFactor SET id =  nextval('dd_factor_sequence')
09:38:24.453 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing SQL with callback... SELECT COUNT(*) FROM dd_query_testFactor;
09:38:24.454 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_weights_testFactor CASCADE
09:38:24.454 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_weights_testFactor AS
              SELECT  "weight" , false::int AS isfixed, 0.0::float AS initvalue, 
                0::bigint AS id
              FROM dd_query_testFactor
              GROUP BY  "weight"
09:38:24.457 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: UPDATE dd_weights_testFactor SET id =  nextval('dd_weight_sequence')
09:38:24.460 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing SQL with callback... SELECT COUNT(*) FROM dd_weights_testFactor;
09:38:24.461 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: INSERT INTO dd_graph_weights(id, isfixed, initvalue, description) 
            SELECT id, isfixed, initvalue, 'weight_prefix-'  || (CASE WHEN "weight" IS NULL THEN '' ELSE "weight"::text END) FROM dd_weights_testFactor
09:38:24.463 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing SQL with callback... SELECT COUNT(*) FROM dd_query_testFactor WHERE  "weight" IS NULL 
09:38:24.464 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] DEBUG Executing queries by file: psql  -d deepdive_test  -U jackywang  -p 5432  -h localhost  -c 'COPY (SELECT t0.id AS factor_id, t1.id AS weight_id,  "r1.id" ,  "r2.id"
             FROM dd_query_testFactor t0, dd_weights_testFactor t1
             WHERE  t0."weight" = t1."weight") TO STDOUT;'   > /Users/jackywang/Desktop/341/project/deepdive/out/dd_factors_testFactor_out
09:38:24.464 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/exec_sql7012315113564632797.sh" 
09:38:24.504 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] DEBUG Executing queries by file: psql  -d deepdive_test  -U jackywang  -p 5432  -h localhost  -c 'COPY (SELECT id, isfixed, COALESCE(initvalue, 0) FROM dd_graph_weights) TO STDOUT;'   > /Users/jackywang/Desktop/341/project/deepdive/out/dd_weights
09:38:24.504 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/exec_sql8654046667098122192.sh" 
09:38:24.541 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_inference_result_variables CASCADE
09:38:24.542 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_inference_result_variables(
      id bigint, 
      category bigint, 
      expectation double precision)
09:38:24.543 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_inference_result_weights CASCADE
09:38:24.544 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_inference_result_weights(
      id bigint primary key, 
      weight double precision)
09:38:24.546 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  Converting grounding file format...
09:38:24.546 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] DEBUG Executing: python /Users/jackywang/Desktop/341/project/deepdive/util/tobinary.py /Users/jackywang/Desktop/341/project/deepdive/out /Users/jackywang/Desktop/341/project/deepdive/util/format_converter_mac /Users/jackywang/Desktop/341/project/deepdive/out
09:38:24.876 [Thread-114][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  SPLITTING testFactor ...
09:38:24.876 [Thread-114][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  BINARIZE  testFactor ...
09:38:24.876 [Thread-114][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  SPLITTING dd_variables_r1 ...
09:38:24.876 [Thread-114][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  BINARIZE  dd_variables_r1 ...
09:38:24.876 [Thread-114][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  SPLITTING dd_variables_r2 ...
09:38:24.876 [Thread-114][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  BINARIZE  dd_variables_r2 ...
09:38:24.876 [Thread-114][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  BINARIZE  weights ...
09:38:24.876 [Thread-114][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  COUNTING variables ...
09:38:24.876 [Thread-114][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  COUNTING factors ...
09:38:24.876 [Thread-114][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  COUNTING weights ...
09:38:24.876 [Thread-114][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  CONCATENATING FILES...
09:38:24.877 [Thread-114][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  Cleaning up files
09:38:24.880 [ScalaTest-running-PostgresInferenceDataStoreSpec][JdbcDataStore$(akka://deepdive)][JdbcDataStore$] INFO  Closing all JDBC data stores
09:38:24.880 [ScalaTest-running-PostgresInferenceDataStoreSpec][JdbcDataStore$(akka://deepdive)][JdbcDataStore$] INFO  Intializing all JDBC data stores
09:38:25.035 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing SQL with callback... 
    SELECT version() LIKE '%Greenplum%';
  
09:38:25.036 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  Using Greenplum = false
09:38:25.036 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  Datastore type = psql
09:38:25.036 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  Parallel grounding = false
09:38:25.036 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] DEBUG Grounding Path = /Users/jackywang/Desktop/341/project/deepdive/out
09:38:25.036 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing SQL with callback... 
    SELECT version() LIKE '%Greenplum%';
  
09:38:25.036 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP SEQUENCE IF EXISTS dd_variable_sequence CASCADE
09:38:25.037 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE SEQUENCE dd_variable_sequence MINVALUE -1 START 0
09:38:25.040 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: UPDATE r1 SET id =  nextval('dd_variable_sequence')
09:38:25.042 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_graph_variables_holdout CASCADE
09:38:25.042 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_graph_variables_holdout(variable_id bigint primary key)
09:38:25.044 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_graph_variables_observation CASCADE
09:38:25.044 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_graph_variables_observation(variable_id bigint primary key)
09:38:25.047 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: INSERT INTO dd_graph_variables_holdout
            SELECT id FROM r1
            WHERE RANDOM() < 0.0 AND value IS NOT NULL
09:38:25.049 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS r1_value_cardinality CASCADE
09:38:25.049 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE r1_value_cardinality(cardinality text)
09:38:25.051 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: INSERT INTO r1_value_cardinality VALUES ('00000'), ('00001'), ('00002'), ('00003')
09:38:25.052 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS r1_vtype CASCADE
09:38:25.053 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE r1_vtype AS
        SELECT t0.id, CASE WHEN t2.variable_id IS NOT NULL AND value IS NOT NULL THEN 2
                           WHEN t1.variable_id IS NOT NULL THEN 0
                           WHEN value IS NOT NULL THEN 1
                           ELSE 0
                      END as __dd_variable_type__
        FROM r1 t0 LEFT OUTER JOIN dd_graph_variables_holdout t1 
        ON t0.id=t1.variable_id LEFT OUTER JOIN dd_graph_variables_observation t2 ON t0.id=t2.variable_id
09:38:25.058 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] DEBUG Executing queries by file: psql  -d deepdive_test  -U jackywang  -p 5432  -h localhost  -c 'COPY (SELECT t0.id, t1.__dd_variable_type__,
        CASE WHEN t1.__dd_variable_type__ = 0 THEN 0 ELSE value::int::float END AS initvalue,
        1 AS type, 4 AS cardinality
        FROM r1 t0, r1_vtype t1
        WHERE t0.id=t1.id) TO STDOUT;'   > /Users/jackywang/Desktop/341/project/deepdive/out/dd_variables_r1
09:38:25.058 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/exec_sql4032554543559879976.sh" 
09:38:25.093 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_graph_factormeta CASCADE
09:38:25.093 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_graph_factormeta (name text, funcid int, sign text)
09:38:25.095 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: INSERT INTO dd_graph_factormeta VALUES ('testFactor', 5, 'true')
09:38:25.097 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] DEBUG Executing queries by file: psql  -d deepdive_test  -U jackywang  -p 5432  -h localhost  -c 'COPY (SELECT * FROM dd_graph_factormeta) TO STDOUT;'   > /Users/jackywang/Desktop/341/project/deepdive/out/dd_factormeta
09:38:25.097 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/exec_sql3463983989062951284.sh" 
09:38:25.129 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_graph_weights CASCADE
09:38:25.129 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_graph_weights (id bigint, isfixed int, initvalue real, 
      cardinality text, description text)
09:38:25.132 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP SEQUENCE IF EXISTS dd_weight_sequence CASCADE
09:38:25.132 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE SEQUENCE dd_weight_sequence MINVALUE -1 START 0
09:38:25.134 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP SEQUENCE IF EXISTS dd_factor_sequence CASCADE
09:38:25.134 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE SEQUENCE dd_factor_sequence MINVALUE -1 START 0
09:38:25.135 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_feature_statistics_support CASCADE
09:38:25.135 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_feature_statistics_support(
            description text, 
            pos_examples bigint, 
            neg_examples bigint, 
            queries bigint)
09:38:25.137 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_query_testFactor CASCADE
09:38:25.138 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_query_testFactor AS SELECT id AS "r1.id", weight AS "weight", value AS "r1.value" FROM r1
09:38:25.141 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: ALTER TABLE dd_query_testFactor ADD COLUMN id bigint
09:38:25.142 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: UPDATE dd_query_testFactor SET id =  nextval('dd_factor_sequence')
09:38:25.144 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing SQL with callback... SELECT COUNT(*) FROM dd_query_testFactor;
09:38:25.146 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS weight_prefix_cardinality_0 CASCADE
09:38:25.147 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE  weight_prefix_cardinality_0 AS
            SELECT * FROM r1_value_cardinality
09:38:25.151 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_weights_testFactor CASCADE
09:38:25.151 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_weights_testFactor AS
            SELECT false::int AS isfixed, 0.0 AS initvalue, _c0.cardinality AS cardinality, 0 AS id
            FROM weight_prefix_cardinality_0 AS _c0
            ORDER BY cardinality
09:38:25.155 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: UPDATE dd_weights_testFactor SET id =  nextval('dd_weight_sequence')
09:38:25.158 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: INSERT INTO dd_graph_weights(id, isfixed, initvalue, cardinality, description) 
            SELECT id, isfixed, initvalue, cardinality, 'weight_prefix-'  FROM dd_weights_testFactor
09:38:25.159 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] DEBUG Executing queries by file: psql  -d deepdive_test  -U jackywang  -p 5432  -h localhost  -c 'COPY (SELECT id AS factor_id, 0 AS weight_id,  "r1.id"  FROM dd_query_testFactor) TO STDOUT;'   > /Users/jackywang/Desktop/341/project/deepdive/out/dd_factors_testFactor_out
09:38:25.159 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/exec_sql3751349959189670162.sh" 
09:38:25.191 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing SQL with callback... SELECT COUNT(*) FROM dd_weights_testFactor;
09:38:25.192 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] DEBUG Executing queries by file: psql  -d deepdive_test  -U jackywang  -p 5432  -h localhost  -c 'COPY (SELECT id, isfixed, COALESCE(initvalue, 0) FROM dd_graph_weights) TO STDOUT;'   > /Users/jackywang/Desktop/341/project/deepdive/out/dd_weights
09:38:25.192 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/exec_sql8932637126600144622.sh" 
09:38:25.223 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_inference_result_variables CASCADE
09:38:25.224 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_inference_result_variables(
      id bigint, 
      category bigint, 
      expectation double precision)
09:38:25.225 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_inference_result_weights CASCADE
09:38:25.225 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_inference_result_weights(
      id bigint primary key, 
      weight double precision)
09:38:25.227 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  Converting grounding file format...
09:38:25.227 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] DEBUG Executing: python /Users/jackywang/Desktop/341/project/deepdive/util/tobinary.py /Users/jackywang/Desktop/341/project/deepdive/out /Users/jackywang/Desktop/341/project/deepdive/util/format_converter_mac /Users/jackywang/Desktop/341/project/deepdive/out
09:38:25.499 [Thread-129][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  SPLITTING testFactor ...
09:38:25.499 [Thread-129][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  BINARIZE  testFactor ...
09:38:25.499 [Thread-129][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  SPLITTING dd_variables_r1 ...
09:38:25.499 [Thread-129][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  BINARIZE  dd_variables_r1 ...
09:38:25.500 [Thread-129][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  BINARIZE  weights ...
09:38:25.500 [Thread-129][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  COUNTING variables ...
09:38:25.500 [Thread-129][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  COUNTING factors ...
09:38:25.500 [Thread-129][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  COUNTING weights ...
09:38:25.500 [Thread-129][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  CONCATENATING FILES...
09:38:25.500 [Thread-129][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  Cleaning up files
09:38:25.502 [ScalaTest-running-PostgresInferenceDataStoreSpec][JdbcDataStore$(akka://deepdive)][JdbcDataStore$] INFO  Closing all JDBC data stores
09:38:25.503 [ScalaTest-running-PostgresInferenceDataStoreSpec][JdbcDataStore$(akka://deepdive)][JdbcDataStore$] INFO  Intializing all JDBC data stores
09:38:25.652 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing SQL with callback... 
    SELECT version() LIKE '%Greenplum%';
  
09:38:25.653 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  Using Greenplum = false
09:38:25.653 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  Datastore type = psql
09:38:25.653 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  Parallel grounding = false
09:38:25.653 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] DEBUG Grounding Path = /Users/jackywang/Desktop/341/project/deepdive/out
09:38:25.653 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing SQL with callback... 
    SELECT version() LIKE '%Greenplum%';
  
09:38:25.653 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP SEQUENCE IF EXISTS dd_variable_sequence CASCADE
09:38:25.654 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE SEQUENCE dd_variable_sequence MINVALUE -1 START 0
09:38:25.656 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: UPDATE r1 SET id =  nextval('dd_variable_sequence')
09:38:25.657 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_graph_variables_holdout CASCADE
09:38:25.657 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_graph_variables_holdout(variable_id bigint primary key)
09:38:25.660 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_graph_variables_observation CASCADE
09:38:25.660 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_graph_variables_observation(variable_id bigint primary key)
09:38:25.662 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: INSERT INTO dd_graph_variables_holdout
            SELECT id FROM r1
            WHERE RANDOM() < 0.0 AND value IS NOT NULL
09:38:25.663 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS r1_value_cardinality CASCADE
09:38:25.664 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE r1_value_cardinality(cardinality text)
09:38:25.667 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: INSERT INTO r1_value_cardinality VALUES ('00000'), ('00001'), ('00002'), ('00003')
09:38:25.668 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS r1_vtype CASCADE
09:38:25.669 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE r1_vtype AS
        SELECT t0.id, CASE WHEN t2.variable_id IS NOT NULL AND value IS NOT NULL THEN 2
                           WHEN t1.variable_id IS NOT NULL THEN 0
                           WHEN value IS NOT NULL THEN 1
                           ELSE 0
                      END as __dd_variable_type__
        FROM r1 t0 LEFT OUTER JOIN dd_graph_variables_holdout t1 
        ON t0.id=t1.variable_id LEFT OUTER JOIN dd_graph_variables_observation t2 ON t0.id=t2.variable_id
09:38:25.675 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] DEBUG Executing queries by file: psql  -d deepdive_test  -U jackywang  -p 5432  -h localhost  -c 'COPY (SELECT t0.id, t1.__dd_variable_type__,
        CASE WHEN t1.__dd_variable_type__ = 0 THEN 0 ELSE value::int::float END AS initvalue,
        1 AS type, 4 AS cardinality
        FROM r1 t0, r1_vtype t1
        WHERE t0.id=t1.id) TO STDOUT;'   > /Users/jackywang/Desktop/341/project/deepdive/out/dd_variables_r1
09:38:25.676 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/exec_sql3608961386960652623.sh" 
09:38:25.716 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_graph_factormeta CASCADE
09:38:25.716 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_graph_factormeta (name text, funcid int, sign text)
09:38:25.718 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: INSERT INTO dd_graph_factormeta VALUES ('testFactor', 5, 'true')
09:38:25.720 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] DEBUG Executing queries by file: psql  -d deepdive_test  -U jackywang  -p 5432  -h localhost  -c 'COPY (SELECT * FROM dd_graph_factormeta) TO STDOUT;'   > /Users/jackywang/Desktop/341/project/deepdive/out/dd_factormeta
09:38:25.720 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/exec_sql8082191469714893990.sh" 
09:38:25.754 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_graph_weights CASCADE
09:38:25.754 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_graph_weights (id bigint, isfixed int, initvalue real, 
      cardinality text, description text)
09:38:25.757 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP SEQUENCE IF EXISTS dd_weight_sequence CASCADE
09:38:25.757 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE SEQUENCE dd_weight_sequence MINVALUE -1 START 0
09:38:25.758 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP SEQUENCE IF EXISTS dd_factor_sequence CASCADE
09:38:25.758 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE SEQUENCE dd_factor_sequence MINVALUE -1 START 0
09:38:25.760 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_feature_statistics_support CASCADE
09:38:25.760 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_feature_statistics_support(
            description text, 
            pos_examples bigint, 
            neg_examples bigint, 
            queries bigint)
09:38:25.762 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_query_testFactor CASCADE
09:38:25.762 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_query_testFactor AS SELECT id AS "r1.id", weight AS "weight", value AS "r1.value" FROM r1
09:38:25.778 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: ALTER TABLE dd_query_testFactor ADD COLUMN id bigint
09:38:25.779 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: UPDATE dd_query_testFactor SET id =  nextval('dd_factor_sequence')
09:38:25.782 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing SQL with callback... SELECT COUNT(*) FROM dd_query_testFactor;
09:38:25.782 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS weight_prefix_cardinality_0 CASCADE
09:38:25.783 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE  weight_prefix_cardinality_0 AS
            SELECT * FROM r1_value_cardinality
09:38:25.785 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_weight_testFactor_temp CASCADE
09:38:25.786 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_weight_testFactor_temp AS
                      SELECT  "weight" , false::int AS isfixed, 0.0::float AS initvalue
                      FROM dd_query_testFactor
                      GROUP BY  "weight"
09:38:25.789 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_weights_testFactor CASCADE
09:38:25.789 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_weights_testFactor AS 
            SELECT dd_weight_testFactor_temp.*, _c0.cardinality AS cardinality
            FROM dd_weight_testFactor_temp, weight_prefix_cardinality_0 AS _c0 LIMIT 0
09:38:25.794 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_weights_testFactor_unsorted CASCADE
09:38:25.795 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_weights_testFactor_unsorted AS 
            SELECT dd_weight_testFactor_temp.*, _c0.cardinality AS cardinality
            FROM dd_weight_testFactor_temp, weight_prefix_cardinality_0 AS _c0 LIMIT 0
09:38:25.797 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: ALTER TABLE dd_weights_testFactor ADD COLUMN id bigint
09:38:25.798 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: ALTER TABLE dd_weights_testFactor_unsorted ADD COLUMN id bigint
09:38:25.799 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: INSERT INTO dd_weights_testFactor_unsorted
            SELECT dd_weight_testFactor_temp.*, _c0.cardinality as cardinality, 0 AS id
            FROM dd_weight_testFactor_temp, weight_prefix_cardinality_0 AS _c0
            ORDER BY  "weight" , cardinality
09:38:25.800 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: INSERT INTO dd_weights_testFactor
            SELECT * FROM dd_weights_testFactor_unsorted
            ORDER BY  "weight" , cardinality
09:38:25.801 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: UPDATE dd_weights_testFactor SET id =  nextval('dd_weight_sequence')
09:38:25.803 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing SQL with callback... SELECT COUNT(*) FROM dd_weights_testFactor;
09:38:25.803 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: INSERT INTO dd_graph_weights(id, isfixed, initvalue, cardinality, description) 
            SELECT id, isfixed, initvalue, cardinality, 'weight_prefix-'  || (CASE WHEN "weight" IS NULL THEN '' ELSE "weight"::text END) FROM dd_weights_testFactor
09:38:25.806 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] DEBUG Executing queries by file: psql  -d deepdive_test  -U jackywang  -p 5432  -h localhost  -c 'COPY (SELECT t0.id AS factor_id, t1.id AS weight_id,  "r1.id"
             FROM dd_query_testFactor t0, dd_weights_testFactor t1
             WHERE  t0."weight" = t1."weight"  AND t1.cardinality = '\''00000'\'') TO STDOUT;'   > /Users/jackywang/Desktop/341/project/deepdive/out/dd_factors_testFactor_out
09:38:25.806 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/exec_sql2084329901240948767.sh" 
09:38:25.845 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] DEBUG Executing queries by file: psql  -d deepdive_test  -U jackywang  -p 5432  -h localhost  -c 'COPY (SELECT id, isfixed, COALESCE(initvalue, 0) FROM dd_graph_weights) TO STDOUT;'   > /Users/jackywang/Desktop/341/project/deepdive/out/dd_weights
09:38:25.845 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/exec_sql6311628289270885744.sh" 
09:38:25.880 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_inference_result_variables CASCADE
09:38:25.880 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_inference_result_variables(
      id bigint, 
      category bigint, 
      expectation double precision)
09:38:25.882 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_inference_result_weights CASCADE
09:38:25.882 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_inference_result_weights(
      id bigint primary key, 
      weight double precision)
09:38:25.884 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  Converting grounding file format...
09:38:25.884 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] DEBUG Executing: python /Users/jackywang/Desktop/341/project/deepdive/util/tobinary.py /Users/jackywang/Desktop/341/project/deepdive/out /Users/jackywang/Desktop/341/project/deepdive/util/format_converter_mac /Users/jackywang/Desktop/341/project/deepdive/out
09:38:26.153 [Thread-144][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  SPLITTING testFactor ...
09:38:26.153 [Thread-144][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  BINARIZE  testFactor ...
09:38:26.153 [Thread-144][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  SPLITTING dd_variables_r1 ...
09:38:26.154 [Thread-144][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  BINARIZE  dd_variables_r1 ...
09:38:26.154 [Thread-144][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  BINARIZE  weights ...
09:38:26.154 [Thread-144][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  COUNTING variables ...
09:38:26.154 [Thread-144][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  COUNTING factors ...
09:38:26.154 [Thread-144][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  COUNTING weights ...
09:38:26.154 [Thread-144][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  CONCATENATING FILES...
09:38:26.154 [Thread-144][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  Cleaning up files
09:38:26.157 [ScalaTest-running-PostgresInferenceDataStoreSpec][JdbcDataStore$(akka://deepdive)][JdbcDataStore$] INFO  Closing all JDBC data stores
09:38:26.157 [ScalaTest-running-PostgresInferenceDataStoreSpec][JdbcDataStore$(akka://deepdive)][JdbcDataStore$] INFO  Intializing all JDBC data stores
09:38:26.318 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing SQL with callback... 
    SELECT version() LIKE '%Greenplum%';
  
09:38:26.318 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  Using Greenplum = false
09:38:26.319 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  Datastore type = psql
09:38:26.319 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  Parallel grounding = false
09:38:26.319 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] DEBUG Grounding Path = /Users/jackywang/Desktop/341/project/deepdive/out
09:38:26.319 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing SQL with callback... 
    SELECT version() LIKE '%Greenplum%';
  
09:38:26.319 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP SEQUENCE IF EXISTS dd_variable_sequence CASCADE
09:38:26.319 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE SEQUENCE dd_variable_sequence MINVALUE -1 START 0
09:38:26.321 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: UPDATE r1 SET id =  nextval('dd_variable_sequence')
09:38:26.323 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_graph_variables_holdout CASCADE
09:38:26.323 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_graph_variables_holdout(variable_id bigint primary key)
09:38:26.325 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_graph_variables_observation CASCADE
09:38:26.325 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_graph_variables_observation(variable_id bigint primary key)
09:38:26.327 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: INSERT INTO dd_graph_variables_holdout
            SELECT id FROM r1
            WHERE RANDOM() < 0.0 AND value IS NOT NULL
09:38:26.328 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS r1_value_cardinality CASCADE
09:38:26.328 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE r1_value_cardinality(cardinality text)
09:38:26.330 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: INSERT INTO r1_value_cardinality VALUES ('00000'), ('00001'), ('00002'), ('00003')
09:38:26.331 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS r1_vtype CASCADE
09:38:26.332 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE r1_vtype AS
        SELECT t0.id, CASE WHEN t2.variable_id IS NOT NULL AND value IS NOT NULL THEN 2
                           WHEN t1.variable_id IS NOT NULL THEN 0
                           WHEN value IS NOT NULL THEN 1
                           ELSE 0
                      END as __dd_variable_type__
        FROM r1 t0 LEFT OUTER JOIN dd_graph_variables_holdout t1 
        ON t0.id=t1.variable_id LEFT OUTER JOIN dd_graph_variables_observation t2 ON t0.id=t2.variable_id
09:38:26.338 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] DEBUG Executing queries by file: psql  -d deepdive_test  -U jackywang  -p 5432  -h localhost  -c 'COPY (SELECT t0.id, t1.__dd_variable_type__,
        CASE WHEN t1.__dd_variable_type__ = 0 THEN 0 ELSE value::int::float END AS initvalue,
        1 AS type, 4 AS cardinality
        FROM r1 t0, r1_vtype t1
        WHERE t0.id=t1.id) TO STDOUT;'   > /Users/jackywang/Desktop/341/project/deepdive/out/dd_variables_r1
09:38:26.338 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/exec_sql4253567877284546393.sh" 
09:38:26.375 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_graph_factormeta CASCADE
09:38:26.375 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_graph_factormeta (name text, funcid int, sign text)
09:38:26.379 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: INSERT INTO dd_graph_factormeta VALUES ('testFactor', 5, 'true')
09:38:26.381 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] DEBUG Executing queries by file: psql  -d deepdive_test  -U jackywang  -p 5432  -h localhost  -c 'COPY (SELECT * FROM dd_graph_factormeta) TO STDOUT;'   > /Users/jackywang/Desktop/341/project/deepdive/out/dd_factormeta
09:38:26.381 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/exec_sql1607845724722608868.sh" 
09:38:26.413 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_graph_weights CASCADE
09:38:26.413 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_graph_weights (id bigint, isfixed int, initvalue real, 
      cardinality text, description text)
09:38:26.415 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP SEQUENCE IF EXISTS dd_weight_sequence CASCADE
09:38:26.415 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE SEQUENCE dd_weight_sequence MINVALUE -1 START 0
09:38:26.416 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP SEQUENCE IF EXISTS dd_factor_sequence CASCADE
09:38:26.417 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE SEQUENCE dd_factor_sequence MINVALUE -1 START 0
09:38:26.418 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_feature_statistics_support CASCADE
09:38:26.418 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_feature_statistics_support(
            description text, 
            pos_examples bigint, 
            neg_examples bigint, 
            queries bigint)
09:38:26.420 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_query_testFactor CASCADE
09:38:26.420 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_query_testFactor AS SELECT id AS "r1.id", value AS "r1.value" FROM r1
09:38:26.422 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: ALTER TABLE dd_query_testFactor ADD COLUMN id bigint
09:38:26.422 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: UPDATE dd_query_testFactor SET id =  nextval('dd_factor_sequence')
09:38:26.425 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing SQL with callback... SELECT COUNT(*) FROM dd_query_testFactor;
09:38:26.426 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS weight_prefix_cardinality_0 CASCADE
09:38:26.426 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE  weight_prefix_cardinality_0 AS
            SELECT * FROM r1_value_cardinality
09:38:26.429 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_weights_testFactor CASCADE
09:38:26.429 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_weights_testFactor AS
            SELECT true::int AS isfixed, 0.37 AS initvalue, _c0.cardinality AS cardinality, 0 AS id
            FROM weight_prefix_cardinality_0 AS _c0
            ORDER BY cardinality
09:38:26.433 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: UPDATE dd_weights_testFactor SET id =  nextval('dd_weight_sequence')
09:38:26.435 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: INSERT INTO dd_graph_weights(id, isfixed, initvalue, cardinality, description) 
            SELECT id, isfixed, initvalue, cardinality, 'weight_prefix-'  FROM dd_weights_testFactor
09:38:26.438 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] DEBUG Executing queries by file: psql  -d deepdive_test  -U jackywang  -p 5432  -h localhost  -c 'COPY (SELECT id AS factor_id, 0 AS weight_id,  "r1.id"  FROM dd_query_testFactor) TO STDOUT;'   > /Users/jackywang/Desktop/341/project/deepdive/out/dd_factors_testFactor_out
09:38:26.438 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/exec_sql1297033945379761490.sh" 
09:38:26.470 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing SQL with callback... SELECT COUNT(*) FROM dd_weights_testFactor;
09:38:26.471 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] DEBUG Executing queries by file: psql  -d deepdive_test  -U jackywang  -p 5432  -h localhost  -c 'COPY (SELECT id, isfixed, COALESCE(initvalue, 0) FROM dd_graph_weights) TO STDOUT;'   > /Users/jackywang/Desktop/341/project/deepdive/out/dd_weights
09:38:26.471 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/exec_sql1349271293413889306.sh" 
09:38:26.503 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_inference_result_variables CASCADE
09:38:26.503 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_inference_result_variables(
      id bigint, 
      category bigint, 
      expectation double precision)
09:38:26.504 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_inference_result_weights CASCADE
09:38:26.505 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_inference_result_weights(
      id bigint primary key, 
      weight double precision)
09:38:26.507 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  Converting grounding file format...
09:38:26.507 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] DEBUG Executing: python /Users/jackywang/Desktop/341/project/deepdive/util/tobinary.py /Users/jackywang/Desktop/341/project/deepdive/out /Users/jackywang/Desktop/341/project/deepdive/util/format_converter_mac /Users/jackywang/Desktop/341/project/deepdive/out
09:38:26.775 [Thread-159][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  SPLITTING testFactor ...
09:38:26.775 [Thread-159][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  BINARIZE  testFactor ...
09:38:26.775 [Thread-159][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  SPLITTING dd_variables_r1 ...
09:38:26.775 [Thread-159][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  BINARIZE  dd_variables_r1 ...
09:38:26.775 [Thread-159][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  BINARIZE  weights ...
09:38:26.775 [Thread-159][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  COUNTING variables ...
09:38:26.775 [Thread-159][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  COUNTING factors ...
09:38:26.775 [Thread-159][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  COUNTING weights ...
09:38:26.775 [Thread-159][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  CONCATENATING FILES...
09:38:26.775 [Thread-159][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  Cleaning up files
09:38:26.779 [ScalaTest-running-PostgresInferenceDataStoreSpec][JdbcDataStore$(akka://deepdive)][JdbcDataStore$] INFO  Closing all JDBC data stores
09:38:26.779 [ScalaTest-running-PostgresInferenceDataStoreSpec][JdbcDataStore$(akka://deepdive)][JdbcDataStore$] INFO  Intializing all JDBC data stores
09:38:26.930 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing SQL with callback... 
    SELECT version() LIKE '%Greenplum%';
  
09:38:26.930 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  Using Greenplum = false
09:38:26.930 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  Datastore type = psql
09:38:26.930 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  Parallel grounding = false
09:38:26.931 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] DEBUG Grounding Path = /Users/jackywang/Desktop/341/project/deepdive/out
09:38:26.931 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing SQL with callback... 
    SELECT version() LIKE '%Greenplum%';
  
09:38:26.931 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP SEQUENCE IF EXISTS dd_variable_sequence CASCADE
09:38:26.931 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE SEQUENCE dd_variable_sequence MINVALUE -1 START 0
09:38:26.933 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: UPDATE r1 SET id =  nextval('dd_variable_sequence')
09:38:26.934 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_graph_variables_holdout CASCADE
09:38:26.935 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_graph_variables_holdout(variable_id bigint primary key)
09:38:26.937 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_graph_variables_observation CASCADE
09:38:26.937 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_graph_variables_observation(variable_id bigint primary key)
09:38:26.939 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: INSERT INTO dd_graph_variables_holdout
            SELECT id FROM r1
            WHERE RANDOM() < 0.0 AND value IS NOT NULL
09:38:26.941 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS r1_value_cardinality CASCADE
09:38:26.941 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE r1_value_cardinality(cardinality text)
09:38:26.943 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: INSERT INTO r1_value_cardinality VALUES ('00000'), ('00001'), ('00002'), ('00003')
09:38:26.944 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS r1_vtype CASCADE
09:38:26.945 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE r1_vtype AS
        SELECT t0.id, CASE WHEN t2.variable_id IS NOT NULL AND value IS NOT NULL THEN 2
                           WHEN t1.variable_id IS NOT NULL THEN 0
                           WHEN value IS NOT NULL THEN 1
                           ELSE 0
                      END as __dd_variable_type__
        FROM r1 t0 LEFT OUTER JOIN dd_graph_variables_holdout t1 
        ON t0.id=t1.variable_id LEFT OUTER JOIN dd_graph_variables_observation t2 ON t0.id=t2.variable_id
09:38:26.950 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] DEBUG Executing queries by file: psql  -d deepdive_test  -U jackywang  -p 5432  -h localhost  -c 'COPY (SELECT t0.id, t1.__dd_variable_type__,
        CASE WHEN t1.__dd_variable_type__ = 0 THEN 0 ELSE value::int::float END AS initvalue,
        1 AS type, 4 AS cardinality
        FROM r1 t0, r1_vtype t1
        WHERE t0.id=t1.id) TO STDOUT;'   > /Users/jackywang/Desktop/341/project/deepdive/out/dd_variables_r1
09:38:26.951 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/exec_sql2800460073390076725.sh" 
09:38:26.985 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_graph_factormeta CASCADE
09:38:26.985 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_graph_factormeta (name text, funcid int, sign text)
09:38:26.987 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: INSERT INTO dd_graph_factormeta VALUES ('testFactor', 5, 'true')
09:38:26.988 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] DEBUG Executing queries by file: psql  -d deepdive_test  -U jackywang  -p 5432  -h localhost  -c 'COPY (SELECT * FROM dd_graph_factormeta) TO STDOUT;'   > /Users/jackywang/Desktop/341/project/deepdive/out/dd_factormeta
09:38:26.988 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/exec_sql6560449140429459349.sh" 
09:38:27.019 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_graph_weights CASCADE
09:38:27.020 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_graph_weights (id bigint, isfixed int, initvalue real, 
      cardinality text, description text)
09:38:27.022 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP SEQUENCE IF EXISTS dd_weight_sequence CASCADE
09:38:27.022 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE SEQUENCE dd_weight_sequence MINVALUE -1 START 0
09:38:27.025 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP SEQUENCE IF EXISTS dd_factor_sequence CASCADE
09:38:27.026 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE SEQUENCE dd_factor_sequence MINVALUE -1 START 0
09:38:27.027 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_feature_statistics_support CASCADE
09:38:27.027 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_feature_statistics_support(
            description text, 
            pos_examples bigint, 
            neg_examples bigint, 
            queries bigint)
09:38:27.029 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_query_testFactor CASCADE
09:38:27.029 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_query_testFactor AS SELECT id AS "r1.id", value AS "r1.value" FROM r1
09:38:27.032 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: ALTER TABLE dd_query_testFactor ADD COLUMN id bigint
09:38:27.033 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: UPDATE dd_query_testFactor SET id =  nextval('dd_factor_sequence')
09:38:27.036 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing SQL with callback... SELECT COUNT(*) FROM dd_query_testFactor;
09:38:27.036 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS weight_prefix_cardinality_0 CASCADE
09:38:27.037 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE  weight_prefix_cardinality_0 AS
            SELECT * FROM r1_value_cardinality
09:38:27.039 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_weights_testFactor CASCADE
09:38:27.040 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_weights_testFactor AS
            SELECT false::int AS isfixed, 0.0 AS initvalue, _c0.cardinality AS cardinality, 0 AS id
            FROM weight_prefix_cardinality_0 AS _c0
            ORDER BY cardinality
09:38:27.044 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: UPDATE dd_weights_testFactor SET id =  nextval('dd_weight_sequence')
09:38:27.046 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: INSERT INTO dd_graph_weights(id, isfixed, initvalue, cardinality, description) 
            SELECT id, isfixed, initvalue, cardinality, 'weight_prefix-'  FROM dd_weights_testFactor
09:38:27.047 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] DEBUG Executing queries by file: psql  -d deepdive_test  -U jackywang  -p 5432  -h localhost  -c 'COPY (SELECT id AS factor_id, 0 AS weight_id,  "r1.id"  FROM dd_query_testFactor) TO STDOUT;'   > /Users/jackywang/Desktop/341/project/deepdive/out/dd_factors_testFactor_out
09:38:27.047 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/exec_sql6253574918438136230.sh" 
09:38:27.079 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing SQL with callback... SELECT COUNT(*) FROM dd_weights_testFactor;
09:38:27.080 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] DEBUG Executing queries by file: psql  -d deepdive_test  -U jackywang  -p 5432  -h localhost  -c 'COPY (SELECT id, isfixed, COALESCE(initvalue, 0) FROM dd_graph_weights) TO STDOUT;'   > /Users/jackywang/Desktop/341/project/deepdive/out/dd_weights
09:38:27.080 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/exec_sql3830764205934963541.sh" 
09:38:27.111 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_inference_result_variables CASCADE
09:38:27.112 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_inference_result_variables(
      id bigint, 
      category bigint, 
      expectation double precision)
09:38:27.113 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_inference_result_weights CASCADE
09:38:27.113 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_inference_result_weights(
      id bigint primary key, 
      weight double precision)
09:38:27.115 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  Converting grounding file format...
09:38:27.115 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] DEBUG Executing: python /Users/jackywang/Desktop/341/project/deepdive/util/tobinary.py /Users/jackywang/Desktop/341/project/deepdive/out /Users/jackywang/Desktop/341/project/deepdive/util/format_converter_mac /Users/jackywang/Desktop/341/project/deepdive/out
09:38:27.393 [Thread-174][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  SPLITTING testFactor ...
09:38:27.393 [Thread-174][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  BINARIZE  testFactor ...
09:38:27.393 [Thread-174][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  SPLITTING dd_variables_r1 ...
09:38:27.393 [Thread-174][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  BINARIZE  dd_variables_r1 ...
09:38:27.393 [Thread-174][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  BINARIZE  weights ...
09:38:27.393 [Thread-174][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  COUNTING variables ...
09:38:27.394 [Thread-174][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  COUNTING factors ...
09:38:27.394 [Thread-174][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  COUNTING weights ...
09:38:27.394 [Thread-174][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  CONCATENATING FILES...
09:38:27.394 [Thread-174][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  Cleaning up files
09:38:27.397 [ScalaTest-running-PostgresInferenceDataStoreSpec][JdbcDataStore$(akka://deepdive)][JdbcDataStore$] INFO  Closing all JDBC data stores
09:38:27.397 [ScalaTest-running-PostgresInferenceDataStoreSpec][JdbcDataStore$(akka://deepdive)][JdbcDataStore$] INFO  Intializing all JDBC data stores
09:38:27.520 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing SQL with callback... 
    SELECT version() LIKE '%Greenplum%';
  
09:38:27.525 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  Using Greenplum = false
09:38:27.525 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  Datastore type = psql
09:38:27.526 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  Parallel grounding = false
09:38:27.526 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] DEBUG Grounding Path = /Users/jackywang/Desktop/341/project/deepdive/out
09:38:27.526 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing SQL with callback... 
    SELECT version() LIKE '%Greenplum%';
  
09:38:27.526 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP SEQUENCE IF EXISTS dd_variable_sequence CASCADE
09:38:27.526 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE SEQUENCE dd_variable_sequence MINVALUE -1 START 0
09:38:27.532 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_graph_variables_holdout CASCADE
09:38:27.533 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_graph_variables_holdout(variable_id bigint primary key)
09:38:27.535 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_graph_variables_observation CASCADE
09:38:27.535 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_graph_variables_observation(variable_id bigint primary key)
09:38:27.537 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_graph_factormeta CASCADE
09:38:27.537 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_graph_factormeta (name text, funcid int, sign text)
09:38:27.540 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] DEBUG Executing queries by file: psql  -d deepdive_test  -U jackywang  -p 5432  -h localhost  -c 'COPY (SELECT * FROM dd_graph_factormeta) TO STDOUT;'   > /Users/jackywang/Desktop/341/project/deepdive/out/dd_factormeta
09:38:27.540 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/exec_sql3081410601820306183.sh" 
09:38:27.570 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_graph_weights CASCADE
09:38:27.571 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_graph_weights (id bigint, isfixed int, initvalue real, 
      cardinality text, description text)
09:38:27.573 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP SEQUENCE IF EXISTS dd_weight_sequence CASCADE
09:38:27.573 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE SEQUENCE dd_weight_sequence MINVALUE -1 START 0
09:38:27.575 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP SEQUENCE IF EXISTS dd_factor_sequence CASCADE
09:38:27.575 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE SEQUENCE dd_factor_sequence MINVALUE -1 START 0
09:38:27.576 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_feature_statistics_support CASCADE
09:38:27.576 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_feature_statistics_support(
            description text, 
            pos_examples bigint, 
            neg_examples bigint, 
            queries bigint)
09:38:27.579 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] DEBUG Executing queries by file: psql  -d deepdive_test  -U jackywang  -p 5432  -h localhost  -c 'COPY (SELECT id, isfixed, COALESCE(initvalue, 0) FROM dd_graph_weights) TO STDOUT;'   > /Users/jackywang/Desktop/341/project/deepdive/out/dd_weights
09:38:27.579 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/exec_sql8700669523661296248.sh" 
09:38:27.609 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_inference_result_variables CASCADE
09:38:27.609 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_inference_result_variables(
      id bigint, 
      category bigint, 
      expectation double precision)
09:38:27.610 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_inference_result_weights CASCADE
09:38:27.610 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_inference_result_weights(
      id bigint primary key, 
      weight double precision)
09:38:27.612 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  Converting grounding file format...
09:38:27.612 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] DEBUG Executing: python /Users/jackywang/Desktop/341/project/deepdive/util/tobinary.py /Users/jackywang/Desktop/341/project/deepdive/out /Users/jackywang/Desktop/341/project/deepdive/util/format_converter_mac /Users/jackywang/Desktop/341/project/deepdive/out
09:38:27.695 [Thread-184][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  mv: rename /Users/jackywang/Desktop/341/project/deepdive/out/dd_tmp/dd_factors*.bin to /Users/jackywang/Desktop/341/project/deepdive/out/dd_factors/dd_factors*.bin: No such file or directory
09:38:27.715 [Thread-184][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  mv: rename /Users/jackywang/Desktop/341/project/deepdive/out/dd_tmp/dd_variables*.bin to /Users/jackywang/Desktop/341/project/deepdive/out/dd_variables/dd_variables*.bin: No such file or directory
09:38:27.723 [Thread-184][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  wc: /Users/jackywang/Desktop/341/project/deepdive/out/dd_tmp/dd_variables_*: open: No such file or directory
09:38:27.735 [Thread-184][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  (standard_in) 1: parse error
09:38:27.742 [Thread-184][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  wc: /Users/jackywang/Desktop/341/project/deepdive/out/dd_tmp/dd_factors_*: open: No such file or directory
09:38:27.756 [Thread-184][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  (standard_in) 1: parse error
09:38:27.773 [Thread-184][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  awk: can't open file /Users/jackywang/Desktop/341/project/deepdive/out/dd_nedges_
09:38:27.774 [Thread-184][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO   source line number 1
09:38:27.801 [Thread-184][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  cat: /Users/jackywang/Desktop/341/project/deepdive/out/dd_variables/*: No such file or directory
09:38:27.808 [Thread-184][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  cat: /Users/jackywang/Desktop/341/project/deepdive/out/dd_factors/dd_factors*factors.bin: No such file or directory
09:38:27.816 [Thread-184][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  cat: /Users/jackywang/Desktop/341/project/deepdive/out/dd_factors/dd_factors*edges.bin: No such file or directory
09:38:27.825 [Thread-183][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  BINARIZE  weights ...
09:38:27.825 [Thread-183][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  COUNTING variables ...
09:38:27.825 [Thread-183][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  COUNTING factors ...
09:38:27.825 [Thread-183][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  COUNTING weights ...
09:38:27.825 [Thread-183][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  CONCATENATING FILES...
09:38:27.825 [Thread-183][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  Cleaning up files
09:38:27.831 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_inference_result_variables CASCADE
09:38:27.833 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_inference_result_variables(
      id bigint, 
      category bigint, 
      expectation double precision)
09:38:27.834 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP TABLE IF EXISTS dd_inference_result_weights CASCADE
09:38:27.836 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE TABLE dd_inference_result_weights(
      id bigint primary key, 
      weight double precision)
09:38:27.838 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  Copying inference result weights...
09:38:27.839 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  psql  -d deepdive_test  -U jackywang  -p 5432  -h localhost  -c "\COPY dd_inference_result_weights(id, weight) FROM '/Users/jackywang/Desktop/341/project/deepdive/target/scala-2.10/test-classes/inference/sample_result.weights.text' DELIMITER ' ';"
09:38:27.839 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/copy9149410355697092640.sh" 
09:38:27.870 [Thread-186][Helpers$(akka://deepdive)][Helpers$] INFO  COPY 2
09:38:27.871 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  Copying inference result variables...
09:38:27.872 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  psql  -d deepdive_test  -U jackywang  -p 5432  -h localhost  -c "\COPY dd_inference_result_variables(id, category, expectation) FROM '/Users/jackywang/Desktop/341/project/deepdive/target/scala-2.10/test-classes/inference/sample_result.variables.text' DELIMITER ' ';"
09:38:27.872 [ScalaTest-running-PostgresInferenceDataStoreSpec][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/copy3345989642209528859.sh" 
09:38:27.902 [Thread-189][Helpers$(akka://deepdive)][Helpers$] INFO  COPY 10
09:38:27.903 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  Creating indices on the inference result...
09:38:27.903 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP INDEX IF EXISTS dd_inference_result_weights_idx CASCADE
09:38:27.903 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: DROP INDEX IF EXISTS dd_inference_result_variables_idx CASCADE
09:38:27.903 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE INDEX dd_inference_result_weights_idx ON dd_inference_result_weights (weight)
09:38:27.906 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE INDEX dd_inference_result_variables_idx ON dd_inference_result_variables (expectation)
09:38:27.912 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE OR REPLACE VIEW dd_inference_result_weights_mapping AS
    SELECT dd_graph_weights.*, dd_inference_result_weights.weight FROM
    dd_graph_weights JOIN dd_inference_result_weights ON dd_graph_weights.id = dd_inference_result_weights.id
    ORDER BY abs(weight) DESC
09:38:27.916 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE OR REPLACE VIEW dd_inference_result_variables_mapped_weights AS
    SELECT * FROM dd_inference_result_weights_mapping
    ORDER BY abs(weight) DESC
09:38:27.917 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE OR REPLACE VIEW dd_feature_statistics AS
        SELECT w.*, f.pos_examples, f.neg_examples, f.queries
        FROM dd_inference_result_weights_mapping w LEFT OUTER JOIN dd_feature_statistics_support f
        ON w.description = f.description
        ORDER BY abs(weight) DESC
09:38:27.920 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE OR REPLACE VIEW has_spouse_is_true_inference AS
    (SELECT has_spouse.*, mir.category, mir.expectation FROM
    has_spouse, dd_inference_result_variables mir
    WHERE has_spouse.id = mir.id
    ORDER BY mir.expectation DESC)
09:38:27.921 [ScalaTest-running-PostgresInferenceDataStoreSpec][JdbcDataStore$(akka://deepdive)][JdbcDataStore$] INFO  Closing all JDBC data stores
09:38:27.922 [ScalaTest-running-PostgresInferenceDataStoreSpec][JdbcDataStore$(akka://deepdive)][JdbcDataStore$] INFO  Intializing all JDBC data stores
09:38:28.063 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE OR REPLACE VIEW t1_c1_inference_bucketed AS
      SELECT t1_c1_inference.*, CASE WHEN expectation >= 0.0 AND expectation <= 0.1 THEN 0
WHEN expectation >= 0.1 AND expectation <= 0.2 THEN 1
WHEN expectation >= 0.2 AND expectation <= 0.30000000000000004 THEN 2
WHEN expectation >= 0.30000000000000004 AND expectation <= 0.4 THEN 3
WHEN expectation >= 0.4 AND expectation <= 0.5 THEN 4
WHEN expectation >= 0.5 AND expectation <= 0.6 THEN 5
WHEN expectation >= 0.6000000000000001 AND expectation <= 0.7000000000000001 THEN 6
WHEN expectation >= 0.7000000000000001 AND expectation <= 0.8 THEN 7
WHEN expectation >= 0.8 AND expectation <= 0.9 THEN 8
WHEN expectation >= 0.9 AND expectation <= 1.0 THEN 9 END bucket
      FROM t1_c1_inference ORDER BY bucket ASC
09:38:28.073 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  created calibration_view=t1_c1_calibration
09:38:28.073 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE OR REPLACE VIEW t1_c1_calibration AS
      SELECT b1.bucket, b1.num_variables, b2.num_correct, b3.num_incorrect FROM
      (SELECT bucket, COUNT(*) AS num_variables from t1_c1_inference_bucketed GROUP BY bucket) b1
      LEFT JOIN (SELECT bucket, COUNT(*) AS num_correct from t1_c1_inference_bucketed 
        WHERE c1=true GROUP BY bucket) b2 ON b1.bucket = b2.bucket
      LEFT JOIN (SELECT bucket, COUNT(*) AS num_incorrect from t1_c1_inference_bucketed 
        WHERE c1=false GROUP BY bucket) b3 ON b1.bucket = b3.bucket 
      ORDER BY b1.bucket ASC
09:38:28.123 [ScalaTest-running-PostgresInferenceDataStoreSpec][JdbcDataStore$(akka://deepdive)][JdbcDataStore$] INFO  Closing all JDBC data stores
09:38:28.123 [ScalaTest-running-PostgresInferenceDataStoreSpec][JdbcDataStore$(akka://deepdive)][JdbcDataStore$] INFO  Intializing all JDBC data stores
09:38:28.242 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE OR REPLACE VIEW t1_c1_inference_bucketed AS
      SELECT t1_c1_inference.*, CASE WHEN expectation >= 0.0 AND expectation <= 0.1 THEN 0
WHEN expectation >= 0.1 AND expectation <= 0.2 THEN 1
WHEN expectation >= 0.2 AND expectation <= 0.30000000000000004 THEN 2
WHEN expectation >= 0.30000000000000004 AND expectation <= 0.4 THEN 3
WHEN expectation >= 0.4 AND expectation <= 0.5 THEN 4
WHEN expectation >= 0.5 AND expectation <= 0.6 THEN 5
WHEN expectation >= 0.6000000000000001 AND expectation <= 0.7000000000000001 THEN 6
WHEN expectation >= 0.7000000000000001 AND expectation <= 0.8 THEN 7
WHEN expectation >= 0.8 AND expectation <= 0.9 THEN 8
WHEN expectation >= 0.9 AND expectation <= 1.0 THEN 9 END bucket
      FROM t1_c1_inference ORDER BY bucket ASC
09:38:28.248 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore(akka://deepdive)][PostgresInferenceDataStoreComponent$PostgresInferenceDataStore] INFO  created calibration_view=t1_c1_calibration
09:38:28.248 [ScalaTest-running-PostgresInferenceDataStoreSpec][PostgresDataStore$(akka://deepdive)][PostgresDataStore$] DEBUG Executing query via JDBC: CREATE OR REPLACE VIEW t1_c1_calibration AS
      SELECT b1.bucket, b1.num_variables, b2.num_correct, b3.num_incorrect FROM
      (SELECT bucket, COUNT(*) AS num_variables from t1_c1_inference_bucketed GROUP BY bucket) b1
      LEFT JOIN (SELECT bucket, COUNT(*) AS num_correct from t1_c1_inference_bucketed 
        WHERE c1 = category GROUP BY bucket) b2 ON b1.bucket = b2.bucket
      LEFT JOIN (SELECT bucket, COUNT(*) AS num_incorrect from t1_c1_inference_bucketed 
        WHERE c1 != category GROUP BY bucket) b3 ON b1.bucket = b3.bucket 
      ORDER BY b1.bucket ASC
09:38:28.257 [ScalaTest-running-PostgresInferenceDataStoreSpec][JdbcDataStore$(akka://deepdive)][JdbcDataStore$] INFO  Closing all JDBC data stores
09:38:28.294 [][][Slf4jLogger] INFO  Slf4jLogger started
09:38:28.294 [pool-4-thread-6][EventStream(akka://ProfilerSpec)][EventStream] DEBUG logger log1-Slf4jLogger started
09:38:28.294 [pool-4-thread-6][EventStream(akka://ProfilerSpec)][EventStream] DEBUG Default Loggers started
09:38:28.311 [ScalaTest-running-ProfilerSpec][akka://ProfilerSpec/user/$$d][Profiler] INFO  starting at akka://ProfilerSpec/user/$$d
09:38:28.313 [ScalaTest-running-ProfilerSpec][akka://ProfilerSpec/user/$$d][Profiler] DEBUG starting report_id=1
09:38:28.313 [ScalaTest-running-ProfilerSpec][akka://ProfilerSpec/user/$$d][Profiler] DEBUG ending report_id=1
09:38:28.329 [ScalaTest-running-PostgresExtractionDataStoreSpec][JdbcDataStore$(akka://deepdive)][JdbcDataStore$] INFO  Intializing all JDBC data stores
09:38:28.492 [ScalaTest-running-PostgresExtractionDataStoreSpec][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG SELECT key from datatype_test order by key asc;
09:38:28.496 [ScalaTest-running-PostgresExtractionDataStoreSpec][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG QUERY PLAN
09:38:28.496 [ScalaTest-running-PostgresExtractionDataStoreSpec][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG Sort  (cost=50.08..51.83 rows=700 width=4)
09:38:28.497 [ScalaTest-running-PostgresExtractionDataStoreSpec][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG   Sort Key: key
09:38:28.497 [ScalaTest-running-PostgresExtractionDataStoreSpec][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG   ->  Seq Scan on datatype_test  (cost=0.00..17.00 rows=700 width=4)
09:38:28.500 [ScalaTest-running-PostgresExtractionDataStoreSpec][JdbcDataStore$(akka://deepdive)][JdbcDataStore$] INFO  Closing all JDBC data stores
09:38:28.501 [ScalaTest-running-PostgresExtractionDataStoreSpec][JdbcDataStore$(akka://deepdive)][JdbcDataStore$] INFO  Intializing all JDBC data stores
09:38:28.627 [ScalaTest-running-PostgresExtractionDataStoreSpec][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG SELECT key AS "d1.key2" from datatype_test order by "d1.key2" asc;
09:38:28.631 [ScalaTest-running-PostgresExtractionDataStoreSpec][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG QUERY PLAN
09:38:28.631 [ScalaTest-running-PostgresExtractionDataStoreSpec][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG Sort  (cost=50.08..51.83 rows=700 width=4)
09:38:28.631 [ScalaTest-running-PostgresExtractionDataStoreSpec][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG   Sort Key: key
09:38:28.631 [ScalaTest-running-PostgresExtractionDataStoreSpec][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG   ->  Seq Scan on datatype_test  (cost=0.00..17.00 rows=700 width=4)
09:38:28.632 [ScalaTest-running-PostgresExtractionDataStoreSpec][JdbcDataStore$(akka://deepdive)][JdbcDataStore$] INFO  Closing all JDBC data stores
09:38:28.632 [ScalaTest-running-PostgresExtractionDataStoreSpec][JdbcDataStore$(akka://deepdive)][JdbcDataStore$] INFO  Intializing all JDBC data stores
09:38:28.755 [ScalaTest-running-PostgresExtractionDataStoreSpec][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG SELECT COUNT(*) AS num 
        from datatype_test GROUP BY key
09:38:28.759 [ScalaTest-running-PostgresExtractionDataStoreSpec][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG QUERY PLAN
09:38:28.759 [ScalaTest-running-PostgresExtractionDataStoreSpec][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG HashAggregate  (cost=20.50..22.50 rows=200 width=4)
09:38:28.759 [ScalaTest-running-PostgresExtractionDataStoreSpec][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG   Group Key: key
09:38:28.759 [ScalaTest-running-PostgresExtractionDataStoreSpec][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG   ->  Seq Scan on datatype_test  (cost=0.00..17.00 rows=700 width=4)
09:38:28.760 [ScalaTest-running-PostgresExtractionDataStoreSpec][JdbcDataStore$(akka://deepdive)][JdbcDataStore$] INFO  Closing all JDBC data stores
09:38:28.760 [ScalaTest-running-PostgresExtractionDataStoreSpec][JdbcDataStore$(akka://deepdive)][JdbcDataStore$] INFO  Intializing all JDBC data stores
09:38:28.881 [ScalaTest-running-PostgresExtractionDataStoreSpec][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG SELECT * from datatype_test;
09:38:28.883 [ScalaTest-running-PostgresExtractionDataStoreSpec][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG QUERY PLAN
09:38:28.884 [ScalaTest-running-PostgresExtractionDataStoreSpec][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG Seq Scan on datatype_test  (cost=0.00..17.00 rows=700 width=86)
09:38:28.887 [ScalaTest-running-PostgresExtractionDataStoreSpec][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] WARN  query returned no results: SELECT * from datatype_test;
09:38:28.887 [ScalaTest-running-PostgresExtractionDataStoreSpec][JdbcDataStore$(akka://deepdive)][JdbcDataStore$] INFO  Closing all JDBC data stores
09:38:28.887 [ScalaTest-running-PostgresExtractionDataStoreSpec][JdbcDataStore$(akka://deepdive)][JdbcDataStore$] INFO  Intializing all JDBC data stores
09:38:29.004 [ScalaTest-running-PostgresExtractionDataStoreSpec][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG SELECT *a from datatype_test;
09:38:29.008 [ScalaTest-running-PostgresExtractionDataStoreSpec][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] ERROR org.postgresql.util.PSQLException: ERROR: syntax error at or near "a"
  Position: 17
09:38:29.008 [ScalaTest-running-PostgresExtractionDataStoreSpec][JdbcDataStore$(akka://deepdive)][JdbcDataStore$] INFO  Closing all JDBC data stores
09:38:29.009 [ScalaTest-running-PostgresExtractionDataStoreSpec][JdbcDataStore$(akka://deepdive)][JdbcDataStore$] INFO  Intializing all JDBC data stores
09:38:29.129 [ScalaTest-running-PostgresExtractionDataStoreSpec][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG SELECT * from datatype_test;
09:38:29.132 [ScalaTest-running-PostgresExtractionDataStoreSpec][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG QUERY PLAN
09:38:29.132 [ScalaTest-running-PostgresExtractionDataStoreSpec][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG Seq Scan on datatype_test  (cost=0.00..17.00 rows=700 width=86)
09:38:29.132 [ScalaTest-running-PostgresExtractionDataStoreSpec][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] WARN  query returned no results: SELECT * from datatype_test;
09:38:29.133 [ScalaTest-running-PostgresExtractionDataStoreSpec][JdbcDataStore$(akka://deepdive)][JdbcDataStore$] INFO  Closing all JDBC data stores
09:38:29.134 [ScalaTest-running-PostgresExtractionDataStoreSpec][JdbcDataStore$(akka://deepdive)][JdbcDataStore$] INFO  Intializing all JDBC data stores
09:38:29.257 [ScalaTest-running-PostgresExtractionDataStoreSpec][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG SELECT key, array_agg(some_text ORDER BY some_text) AS "datatype_test.texts"
        FROM datatype_test GROUP BY key
09:38:29.263 [ScalaTest-running-PostgresExtractionDataStoreSpec][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG QUERY PLAN
09:38:29.263 [ScalaTest-running-PostgresExtractionDataStoreSpec][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG GroupAggregate  (cost=50.08..57.83 rows=200 width=36)
09:38:29.263 [ScalaTest-running-PostgresExtractionDataStoreSpec][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG   Group Key: key
09:38:29.263 [ScalaTest-running-PostgresExtractionDataStoreSpec][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG   ->  Sort  (cost=50.08..51.83 rows=700 width=36)
09:38:29.263 [ScalaTest-running-PostgresExtractionDataStoreSpec][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG         Sort Key: key
09:38:29.263 [ScalaTest-running-PostgresExtractionDataStoreSpec][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG         ->  Seq Scan on datatype_test  (cost=0.00..17.00 rows=700 width=36)
09:38:29.279 [ScalaTest-running-PostgresExtractionDataStoreSpec][JdbcDataStore$(akka://deepdive)][JdbcDataStore$] INFO  Closing all JDBC data stores
09:38:29.280 [ScalaTest-running-PostgresExtractionDataStoreSpec][JdbcDataStore$(akka://deepdive)][JdbcDataStore$] INFO  Intializing all JDBC data stores
09:38:29.402 [ScalaTest-running-PostgresExtractionDataStoreSpec][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG SELECT * from datatype_test WHERE some_text='Hello'
09:38:29.407 [ScalaTest-running-PostgresExtractionDataStoreSpec][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG QUERY PLAN
09:38:29.407 [ScalaTest-running-PostgresExtractionDataStoreSpec][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG Seq Scan on datatype_test  (cost=0.00..18.75 rows=4 width=86)
09:38:29.407 [ScalaTest-running-PostgresExtractionDataStoreSpec][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG   Filter: (some_text = 'Hello'::text)
09:38:29.411 [ScalaTest-running-PostgresExtractionDataStoreSpec][JdbcDataStore$(akka://deepdive)][JdbcDataStore$] INFO  Closing all JDBC data stores
09:38:29.411 [ScalaTest-running-PostgresExtractionDataStoreSpec][JdbcDataStore$(akka://deepdive)][JdbcDataStore$] INFO  Intializing all JDBC data stores
09:38:29.524 [ScalaTest-running-PostgresExtractionDataStoreSpec][JdbcDataStore$(akka://deepdive)][JdbcDataStore$] INFO  Closing all JDBC data stores
09:38:29.524 [ScalaTest-running-PostgresExtractionDataStoreSpec][JdbcDataStore$(akka://deepdive)][JdbcDataStore$] INFO  Intializing all JDBC data stores
09:38:29.645 [ScalaTest-running-PostgresExtractionDataStoreSpec][JdbcDataStore$(akka://deepdive)][JdbcDataStore$] INFO  Closing all JDBC data stores
09:38:29.645 [ScalaTest-running-PostgresExtractionDataStoreSpec][JdbcDataStore$(akka://deepdive)][JdbcDataStore$] INFO  Intializing all JDBC data stores
09:38:29.760 [ScalaTest-running-PostgresExtractionDataStoreSpec][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG Writing data of to file=/private/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/deepdive_datatype_test1792655691067222325.csv
09:38:29.779 [ScalaTest-running-PostgresExtractionDataStoreSpec][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG Copying batch data to postgres. sql='COPY datatype_test(key, some_array, some_boolean, some_double, some_null, some_text) FROM STDIN CSV'file='/private/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/deepdive_datatype_test1792655691067222325.csv'
09:38:29.802 [ScalaTest-running-PostgresExtractionDataStoreSpec][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG Successfully copied batch data to postgres.
09:38:29.803 [ScalaTest-running-PostgresExtractionDataStoreSpec][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG SELECT * from datatype_test
09:38:29.804 [ScalaTest-running-PostgresExtractionDataStoreSpec][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG QUERY PLAN
09:38:29.804 [ScalaTest-running-PostgresExtractionDataStoreSpec][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG Seq Scan on datatype_test  (cost=0.00..17.00 rows=700 width=86)
09:38:29.806 [ScalaTest-running-PostgresExtractionDataStoreSpec][JdbcDataStore$(akka://deepdive)][JdbcDataStore$] INFO  Closing all JDBC data stores
09:38:29.807 [ScalaTest-running-PostgresExtractionDataStoreSpec][JdbcDataStore$(akka://deepdive)][JdbcDataStore$] INFO  Intializing all JDBC data stores
09:38:30.139 [ScalaTest-running-PostgresExtractionDataStoreSpec][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG Writing data of to file=/private/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/deepdive_datatype_test6390225264517888501.csv
09:38:30.151 [ScalaTest-running-PostgresExtractionDataStoreSpec][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG Copying batch data to postgres. sql='COPY datatype_test(key, some_array, some_boolean, some_double, some_null, some_text) FROM STDIN CSV'file='/private/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/deepdive_datatype_test6390225264517888501.csv'
09:38:30.155 [ScalaTest-running-PostgresExtractionDataStoreSpec][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG Successfully copied batch data to postgres.
09:38:30.156 [ScalaTest-running-PostgresExtractionDataStoreSpec][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG SELECT * from datatype_test
09:38:30.156 [ScalaTest-running-PostgresExtractionDataStoreSpec][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG QUERY PLAN
09:38:30.156 [ScalaTest-running-PostgresExtractionDataStoreSpec][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG Seq Scan on datatype_test  (cost=0.00..17.00 rows=700 width=86)
09:38:30.158 [ScalaTest-running-PostgresExtractionDataStoreSpec][JdbcDataStore$(akka://deepdive)][JdbcDataStore$] INFO  Closing all JDBC data stores
09:38:30.165 [][][Slf4jLogger] INFO  Slf4jLogger started
09:38:30.166 [pool-4-thread-6][EventStream(akka://InferenceManagerSpec)][EventStream] DEBUG logger log1-Slf4jLogger started
09:38:30.166 [pool-4-thread-6][EventStream(akka://InferenceManagerSpec)][EventStream] DEBUG Default Loggers started
09:38:30.270 [ScalaTest-running-InferenceManagerSpec][akka://InferenceManagerSpec/user/$$e][TestInferenceManager] INFO  Starting
09:38:30.271 [ScalaTest-running-InferenceManagerSpec][MemoryInferenceDataStoreComponent$MemoryInferenceDataStore(akka://deepdive)][MemoryInferenceDataStoreComponent$MemoryInferenceDataStore] INFO  initialized
09:38:30.290 [ScalaTest-running-InferenceManagerSpec][MemoryInferenceDataStoreComponent$MemoryInferenceDataStore(akka://deepdive)][MemoryInferenceDataStoreComponent$MemoryInferenceDataStore] INFO  initialized
09:38:30.290 [ScalaTest-running-InferenceManagerSpec][akka://InferenceManagerSpec/user/$$f][TestInferenceManager] INFO  Starting
09:38:30.291 [ScalaTest-running-InferenceManagerSpec][akka://InferenceManagerSpec/user/$$f][TestInferenceManager] INFO  writing calibration data
09:38:30.319 [ScalaTest-running-HelpersSpec][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test9070450616594252181.sh" 
09:38:30.355 [ScalaTest-running-HelpersSpec][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test5696222228563878787.sh" 
09:38:30.364 [Thread-196][Helpers$(akka://deepdive)][Helpers$] INFO  /var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test5696222228563878787.sh: line 1: bad: command not found
09:38:30.390 [][][Slf4jLogger] INFO  Slf4jLogger started
09:38:30.390 [pool-4-thread-6][EventStream(akka://ExtractorRunnerSpec)][EventStream] DEBUG logger log1-Slf4jLogger started
09:38:30.391 [pool-4-thread-6][EventStream(akka://ExtractorRunnerSpec)][EventStream] DEBUG Default Loggers started
09:38:30.420 [ScalaTest-running-ExtractorRunnerSpec][JdbcDataStore$(akka://deepdive)][JdbcDataStore$] INFO  Intializing all JDBC data stores
09:38:30.543 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG EXECUTING.... drop table if exists testtable;
09:38:30.545 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG DONE!
09:38:30.545 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG EXECUTING.... create table testtable ( a text );
09:38:30.547 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG DONE!
09:38:30.547 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] INFO  /var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test932937660968635248.sh
09:38:30.548 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG Writing to file /var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test932937660968635248.sh:

 echo "I should be in the table" > /var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test2700750862011255269.tsv 
 echo "I should also be in the table" >> /var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test2700750862011255269.tsv
      
09:38:30.549 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG Writing to file /var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test3612487571261294196.py:
#! /usr/bin/python
import json
for l in open('/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test2700750862011255269.tsv'):
  print json.dumps({'a':l.strip()})


09:38:30.568 [ExtractorRunnerSpec-akka.actor.default-dispatcher-3][akka://ExtractorRunnerSpec/user/$a][ExtractorRunner] INFO  waiting for tasks
09:38:30.571 [ExtractorRunnerSpec-akka.actor.default-dispatcher-3][akka://ExtractorRunnerSpec/user/$a][ExtractorRunner] INFO  Received task=testExtractor. Executing
09:38:30.572 [ExtractorRunnerSpec-akka.actor.default-dispatcher-3][akka://ExtractorRunnerSpec/user/$a][ExtractorRunner] INFO  Executing before script.
09:38:30.572 [ExtractorRunnerSpec-akka.actor.default-dispatcher-3][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test932937660968635248.sh" 
09:38:30.582 [ExtractorRunnerSpec-akka.actor.default-dispatcher-3][akka://ExtractorRunnerSpec/user/$a][ExtractorRunner] INFO  Starting 1 children process workers
09:38:30.591 [ExtractorRunnerSpec-akka.actor.default-dispatcher-2][akka://ExtractorRunnerSpec/user/$a/processExecutor1][ProcessExecutor] INFO  started
09:38:30.593 [ExtractorRunnerSpec-akka.actor.default-dispatcher-4][akka://ExtractorRunnerSpec/user/$a/processExecutor1][ProcessExecutor] INFO  starting process with cmd="/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test3612487571261294196.py" and batch_size=1000
09:38:30.594 [ExtractorRunnerSpec-akka.actor.default-dispatcher-2][akka://ExtractorRunnerSpec/user/$a][ExtractorRunner] INFO  Getting data from the data store and sending it to the workers. query='DatastoreInputQuery(SELECT 5)'
09:38:30.596 [ExtractorRunnerSpec-akka.actor.default-dispatcher-2][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG SELECT 5
09:38:30.597 [ExtractorRunnerSpec-akka.actor.default-dispatcher-2][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG QUERY PLAN
09:38:30.597 [ExtractorRunnerSpec-akka.actor.default-dispatcher-2][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG Result  (cost=0.00..0.01 rows=1 width=0)
09:38:30.640 [ExtractorRunnerSpec-akka.actor.default-dispatcher-2][akka://ExtractorRunnerSpec/user/$a][ExtractorRunner] DEBUG all data was sent to workers.
09:38:30.640 [ExtractorRunnerSpec-akka.actor.default-dispatcher-5][akka://ExtractorRunnerSpec/user/$a/processExecutor1][ProcessExecutor] DEBUG closing input stream
09:38:32.502 [ExtractorRunnerSpec-akka.actor.default-dispatcher-5][akka://ExtractorRunnerSpec/user/$a][ExtractorRunner] DEBUG adding chunk of size=2 data store.
09:38:32.525 [ExtractorRunnerSpec-akka.actor.default-dispatcher-5][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG Writing data of to file=/private/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/deepdive_testtable5707615799908931123.csv
09:38:32.532 [ExtractorRunnerSpec-akka.actor.default-dispatcher-5][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG Copying batch data to postgres. sql='COPY testtable(a) FROM STDIN CSV'file='/private/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/deepdive_testtable5707615799908931123.csv'
09:38:32.534 [ExtractorRunnerSpec-akka.actor.default-dispatcher-5][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG Successfully copied batch data to postgres.
09:38:32.535 [Thread-201][akka://ExtractorRunnerSpec/user/$a/processExecutor1][ProcessExecutor] DEBUG closing output stream
09:38:32.535 [ExtractorRunnerSpec-akka.actor.default-dispatcher-5][akka://ExtractorRunnerSpec/user/$a/processExecutor1][ProcessExecutor] INFO  process exited with exit_value=0
09:38:32.540 [ExtractorRunnerSpec-akka.actor.default-dispatcher-4][akka://ExtractorRunnerSpec/user/$a][ExtractorRunner] DEBUG worker=processExecutor1 has terminated. Waiting for 0 others.
09:38:32.540 [ExtractorRunnerSpec-akka.actor.default-dispatcher-4][akka://ExtractorRunnerSpec/user/$a][ExtractorRunner] INFO  All workers are done. Finishing up.
09:38:32.541 [ExtractorRunnerSpec-akka.actor.default-dispatcher-4][akka://ExtractorRunnerSpec/user/$a][ExtractorRunner] INFO  Shutting down
09:38:32.545 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG EXECUTING.... DELETE FROM testtable WHERE a='I should be in the table';
09:38:32.546 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG DONE!
09:38:32.546 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG EXECUTING.... DELETE FROM testtable WHERE a='I should also be in the table';
09:38:32.546 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG DONE!
09:38:32.556 [ExtractorRunnerSpec-akka.actor.default-dispatcher-4][akka://ExtractorRunnerSpec/user/$b][ExtractorRunner] INFO  waiting for tasks
09:38:32.556 [ExtractorRunnerSpec-akka.actor.default-dispatcher-4][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/bin/i_am_not_exist" 
09:38:32.557 [ExtractorRunnerSpec-akka.actor.default-dispatcher-4][akka://ExtractorRunnerSpec/user/$b][ExtractorRunner] INFO  Received task=testExtractor. Executing
09:38:32.557 [ExtractorRunnerSpec-akka.actor.default-dispatcher-4][akka://ExtractorRunnerSpec/user/$b][ExtractorRunner] INFO  Executing before script.
09:38:32.563 [ExtractorRunnerSpec-akka.actor.default-dispatcher-4][akka://ExtractorRunnerSpec/user/$b][ExtractorRunner] ERROR java.io.IOException: Cannot run program "/bin/i_am_not_exist": error=2, No such file or directory
09:38:32.568 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG EXECUTING.... drop table if exists testtable;
09:38:32.569 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG DONE!
09:38:32.569 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG EXECUTING.... create table testtable ( a text );
09:38:32.571 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG DONE!
09:38:32.571 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] INFO  /var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test7435850802729990086.py
09:38:32.572 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG Writing to file /var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test7435850802729990086.py:
#! /usr/bin/python
 echo "I should also be in the table" >> /var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test1603061270077596648.tsv
      
09:38:32.572 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG Writing to file /var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test3196227354044056596.py:
#! /usr/bin/python
import json
for l in open('/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test1603061270077596648.tsv'):
  print json.dumps({'a':l.strip()})


09:38:32.573 [ExtractorRunnerSpec-akka.actor.default-dispatcher-3][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test7435850802729990086.py" 
09:38:32.576 [ExtractorRunnerSpec-akka.actor.default-dispatcher-5][akka://ExtractorRunnerSpec/user/$b][OneForOneStrategy] ERROR java.io.IOException: Cannot run program "/bin/i_am_not_exist": error=2, No such file or directory
java.lang.RuntimeException: java.io.IOException: Cannot run program "/bin/i_am_not_exist": error=2, No such file or directory
	at org.deepdive.extraction.ExtractorRunner.org$deepdive$extraction$ExtractorRunner$$executeScriptOrFail(ExtractorRunner.scala:298) ~[classes/:na]
	at org.deepdive.extraction.ExtractorRunner$$anonfun$2$$anonfun$applyOrElse$3.apply(ExtractorRunner.scala:110) ~[classes/:na]
	at org.deepdive.extraction.ExtractorRunner$$anonfun$2$$anonfun$applyOrElse$3.apply(ExtractorRunner.scala:108) ~[classes/:na]
	at scala.Option.foreach(Option.scala:236) ~[scala-library.jar:0.13.7]
	at org.deepdive.extraction.ExtractorRunner$$anonfun$2.applyOrElse(ExtractorRunner.scala:107) ~[classes/:na]
	at org.deepdive.extraction.ExtractorRunner$$anonfun$2.applyOrElse(ExtractorRunner.scala:100) ~[classes/:na]
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:33) ~[scala-library.jar:0.13.7]
	at akka.actor.FSM$class.processEvent(FSM.scala:587) ~[akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at org.deepdive.extraction.ExtractorRunner.processEvent(ExtractorRunner.scala:59) ~[classes/:na]
	at akka.actor.FSM$class.akka$actor$FSM$$processMsg(FSM.scala:581) ~[akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:575) ~[akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at akka.actor.Actor$class.aroundReceive(Actor.scala:467) ~[akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at org.deepdive.extraction.ExtractorRunner.aroundReceive(ExtractorRunner.scala:59) ~[classes/:na]
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:491) [akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at akka.actor.ActorCell.invoke(ActorCell.scala:462) [akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:237) [akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at akka.dispatch.Mailbox.run(Mailbox.scala:219) [akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:385) [akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [scala-library.jar:na]
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [scala-library.jar:na]
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [scala-library.jar:na]
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [scala-library.jar:na]
09:38:32.577 [ExtractorRunnerSpec-akka.actor.default-dispatcher-3][akka://ExtractorRunnerSpec/user/$c][ExtractorRunner] INFO  waiting for tasks
09:38:32.577 [ExtractorRunnerSpec-akka.actor.default-dispatcher-3][akka://ExtractorRunnerSpec/user/$c][ExtractorRunner] INFO  Received task=testExtractor. Executing
09:38:32.577 [ExtractorRunnerSpec-akka.actor.default-dispatcher-3][akka://ExtractorRunnerSpec/user/$c][ExtractorRunner] INFO  Executing before script.
09:38:32.608 [Thread-205][Helpers$(akka://deepdive)][Helpers$] INFO    File "/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test7435850802729990086.py", line 2
09:38:32.608 [Thread-205][Helpers$(akka://deepdive)][Helpers$] INFO      echo "I should also be in the table" >> /var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test1603061270077596648.tsv
09:38:32.608 [Thread-205][Helpers$(akka://deepdive)][Helpers$] INFO      ^
09:38:32.608 [Thread-205][Helpers$(akka://deepdive)][Helpers$] INFO  IndentationError: unexpected indent
09:38:32.610 [ExtractorRunnerSpec-akka.actor.default-dispatcher-3][akka://ExtractorRunnerSpec/user/$c][ExtractorRunner] ERROR java.lang.RuntimeException: Failure when executing script: /var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test7435850802729990086.py
09:38:32.611 [ExtractorRunnerSpec-akka.actor.default-dispatcher-5][akka://ExtractorRunnerSpec/user/$c][OneForOneStrategy] ERROR java.lang.RuntimeException: Failure when executing script: /var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test7435850802729990086.py
java.lang.RuntimeException: java.lang.RuntimeException: Failure when executing script: /var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test7435850802729990086.py
	at org.deepdive.extraction.ExtractorRunner.org$deepdive$extraction$ExtractorRunner$$executeScriptOrFail(ExtractorRunner.scala:298) ~[classes/:na]
	at org.deepdive.extraction.ExtractorRunner$$anonfun$2$$anonfun$applyOrElse$3.apply(ExtractorRunner.scala:110) ~[classes/:na]
	at org.deepdive.extraction.ExtractorRunner$$anonfun$2$$anonfun$applyOrElse$3.apply(ExtractorRunner.scala:108) ~[classes/:na]
	at scala.Option.foreach(Option.scala:236) ~[scala-library.jar:0.13.7]
	at org.deepdive.extraction.ExtractorRunner$$anonfun$2.applyOrElse(ExtractorRunner.scala:107) ~[classes/:na]
	at org.deepdive.extraction.ExtractorRunner$$anonfun$2.applyOrElse(ExtractorRunner.scala:100) ~[classes/:na]
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:33) ~[scala-library.jar:0.13.7]
	at akka.actor.FSM$class.processEvent(FSM.scala:587) ~[akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at org.deepdive.extraction.ExtractorRunner.processEvent(ExtractorRunner.scala:59) ~[classes/:na]
	at akka.actor.FSM$class.akka$actor$FSM$$processMsg(FSM.scala:581) ~[akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:575) ~[akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at akka.actor.Actor$class.aroundReceive(Actor.scala:467) ~[akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at org.deepdive.extraction.ExtractorRunner.aroundReceive(ExtractorRunner.scala:59) ~[classes/:na]
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:491) [akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at akka.actor.ActorCell.invoke(ActorCell.scala:462) [akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:237) [akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at akka.dispatch.Mailbox.run(Mailbox.scala:219) [akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:385) [akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [scala-library.jar:na]
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [scala-library.jar:na]
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [scala-library.jar:na]
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [scala-library.jar:na]
09:38:32.616 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG EXECUTING.... drop table if exists testtable;
09:38:32.616 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG DONE!
09:38:32.616 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG EXECUTING.... create table testtable ( a text );
09:38:32.618 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG DONE!
09:38:32.619 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] INFO  /var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test9107758672738170946.sh
09:38:32.619 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG Writing to file /var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test9107758672738170946.sh:

 echo "I should be in the table" > /var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test7215477275623592836.tsv 
 echo "I should also be in the table" >> /var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test7215477275623592836.tsv
      
09:38:32.619 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG Writing to file /var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test5727256521891681918.py:
#! /usr/bin/python
import json
for l in open('/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test7215477275623592836.tsv'):
  print json.dumps({'a':l.strip()})


09:38:32.620 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG Writing to file /var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test4897818223324268566.sh:

 psql  -d deepdive_test  -U jackywang  -p 5432  -h localhost  -c  "INSERT INTO testtable VALUES ('Hello!');"
 psql  -d deepdive_test  -U jackywang  -p 5432  -h localhost  -c  "INSERT INTO testtable VALUES('Aloha!');"
      
09:38:32.620 [ExtractorRunnerSpec-akka.actor.default-dispatcher-3][akka://ExtractorRunnerSpec/user/$d][ExtractorRunner] INFO  waiting for tasks
09:38:32.620 [ExtractorRunnerSpec-akka.actor.default-dispatcher-3][akka://ExtractorRunnerSpec/user/$d][ExtractorRunner] INFO  Received task=testExtractor. Executing
09:38:32.620 [ExtractorRunnerSpec-akka.actor.default-dispatcher-3][akka://ExtractorRunnerSpec/user/$d][ExtractorRunner] INFO  Executing before script.
09:38:32.620 [ExtractorRunnerSpec-akka.actor.default-dispatcher-3][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test9107758672738170946.sh" 
09:38:32.631 [ExtractorRunnerSpec-akka.actor.default-dispatcher-3][akka://ExtractorRunnerSpec/user/$d][ExtractorRunner] INFO  Starting 1 children process workers
09:38:32.631 [ExtractorRunnerSpec-akka.actor.default-dispatcher-2][akka://ExtractorRunnerSpec/user/$d][ExtractorRunner] INFO  Getting data from the data store and sending it to the workers. query='DatastoreInputQuery(SELECT 5)'
09:38:32.631 [ExtractorRunnerSpec-akka.actor.default-dispatcher-5][akka://ExtractorRunnerSpec/user/$d/processExecutor1][ProcessExecutor] INFO  started
09:38:32.631 [ExtractorRunnerSpec-akka.actor.default-dispatcher-5][akka://ExtractorRunnerSpec/user/$d/processExecutor1][ProcessExecutor] INFO  starting process with cmd="/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test5727256521891681918.py" and batch_size=1000
09:38:32.631 [ExtractorRunnerSpec-akka.actor.default-dispatcher-2][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG SELECT 5
09:38:32.632 [ExtractorRunnerSpec-akka.actor.default-dispatcher-2][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG QUERY PLAN
09:38:32.632 [ExtractorRunnerSpec-akka.actor.default-dispatcher-2][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG Result  (cost=0.00..0.01 rows=1 width=0)
09:38:32.638 [ExtractorRunnerSpec-akka.actor.default-dispatcher-2][akka://ExtractorRunnerSpec/user/$d][ExtractorRunner] DEBUG all data was sent to workers.
09:38:32.638 [ExtractorRunnerSpec-akka.actor.default-dispatcher-4][akka://ExtractorRunnerSpec/user/$d/processExecutor1][ProcessExecutor] DEBUG closing input stream
09:38:32.675 [ExtractorRunnerSpec-akka.actor.default-dispatcher-4][akka://ExtractorRunnerSpec/user/$d][ExtractorRunner] DEBUG adding chunk of size=2 data store.
09:38:32.676 [ExtractorRunnerSpec-akka.actor.default-dispatcher-4][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG Writing data of to file=/private/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/deepdive_testtable6200230134566783838.csv
09:38:32.680 [ExtractorRunnerSpec-akka.actor.default-dispatcher-4][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG Copying batch data to postgres. sql='COPY testtable(a) FROM STDIN CSV'file='/private/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/deepdive_testtable6200230134566783838.csv'
09:38:32.682 [ExtractorRunnerSpec-akka.actor.default-dispatcher-4][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG Successfully copied batch data to postgres.
09:38:32.682 [Thread-210][akka://ExtractorRunnerSpec/user/$d/processExecutor1][ProcessExecutor] DEBUG closing output stream
09:38:32.682 [ExtractorRunnerSpec-akka.actor.default-dispatcher-2][akka://ExtractorRunnerSpec/user/$d/processExecutor1][ProcessExecutor] INFO  process exited with exit_value=0
09:38:32.682 [ExtractorRunnerSpec-akka.actor.default-dispatcher-3][akka://ExtractorRunnerSpec/user/$d][ExtractorRunner] DEBUG worker=processExecutor1 has terminated. Waiting for 0 others.
09:38:32.682 [ExtractorRunnerSpec-akka.actor.default-dispatcher-3][akka://ExtractorRunnerSpec/user/$d][ExtractorRunner] INFO  All workers are done. Finishing up.
09:38:32.682 [ExtractorRunnerSpec-akka.actor.default-dispatcher-3][akka://ExtractorRunnerSpec/user/$d][ExtractorRunner] INFO  Analyzing output relation.
09:38:32.686 [ExtractorRunnerSpec-akka.actor.default-dispatcher-3][akka://ExtractorRunnerSpec/user/$d][ExtractorRunner] INFO  Executing after script.
09:38:32.686 [ExtractorRunnerSpec-akka.actor.default-dispatcher-3][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test4897818223324268566.sh" 
09:38:32.718 [Thread-213][Helpers$(akka://deepdive)][Helpers$] INFO  INSERT 0 1
09:38:32.740 [Thread-213][Helpers$(akka://deepdive)][Helpers$] INFO  INSERT 0 1
09:38:32.740 [ExtractorRunnerSpec-akka.actor.default-dispatcher-3][akka://ExtractorRunnerSpec/user/$d][ExtractorRunner] INFO  Shutting down
09:38:32.743 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG EXECUTING.... DELETE FROM testtable WHERE a='I should be in the table';
09:38:32.744 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG DONE!
09:38:32.744 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG EXECUTING.... DELETE FROM testtable WHERE a='I should also be in the table';
09:38:32.744 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG DONE!
09:38:32.744 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG EXECUTING.... DELETE FROM testtable WHERE a='Hello!';
09:38:32.745 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG DONE!
09:38:32.745 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG EXECUTING.... DELETE FROM testtable WHERE a='Aloha!';
09:38:32.746 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG DONE!
09:38:32.753 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG EXECUTING.... drop table if exists testtable;
09:38:32.753 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG DONE!
09:38:32.753 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG EXECUTING.... create table testtable ( a text );
09:38:32.755 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG DONE!
09:38:32.756 [ExtractorRunnerSpec-akka.actor.default-dispatcher-2][akka://ExtractorRunnerSpec/user/$e][ExtractorRunner] INFO  waiting for tasks
09:38:32.756 [ExtractorRunnerSpec-akka.actor.default-dispatcher-2][akka://ExtractorRunnerSpec/user/$e][ExtractorRunner] INFO  Received task=testExtractor. Executing
09:38:32.756 [ExtractorRunnerSpec-akka.actor.default-dispatcher-2][akka://ExtractorRunnerSpec/user/$e][ExtractorRunner] INFO  Starting 1 children process workers
09:38:32.757 [ExtractorRunnerSpec-akka.actor.default-dispatcher-3][akka://ExtractorRunnerSpec/user/$e][ExtractorRunner] INFO  Getting data from the data store and sending it to the workers. query='DatastoreInputQuery(SELECT 5)'
09:38:32.757 [ExtractorRunnerSpec-akka.actor.default-dispatcher-4][akka://ExtractorRunnerSpec/user/$e/processExecutor1][ProcessExecutor] INFO  started
09:38:32.757 [ExtractorRunnerSpec-akka.actor.default-dispatcher-4][akka://ExtractorRunnerSpec/user/$e/processExecutor1][ProcessExecutor] INFO  starting process with cmd="/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test6958481867116430570.py" and batch_size=1000
09:38:32.757 [ExtractorRunnerSpec-akka.actor.default-dispatcher-3][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG SELECT 5
09:38:32.757 [ExtractorRunnerSpec-akka.actor.default-dispatcher-3][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG QUERY PLAN
09:38:32.757 [ExtractorRunnerSpec-akka.actor.default-dispatcher-3][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG Result  (cost=0.00..0.01 rows=1 width=0)
09:38:32.762 [ExtractorRunnerSpec-akka.actor.default-dispatcher-3][akka://ExtractorRunnerSpec/user/$e][ExtractorRunner] DEBUG all data was sent to workers.
09:38:32.763 [ExtractorRunnerSpec-akka.actor.default-dispatcher-4][akka://ExtractorRunnerSpec/user/$e/processExecutor1][ProcessExecutor] DEBUG closing input stream
09:38:32.766 [Thread-216][akka://ExtractorRunnerSpec/user/$e/processExecutor1][ProcessExecutor] DEBUG closing output stream
09:38:32.766 [ExtractorRunnerSpec-akka.actor.default-dispatcher-4][akka://ExtractorRunnerSpec/user/$e/processExecutor1][ProcessExecutor] INFO  process exited with exit_value=0
09:38:32.766 [ExtractorRunnerSpec-akka.actor.default-dispatcher-2][akka://ExtractorRunnerSpec/user/$e][ExtractorRunner] DEBUG worker=processExecutor1 has terminated. Waiting for 0 others.
09:38:32.766 [ExtractorRunnerSpec-akka.actor.default-dispatcher-2][akka://ExtractorRunnerSpec/user/$e][ExtractorRunner] INFO  All workers are done. Finishing up.
09:38:32.766 [ExtractorRunnerSpec-akka.actor.default-dispatcher-2][akka://ExtractorRunnerSpec/user/$e][ExtractorRunner] INFO  Analyzing output relation.
09:38:32.767 [ExtractorRunnerSpec-akka.actor.default-dispatcher-2][akka://ExtractorRunnerSpec/user/$e][ExtractorRunner] INFO  Executing after script.
09:38:32.767 [ExtractorRunnerSpec-akka.actor.default-dispatcher-2][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/bin/i_am_not_exist" 
09:38:32.773 [ExtractorRunnerSpec-akka.actor.default-dispatcher-2][akka://ExtractorRunnerSpec/user/$e][ExtractorRunner] ERROR java.io.IOException: Cannot run program "/bin/i_am_not_exist": error=2, No such file or directory
09:38:32.774 [ExtractorRunnerSpec-akka.actor.default-dispatcher-3][akka://ExtractorRunnerSpec/user/$e][OneForOneStrategy] ERROR java.io.IOException: Cannot run program "/bin/i_am_not_exist": error=2, No such file or directory
java.lang.RuntimeException: java.io.IOException: Cannot run program "/bin/i_am_not_exist": error=2, No such file or directory
	at org.deepdive.extraction.ExtractorRunner.org$deepdive$extraction$ExtractorRunner$$executeScriptOrFail(ExtractorRunner.scala:298) ~[classes/:na]
	at org.deepdive.extraction.ExtractorRunner$$anonfun$4$$anonfun$applyOrElse$6.apply(ExtractorRunner.scala:211) ~[classes/:na]
	at org.deepdive.extraction.ExtractorRunner$$anonfun$4$$anonfun$applyOrElse$6.apply(ExtractorRunner.scala:207) ~[classes/:na]
	at scala.Option.foreach(Option.scala:236) ~[scala-library.jar:0.13.7]
	at org.deepdive.extraction.ExtractorRunner$$anonfun$4.applyOrElse(ExtractorRunner.scala:206) ~[classes/:na]
	at org.deepdive.extraction.ExtractorRunner$$anonfun$4.applyOrElse(ExtractorRunner.scala:203) ~[classes/:na]
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:33) ~[scala-library.jar:0.13.7]
	at akka.actor.FSM$class.processEvent(FSM.scala:587) ~[akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at org.deepdive.extraction.ExtractorRunner.processEvent(ExtractorRunner.scala:59) ~[classes/:na]
	at akka.actor.FSM$class.akka$actor$FSM$$processMsg(FSM.scala:581) ~[akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:575) ~[akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at akka.actor.Actor$class.aroundReceive(Actor.scala:467) ~[akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at org.deepdive.extraction.ExtractorRunner.aroundReceive(ExtractorRunner.scala:59) ~[classes/:na]
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:491) [akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at akka.actor.ActorCell.invoke(ActorCell.scala:462) [akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:237) [akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at akka.dispatch.Mailbox.run(Mailbox.scala:219) [akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:385) [akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [scala-library.jar:na]
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [scala-library.jar:na]
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [scala-library.jar:na]
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [scala-library.jar:na]
09:38:32.780 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG EXECUTING.... drop table if exists testtable;
09:38:32.781 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG DONE!
09:38:32.781 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG EXECUTING.... create table testtable ( a text );
09:38:32.783 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG DONE!
09:38:32.783 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] INFO  /var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test185403360237469895.py
09:38:32.784 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG Writing to file /var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test185403360237469895.py:
#! /usr/bin/python
 echo "I should also be in the table" >> /var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test2363907883445278385.tsv
      
09:38:32.784 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG Writing to file /var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test478639008925166985.py:
#! /usr/bin/python
import json
for l in open('/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test2363907883445278385.tsv'):
  print json.dumps({'a':l.strip()})


09:38:32.784 [ExtractorRunnerSpec-akka.actor.default-dispatcher-2][akka://ExtractorRunnerSpec/user/$f][ExtractorRunner] INFO  waiting for tasks
09:38:32.784 [ExtractorRunnerSpec-akka.actor.default-dispatcher-2][akka://ExtractorRunnerSpec/user/$f][ExtractorRunner] INFO  Received task=testExtractor. Executing
09:38:32.784 [ExtractorRunnerSpec-akka.actor.default-dispatcher-2][akka://ExtractorRunnerSpec/user/$f][ExtractorRunner] INFO  Starting 1 children process workers
09:38:32.784 [ExtractorRunnerSpec-akka.actor.default-dispatcher-4][akka://ExtractorRunnerSpec/user/$f/processExecutor1][ProcessExecutor] INFO  started
09:38:32.785 [ExtractorRunnerSpec-akka.actor.default-dispatcher-3][akka://ExtractorRunnerSpec/user/$f][ExtractorRunner] INFO  Getting data from the data store and sending it to the workers. query='DatastoreInputQuery(SELECT 5)'
09:38:32.785 [ExtractorRunnerSpec-akka.actor.default-dispatcher-4][akka://ExtractorRunnerSpec/user/$f/processExecutor1][ProcessExecutor] INFO  starting process with cmd="/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test478639008925166985.py" and batch_size=1000
09:38:32.785 [ExtractorRunnerSpec-akka.actor.default-dispatcher-3][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG SELECT 5
09:38:32.785 [ExtractorRunnerSpec-akka.actor.default-dispatcher-3][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG QUERY PLAN
09:38:32.785 [ExtractorRunnerSpec-akka.actor.default-dispatcher-3][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG Result  (cost=0.00..0.01 rows=1 width=0)
09:38:32.791 [ExtractorRunnerSpec-akka.actor.default-dispatcher-3][akka://ExtractorRunnerSpec/user/$f][ExtractorRunner] DEBUG all data was sent to workers.
09:38:32.792 [ExtractorRunnerSpec-akka.actor.default-dispatcher-4][akka://ExtractorRunnerSpec/user/$f/processExecutor1][ProcessExecutor] DEBUG closing input stream
09:38:32.824 [Thread-219][akka://ExtractorRunnerSpec/user/$f/processExecutor1][ProcessExecutor] DEBUG closing output stream
09:38:32.824 [ExtractorRunnerSpec-akka.actor.default-dispatcher-4][akka://ExtractorRunnerSpec/user/$f/processExecutor1][ProcessExecutor] INFO  process exited with exit_value=0
09:38:32.824 [ExtractorRunnerSpec-akka.actor.default-dispatcher-5][akka://ExtractorRunnerSpec/user/$f][ExtractorRunner] DEBUG worker=processExecutor1 has terminated. Waiting for 0 others.
09:38:32.824 [ExtractorRunnerSpec-akka.actor.default-dispatcher-5][akka://ExtractorRunnerSpec/user/$f][ExtractorRunner] INFO  All workers are done. Finishing up.
09:38:32.825 [ExtractorRunnerSpec-akka.actor.default-dispatcher-5][akka://ExtractorRunnerSpec/user/$f][ExtractorRunner] INFO  Analyzing output relation.
09:38:32.825 [ExtractorRunnerSpec-akka.actor.default-dispatcher-5][akka://ExtractorRunnerSpec/user/$f][ExtractorRunner] INFO  Executing after script.
09:38:32.825 [ExtractorRunnerSpec-akka.actor.default-dispatcher-5][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test185403360237469895.py" 
09:38:32.858 [Thread-223][Helpers$(akka://deepdive)][Helpers$] INFO    File "/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test185403360237469895.py", line 2
09:38:32.858 [Thread-223][Helpers$(akka://deepdive)][Helpers$] INFO      echo "I should also be in the table" >> /var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test2363907883445278385.tsv
09:38:32.858 [Thread-223][Helpers$(akka://deepdive)][Helpers$] INFO      ^
09:38:32.858 [Thread-223][Helpers$(akka://deepdive)][Helpers$] INFO  IndentationError: unexpected indent
09:38:32.860 [ExtractorRunnerSpec-akka.actor.default-dispatcher-5][akka://ExtractorRunnerSpec/user/$f][ExtractorRunner] ERROR java.lang.RuntimeException: Failure when executing script: /var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test185403360237469895.py
09:38:32.861 [ExtractorRunnerSpec-akka.actor.default-dispatcher-4][akka://ExtractorRunnerSpec/user/$f][OneForOneStrategy] ERROR java.lang.RuntimeException: Failure when executing script: /var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test185403360237469895.py
java.lang.RuntimeException: java.lang.RuntimeException: Failure when executing script: /var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test185403360237469895.py
	at org.deepdive.extraction.ExtractorRunner.org$deepdive$extraction$ExtractorRunner$$executeScriptOrFail(ExtractorRunner.scala:298) ~[classes/:na]
	at org.deepdive.extraction.ExtractorRunner$$anonfun$4$$anonfun$applyOrElse$6.apply(ExtractorRunner.scala:211) ~[classes/:na]
	at org.deepdive.extraction.ExtractorRunner$$anonfun$4$$anonfun$applyOrElse$6.apply(ExtractorRunner.scala:207) ~[classes/:na]
	at scala.Option.foreach(Option.scala:236) ~[scala-library.jar:0.13.7]
	at org.deepdive.extraction.ExtractorRunner$$anonfun$4.applyOrElse(ExtractorRunner.scala:206) ~[classes/:na]
	at org.deepdive.extraction.ExtractorRunner$$anonfun$4.applyOrElse(ExtractorRunner.scala:203) ~[classes/:na]
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:33) ~[scala-library.jar:0.13.7]
	at akka.actor.FSM$class.processEvent(FSM.scala:587) ~[akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at org.deepdive.extraction.ExtractorRunner.processEvent(ExtractorRunner.scala:59) ~[classes/:na]
	at akka.actor.FSM$class.akka$actor$FSM$$processMsg(FSM.scala:581) ~[akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:575) ~[akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at akka.actor.Actor$class.aroundReceive(Actor.scala:467) ~[akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at org.deepdive.extraction.ExtractorRunner.aroundReceive(ExtractorRunner.scala:59) ~[classes/:na]
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:491) [akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at akka.actor.ActorCell.invoke(ActorCell.scala:462) [akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:237) [akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at akka.dispatch.Mailbox.run(Mailbox.scala:219) [akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:385) [akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [scala-library.jar:na]
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [scala-library.jar:na]
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [scala-library.jar:na]
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [scala-library.jar:na]
09:38:32.867 [ExtractorRunnerSpec-akka.actor.default-dispatcher-5][akka://ExtractorRunnerSpec/user/$g][ExtractorRunner] INFO  waiting for tasks
09:38:32.868 [ScalaTest-running-ExtractorRunnerSpec][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG Writing data of to file=/private/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/deepdive_relation15759151886104799246.csv
09:38:32.873 [ScalaTest-running-ExtractorRunnerSpec][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG Copying batch data to postgres. sql='COPY relation1(key) FROM STDIN CSV'file='/private/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/deepdive_relation15759151886104799246.csv'
09:38:32.874 [ScalaTest-running-ExtractorRunnerSpec][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG Successfully copied batch data to postgres.
09:38:32.877 [ExtractorRunnerSpec-akka.actor.default-dispatcher-3][akka://ExtractorRunnerSpec/user/$g][ExtractorRunner] INFO  Received task=testExtractor. Executing
09:38:32.877 [ExtractorRunnerSpec-akka.actor.default-dispatcher-3][akka://ExtractorRunnerSpec/user/$g][ExtractorRunner] INFO  Starting 1 children process workers
09:38:32.877 [ExtractorRunnerSpec-akka.actor.default-dispatcher-2][akka://ExtractorRunnerSpec/user/$g][ExtractorRunner] INFO  Getting data from the data store and sending it to the workers. query='DatastoreInputQuery(SELECT * FROM relation1)'
09:38:32.877 [ExtractorRunnerSpec-akka.actor.default-dispatcher-4][akka://ExtractorRunnerSpec/user/$g/processExecutor1][ProcessExecutor] INFO  started
09:38:32.877 [ExtractorRunnerSpec-akka.actor.default-dispatcher-4][akka://ExtractorRunnerSpec/user/$g/processExecutor1][ProcessExecutor] INFO  starting process with cmd="/bin/cat" and batch_size=1000
09:38:32.878 [ExtractorRunnerSpec-akka.actor.default-dispatcher-2][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG SELECT * FROM relation1
09:38:32.878 [ExtractorRunnerSpec-akka.actor.default-dispatcher-2][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG QUERY PLAN
09:38:32.878 [ExtractorRunnerSpec-akka.actor.default-dispatcher-2][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG Seq Scan on relation1  (cost=0.00..29.40 rows=1940 width=12)
09:38:32.884 [ExtractorRunnerSpec-akka.actor.default-dispatcher-2][akka://ExtractorRunnerSpec/user/$g][ExtractorRunner] DEBUG all data was sent to workers.
09:38:32.885 [ExtractorRunnerSpec-akka.actor.default-dispatcher-3][akka://ExtractorRunnerSpec/user/$g/processExecutor1][ProcessExecutor] DEBUG closing input stream
09:38:32.887 [ExtractorRunnerSpec-akka.actor.default-dispatcher-3][akka://ExtractorRunnerSpec/user/$g][ExtractorRunner] DEBUG adding chunk of size=1 data store.
09:38:32.887 [ExtractorRunnerSpec-akka.actor.default-dispatcher-3][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG Writing data of to file=/private/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/deepdive_relation12895803938760324186.csv
09:38:32.892 [ExtractorRunnerSpec-akka.actor.default-dispatcher-3][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG Copying batch data to postgres. sql='COPY relation1(key) FROM STDIN CSV'file='/private/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/deepdive_relation12895803938760324186.csv'
09:38:32.893 [ExtractorRunnerSpec-akka.actor.default-dispatcher-3][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG Successfully copied batch data to postgres.
09:38:32.893 [Thread-225][akka://ExtractorRunnerSpec/user/$g/processExecutor1][ProcessExecutor] DEBUG closing output stream
09:38:32.894 [ExtractorRunnerSpec-akka.actor.default-dispatcher-4][akka://ExtractorRunnerSpec/user/$g/processExecutor1][ProcessExecutor] INFO  process exited with exit_value=0
09:38:32.894 [ExtractorRunnerSpec-akka.actor.default-dispatcher-3][akka://ExtractorRunnerSpec/user/$g][ExtractorRunner] DEBUG worker=processExecutor1 has terminated. Waiting for 0 others.
09:38:32.894 [ExtractorRunnerSpec-akka.actor.default-dispatcher-3][akka://ExtractorRunnerSpec/user/$g][ExtractorRunner] INFO  All workers are done. Finishing up.
09:38:32.894 [ExtractorRunnerSpec-akka.actor.default-dispatcher-3][akka://ExtractorRunnerSpec/user/$g][ExtractorRunner] INFO  Shutting down
09:38:32.902 [ExtractorRunnerSpec-akka.actor.default-dispatcher-4][akka://ExtractorRunnerSpec/user/$h][ExtractorRunner] INFO  waiting for tasks
09:38:32.902 [ExtractorRunnerSpec-akka.actor.default-dispatcher-4][akka://ExtractorRunnerSpec/user/$h][ExtractorRunner] INFO  Received task=testExtractor. Executing
09:38:32.902 [ExtractorRunnerSpec-akka.actor.default-dispatcher-4][akka://ExtractorRunnerSpec/user/$h][ExtractorRunner] INFO  Starting 1 children process workers
09:38:32.902 [ExtractorRunnerSpec-akka.actor.default-dispatcher-2][akka://ExtractorRunnerSpec/user/$h][ExtractorRunner] INFO  Getting data from the data store and sending it to the workers. query='DatastoreInputQuery(SELECT * FROM relation1)'
09:38:32.902 [ExtractorRunnerSpec-akka.actor.default-dispatcher-5][akka://ExtractorRunnerSpec/user/$h/processExecutor1][ProcessExecutor] INFO  started
09:38:32.902 [ExtractorRunnerSpec-akka.actor.default-dispatcher-5][akka://ExtractorRunnerSpec/user/$h/processExecutor1][ProcessExecutor] INFO  starting process with cmd="/bin/cat" and batch_size=1000
09:38:32.902 [ExtractorRunnerSpec-akka.actor.default-dispatcher-2][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG SELECT * FROM relation1
09:38:32.903 [ExtractorRunnerSpec-akka.actor.default-dispatcher-2][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG QUERY PLAN
09:38:32.903 [ExtractorRunnerSpec-akka.actor.default-dispatcher-2][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG Seq Scan on relation1  (cost=0.00..29.40 rows=1940 width=12)
09:38:32.903 [ExtractorRunnerSpec-akka.actor.default-dispatcher-2][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] WARN  query returned no results: SELECT * FROM relation1
09:38:32.903 [ExtractorRunnerSpec-akka.actor.default-dispatcher-2][akka://ExtractorRunnerSpec/user/$h][ExtractorRunner] DEBUG all data was sent to workers.
09:38:32.909 [ExtractorRunnerSpec-akka.actor.default-dispatcher-5][akka://ExtractorRunnerSpec/user/$h/processExecutor1][ProcessExecutor] DEBUG closing input stream
09:38:32.912 [Thread-228][akka://ExtractorRunnerSpec/user/$h/processExecutor1][ProcessExecutor] DEBUG closing output stream
09:38:32.912 [ExtractorRunnerSpec-akka.actor.default-dispatcher-5][akka://ExtractorRunnerSpec/user/$h/processExecutor1][ProcessExecutor] INFO  process exited with exit_value=0
09:38:32.912 [ExtractorRunnerSpec-akka.actor.default-dispatcher-3][akka://ExtractorRunnerSpec/user/$h][ExtractorRunner] DEBUG worker=processExecutor1 has terminated. Waiting for 0 others.
09:38:32.913 [ExtractorRunnerSpec-akka.actor.default-dispatcher-3][akka://ExtractorRunnerSpec/user/$h][ExtractorRunner] INFO  All workers are done. Finishing up.
09:38:32.913 [ExtractorRunnerSpec-akka.actor.default-dispatcher-3][akka://ExtractorRunnerSpec/user/$h][ExtractorRunner] INFO  Shutting down
09:38:32.918 [ExtractorRunnerSpec-akka.actor.default-dispatcher-3][akka://ExtractorRunnerSpec/user/$i][ExtractorRunner] INFO  waiting for tasks
09:38:32.953 [ScalaTest-running-ExtractorRunnerSpec][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG Writing data of to file=/private/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/deepdive_relation11621621685579191808.csv
09:38:32.969 [ScalaTest-running-ExtractorRunnerSpec][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG Copying batch data to postgres. sql='COPY relation1(key) FROM STDIN CSV'file='/private/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/deepdive_relation11621621685579191808.csv'
09:38:32.974 [ScalaTest-running-ExtractorRunnerSpec][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG Successfully copied batch data to postgres.
09:38:32.975 [ExtractorRunnerSpec-akka.actor.default-dispatcher-3][akka://ExtractorRunnerSpec/user/$i][ExtractorRunner] INFO  Received task=testExtractor. Executing
09:38:32.975 [ExtractorRunnerSpec-akka.actor.default-dispatcher-3][akka://ExtractorRunnerSpec/user/$i][ExtractorRunner] INFO  Starting 4 children process workers
09:38:32.975 [ExtractorRunnerSpec-akka.actor.default-dispatcher-2][akka://ExtractorRunnerSpec/user/$i/processExecutor1][ProcessExecutor] INFO  started
09:38:32.975 [ExtractorRunnerSpec-akka.actor.default-dispatcher-2][akka://ExtractorRunnerSpec/user/$i/processExecutor2][ProcessExecutor] INFO  started
09:38:32.975 [ExtractorRunnerSpec-akka.actor.default-dispatcher-2][akka://ExtractorRunnerSpec/user/$i/processExecutor3][ProcessExecutor] INFO  started
09:38:32.976 [ExtractorRunnerSpec-akka.actor.default-dispatcher-2][akka://ExtractorRunnerSpec/user/$i/processExecutor4][ProcessExecutor] INFO  started
09:38:32.976 [ExtractorRunnerSpec-akka.actor.default-dispatcher-4][akka://ExtractorRunnerSpec/user/$i/processExecutor2][ProcessExecutor] INFO  starting process with cmd="/bin/cat" and batch_size=200
09:38:32.977 [ExtractorRunnerSpec-akka.actor.default-dispatcher-5][akka://ExtractorRunnerSpec/user/$i/processExecutor1][ProcessExecutor] INFO  starting process with cmd="/bin/cat" and batch_size=200
09:38:32.977 [ExtractorRunnerSpec-akka.actor.default-dispatcher-6][akka://ExtractorRunnerSpec/user/$i/processExecutor3][ProcessExecutor] INFO  starting process with cmd="/bin/cat" and batch_size=200
09:38:32.977 [ExtractorRunnerSpec-akka.actor.default-dispatcher-8][akka://ExtractorRunnerSpec/user/$i][ExtractorRunner] INFO  Getting data from the data store and sending it to the workers. query='DatastoreInputQuery(SELECT * FROM relation1)'
09:38:32.977 [ExtractorRunnerSpec-akka.actor.default-dispatcher-2][akka://ExtractorRunnerSpec/user/$i/processExecutor4][ProcessExecutor] INFO  starting process with cmd="/bin/cat" and batch_size=200
09:38:32.978 [ExtractorRunnerSpec-akka.actor.default-dispatcher-8][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG SELECT * FROM relation1
09:38:32.978 [ExtractorRunnerSpec-akka.actor.default-dispatcher-8][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG QUERY PLAN
09:38:32.978 [ExtractorRunnerSpec-akka.actor.default-dispatcher-8][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG Seq Scan on relation1  (cost=0.00..29.40 rows=1940 width=12)
09:38:33.023 [ExtractorRunnerSpec-akka.actor.default-dispatcher-8][akka://ExtractorRunnerSpec/user/$i][ExtractorRunner] DEBUG all data was sent to workers.
09:38:33.024 [ExtractorRunnerSpec-akka.actor.default-dispatcher-10][akka://ExtractorRunnerSpec/user/$i/processExecutor1][ProcessExecutor] DEBUG closing input stream
09:38:33.024 [ExtractorRunnerSpec-akka.actor.default-dispatcher-4][akka://ExtractorRunnerSpec/user/$i/processExecutor2][ProcessExecutor] DEBUG closing input stream
09:38:33.024 [ExtractorRunnerSpec-akka.actor.default-dispatcher-9][akka://ExtractorRunnerSpec/user/$i/processExecutor3][ProcessExecutor] DEBUG closing input stream
09:38:33.024 [Thread-233][akka://ExtractorRunnerSpec/user/$i/processExecutor3][ProcessExecutor] DEBUG closing output stream
09:38:33.024 [ExtractorRunnerSpec-akka.actor.default-dispatcher-3][akka://ExtractorRunnerSpec/user/$i/processExecutor4][ProcessExecutor] DEBUG closing input stream
09:38:33.024 [Thread-239][akka://ExtractorRunnerSpec/user/$i/processExecutor4][ProcessExecutor] DEBUG closing output stream
09:38:33.024 [ExtractorRunnerSpec-akka.actor.default-dispatcher-13][akka://ExtractorRunnerSpec/user/$i/processExecutor3][ProcessExecutor] INFO  process exited with exit_value=0
09:38:33.024 [ExtractorRunnerSpec-akka.actor.default-dispatcher-2][akka://ExtractorRunnerSpec/user/$i/processExecutor4][ProcessExecutor] INFO  process exited with exit_value=0
09:38:33.024 [ExtractorRunnerSpec-akka.actor.default-dispatcher-11][akka://ExtractorRunnerSpec/user/$i][ExtractorRunner] DEBUG adding chunk of size=200 data store.
09:38:33.024 [ExtractorRunnerSpec-akka.actor.default-dispatcher-9][akka://ExtractorRunnerSpec/user/$i][ExtractorRunner] DEBUG adding chunk of size=200 data store.
09:38:33.024 [ExtractorRunnerSpec-akka.actor.default-dispatcher-12][akka://ExtractorRunnerSpec/user/$i][ExtractorRunner] DEBUG worker=processExecutor3 has terminated. Waiting for 3 others.
09:38:33.025 [ExtractorRunnerSpec-akka.actor.default-dispatcher-12][akka://ExtractorRunnerSpec/user/$i][ExtractorRunner] DEBUG worker=processExecutor4 has terminated. Waiting for 2 others.
09:38:33.028 [ExtractorRunnerSpec-akka.actor.default-dispatcher-11][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG Writing data of to file=/private/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/deepdive_relation11640034127014198405.csv
09:38:33.028 [ExtractorRunnerSpec-akka.actor.default-dispatcher-9][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG Writing data of to file=/private/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/deepdive_relation13710510230690292395.csv
09:38:33.034 [ExtractorRunnerSpec-akka.actor.default-dispatcher-9][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG Copying batch data to postgres. sql='COPY relation1(key) FROM STDIN CSV'file='/private/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/deepdive_relation13710510230690292395.csv'
09:38:33.037 [ExtractorRunnerSpec-akka.actor.default-dispatcher-9][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG Successfully copied batch data to postgres.
09:38:33.038 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][akka://ExtractorRunnerSpec/user/$i][ExtractorRunner] DEBUG adding chunk of size=200 data store.
09:38:33.042 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG Writing data of to file=/private/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/deepdive_relation14536904957372773839.csv
09:38:33.046 [ExtractorRunnerSpec-akka.actor.default-dispatcher-11][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG Copying batch data to postgres. sql='COPY relation1(key) FROM STDIN CSV'file='/private/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/deepdive_relation11640034127014198405.csv'
09:38:33.047 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG Copying batch data to postgres. sql='COPY relation1(key) FROM STDIN CSV'file='/private/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/deepdive_relation14536904957372773839.csv'
09:38:33.051 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG Successfully copied batch data to postgres.
09:38:33.051 [ExtractorRunnerSpec-akka.actor.default-dispatcher-9][akka://ExtractorRunnerSpec/user/$i][ExtractorRunner] DEBUG adding chunk of size=100 data store.
09:38:33.054 [ExtractorRunnerSpec-akka.actor.default-dispatcher-9][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG Writing data of to file=/private/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/deepdive_relation16533578732752954755.csv
09:38:33.056 [ExtractorRunnerSpec-akka.actor.default-dispatcher-11][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG Successfully copied batch data to postgres.
09:38:33.056 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][akka://ExtractorRunnerSpec/user/$i][ExtractorRunner] DEBUG adding chunk of size=200 data store.
09:38:33.059 [ExtractorRunnerSpec-akka.actor.default-dispatcher-9][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG Copying batch data to postgres. sql='COPY relation1(key) FROM STDIN CSV'file='/private/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/deepdive_relation16533578732752954755.csv'
09:38:33.060 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG Writing data of to file=/private/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/deepdive_relation16800730413900532497.csv
09:38:33.062 [ExtractorRunnerSpec-akka.actor.default-dispatcher-9][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG Successfully copied batch data to postgres.
09:38:33.063 [Thread-231][akka://ExtractorRunnerSpec/user/$i/processExecutor2][ProcessExecutor] DEBUG closing output stream
09:38:33.063 [ExtractorRunnerSpec-akka.actor.default-dispatcher-9][akka://ExtractorRunnerSpec/user/$i/processExecutor2][ProcessExecutor] INFO  process exited with exit_value=0
09:38:33.063 [ExtractorRunnerSpec-akka.actor.default-dispatcher-11][akka://ExtractorRunnerSpec/user/$i][ExtractorRunner] DEBUG worker=processExecutor2 has terminated. Waiting for 1 others.
09:38:33.067 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG Copying batch data to postgres. sql='COPY relation1(key) FROM STDIN CSV'file='/private/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/deepdive_relation16800730413900532497.csv'
09:38:33.071 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG Successfully copied batch data to postgres.
09:38:33.072 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][akka://ExtractorRunnerSpec/user/$i][ExtractorRunner] DEBUG adding chunk of size=100 data store.
09:38:33.073 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG Writing data of to file=/private/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/deepdive_relation12385271755783462142.csv
09:38:33.078 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG Copying batch data to postgres. sql='COPY relation1(key) FROM STDIN CSV'file='/private/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/deepdive_relation12385271755783462142.csv'
09:38:33.081 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG Successfully copied batch data to postgres.
09:38:33.081 [Thread-236][akka://ExtractorRunnerSpec/user/$i/processExecutor1][ProcessExecutor] DEBUG closing output stream
09:38:33.081 [ExtractorRunnerSpec-akka.actor.default-dispatcher-9][akka://ExtractorRunnerSpec/user/$i/processExecutor1][ProcessExecutor] INFO  process exited with exit_value=0
09:38:33.081 [ExtractorRunnerSpec-akka.actor.default-dispatcher-5][akka://ExtractorRunnerSpec/user/$i][ExtractorRunner] DEBUG worker=processExecutor1 has terminated. Waiting for 0 others.
09:38:33.081 [ExtractorRunnerSpec-akka.actor.default-dispatcher-5][akka://ExtractorRunnerSpec/user/$i][ExtractorRunner] INFO  All workers are done. Finishing up.
09:38:33.081 [ExtractorRunnerSpec-akka.actor.default-dispatcher-5][akka://ExtractorRunnerSpec/user/$i][ExtractorRunner] INFO  Shutting down
09:38:33.095 [ExtractorRunnerSpec-akka.actor.default-dispatcher-5][akka://ExtractorRunnerSpec/user/$j][ExtractorRunner] INFO  waiting for tasks
09:38:33.096 [ScalaTest-running-ExtractorRunnerSpec][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG Writing data of to file=/private/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/deepdive_relation17386126026216559342.csv
09:38:33.100 [ScalaTest-running-ExtractorRunnerSpec][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG Copying batch data to postgres. sql='COPY relation1(key) FROM STDIN CSV'file='/private/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/deepdive_relation17386126026216559342.csv'
09:38:33.102 [ScalaTest-running-ExtractorRunnerSpec][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG Successfully copied batch data to postgres.
09:38:33.103 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][akka://ExtractorRunnerSpec/user/$j][ExtractorRunner] INFO  Received task=testExtractor. Executing
09:38:33.103 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][akka://ExtractorRunnerSpec/user/$j][ExtractorRunner] INFO  Starting 1 children process workers
09:38:33.103 [ExtractorRunnerSpec-akka.actor.default-dispatcher-9][akka://ExtractorRunnerSpec/user/$j][ExtractorRunner] INFO  Getting data from the data store and sending it to the workers. query='DatastoreInputQuery(SELECT * FROM relation1)'
09:38:33.103 [ExtractorRunnerSpec-akka.actor.default-dispatcher-5][akka://ExtractorRunnerSpec/user/$j/processExecutor1][ProcessExecutor] INFO  started
09:38:33.103 [ExtractorRunnerSpec-akka.actor.default-dispatcher-5][akka://ExtractorRunnerSpec/user/$j/processExecutor1][ProcessExecutor] INFO  starting process with cmd="/Users/jackywang/Desktop/341/project/deepdive/target/scala-2.10/test-classes/failing_extractor.py" and batch_size=1000
09:38:33.104 [ExtractorRunnerSpec-akka.actor.default-dispatcher-9][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG SELECT * FROM relation1
09:38:33.104 [ExtractorRunnerSpec-akka.actor.default-dispatcher-9][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG QUERY PLAN
09:38:33.104 [ExtractorRunnerSpec-akka.actor.default-dispatcher-9][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG Seq Scan on relation1  (cost=0.00..29.40 rows=1940 width=12)
09:38:33.111 [ExtractorRunnerSpec-akka.actor.default-dispatcher-9][akka://ExtractorRunnerSpec/user/$j][ExtractorRunner] DEBUG all data was sent to workers.
09:38:33.111 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][akka://ExtractorRunnerSpec/user/$j/processExecutor1][ProcessExecutor] DEBUG closing input stream
09:38:39.177 [Thread-243][akka://ExtractorRunnerSpec/user/$j/processExecutor1][ProcessExecutor] DEBUG closing output stream
09:38:39.177 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][akka://ExtractorRunnerSpec/user/$j/processExecutor1][ProcessExecutor] INFO  process exited with exit_value=1
09:38:39.188 [ExtractorRunnerSpec-akka.actor.default-dispatcher-11][akka://ExtractorRunnerSpec/user/$k][ExtractorRunner] INFO  waiting for tasks
09:38:39.188 [ExtractorRunnerSpec-akka.actor.default-dispatcher-11][akka://ExtractorRunnerSpec/user/$k][ExtractorRunner] INFO  Received task=testExtractor. Executing
09:38:39.188 [ExtractorRunnerSpec-akka.actor.default-dispatcher-11][akka://ExtractorRunnerSpec/user/$k][ExtractorRunner] INFO  Executing before script.
09:38:39.188 [ExtractorRunnerSpec-akka.actor.default-dispatcher-11][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "echo Hello" 
09:38:39.228 [Thread-246][Helpers$(akka://deepdive)][Helpers$] INFO  Hello
09:38:39.229 [ExtractorRunnerSpec-akka.actor.default-dispatcher-11][akka://ExtractorRunnerSpec/user/$k][ExtractorRunner] INFO  Starting 1 children process workers
09:38:39.229 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][akka://ExtractorRunnerSpec/user/$k][ExtractorRunner] INFO  Getting data from the data store and sending it to the workers. query='DatastoreInputQuery(SELECT * FROM relation1)'
09:38:39.229 [ExtractorRunnerSpec-akka.actor.default-dispatcher-9][akka://ExtractorRunnerSpec/user/$k/processExecutor1][ProcessExecutor] INFO  started
09:38:39.229 [ExtractorRunnerSpec-akka.actor.default-dispatcher-9][akka://ExtractorRunnerSpec/user/$k/processExecutor1][ProcessExecutor] INFO  starting process with cmd="/bin/cat" and batch_size=1000
09:38:39.229 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG SELECT * FROM relation1
09:38:39.230 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG QUERY PLAN
09:38:39.230 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG Seq Scan on relation1  (cost=0.00..29.40 rows=1940 width=12)
09:38:39.230 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] WARN  query returned no results: SELECT * FROM relation1
09:38:39.230 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][akka://ExtractorRunnerSpec/user/$k][ExtractorRunner] DEBUG all data was sent to workers.
09:38:39.235 [ExtractorRunnerSpec-akka.actor.default-dispatcher-9][akka://ExtractorRunnerSpec/user/$k/processExecutor1][ProcessExecutor] DEBUG closing input stream
09:38:39.244 [Thread-249][akka://ExtractorRunnerSpec/user/$k/processExecutor1][ProcessExecutor] DEBUG closing output stream
09:38:39.244 [ExtractorRunnerSpec-akka.actor.default-dispatcher-9][akka://ExtractorRunnerSpec/user/$k/processExecutor1][ProcessExecutor] INFO  process exited with exit_value=0
09:38:39.244 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][akka://ExtractorRunnerSpec/user/$k][ExtractorRunner] DEBUG worker=processExecutor1 has terminated. Waiting for 0 others.
09:38:39.244 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][akka://ExtractorRunnerSpec/user/$k][ExtractorRunner] INFO  All workers are done. Finishing up.
09:38:39.244 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][akka://ExtractorRunnerSpec/user/$k][ExtractorRunner] INFO  Analyzing output relation.
09:38:39.245 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][akka://ExtractorRunnerSpec/user/$k][ExtractorRunner] INFO  Executing after script.
09:38:39.245 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "echo World" 
09:38:39.252 [Thread-252][Helpers$(akka://deepdive)][Helpers$] INFO  World
09:38:39.252 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][akka://ExtractorRunnerSpec/user/$k][ExtractorRunner] INFO  Shutting down
09:38:39.256 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][akka://ExtractorRunnerSpec/user/$l][ExtractorRunner] INFO  waiting for tasks
09:38:39.256 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][akka://ExtractorRunnerSpec/user/$l][ExtractorRunner] INFO  Received task=testExtractor. Executing
09:38:39.256 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][akka://ExtractorRunnerSpec/user/$l][ExtractorRunner] INFO  Starting 1 children process workers
09:38:39.256 [ExtractorRunnerSpec-akka.actor.default-dispatcher-11][akka://ExtractorRunnerSpec/user/$l][ExtractorRunner] INFO  Getting data from the data store and sending it to the workers. query='DatastoreInputQuery(relation1)'
09:38:39.256 [ExtractorRunnerSpec-akka.actor.default-dispatcher-5][akka://ExtractorRunnerSpec/user/$l/processExecutor1][ProcessExecutor] INFO  started
09:38:39.256 [ExtractorRunnerSpec-akka.actor.default-dispatcher-5][akka://ExtractorRunnerSpec/user/$l/processExecutor1][ProcessExecutor] INFO  starting process with cmd="/bin/cat" and batch_size=1000
09:38:39.256 [ExtractorRunnerSpec-akka.actor.default-dispatcher-11][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG relation1
09:38:39.256 [ExtractorRunnerSpec-akka.actor.default-dispatcher-11][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] ERROR org.postgresql.util.PSQLException: ERROR: syntax error at or near "relation1"
  Position: 9
09:38:39.257 [ExtractorRunnerSpec-akka.actor.default-dispatcher-11][akka://ExtractorRunnerSpec/user/$l][ExtractorRunner] ERROR org.postgresql.util.PSQLException: ERROR: syntax error at or near "relation1"
  Position: 9
09:38:39.268 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/bin/OHNO!" 
09:38:39.268 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][akka://ExtractorRunnerSpec/user/$m][ExtractorRunner] INFO  waiting for tasks
09:38:39.268 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][akka://ExtractorRunnerSpec/user/$m][ExtractorRunner] INFO  Received task=testExtractor. Executing
09:38:39.268 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][akka://ExtractorRunnerSpec/user/$m][ExtractorRunner] INFO  Executing before script.
09:38:39.273 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][akka://ExtractorRunnerSpec/user/$m][ExtractorRunner] ERROR java.io.IOException: Cannot run program "/bin/OHNO!": error=2, No such file or directory
09:38:39.273 [ExtractorRunnerSpec-akka.actor.default-dispatcher-11][akka://ExtractorRunnerSpec/user/$m][OneForOneStrategy] ERROR java.io.IOException: Cannot run program "/bin/OHNO!": error=2, No such file or directory
java.lang.RuntimeException: java.io.IOException: Cannot run program "/bin/OHNO!": error=2, No such file or directory
	at org.deepdive.extraction.ExtractorRunner.org$deepdive$extraction$ExtractorRunner$$executeScriptOrFail(ExtractorRunner.scala:298) ~[classes/:na]
	at org.deepdive.extraction.ExtractorRunner$$anonfun$2$$anonfun$applyOrElse$3.apply(ExtractorRunner.scala:110) ~[classes/:na]
	at org.deepdive.extraction.ExtractorRunner$$anonfun$2$$anonfun$applyOrElse$3.apply(ExtractorRunner.scala:108) ~[classes/:na]
	at scala.Option.foreach(Option.scala:236) ~[scala-library.jar:0.13.7]
	at org.deepdive.extraction.ExtractorRunner$$anonfun$2.applyOrElse(ExtractorRunner.scala:107) ~[classes/:na]
	at org.deepdive.extraction.ExtractorRunner$$anonfun$2.applyOrElse(ExtractorRunner.scala:100) ~[classes/:na]
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:33) ~[scala-library.jar:0.13.7]
	at akka.actor.FSM$class.processEvent(FSM.scala:587) ~[akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at org.deepdive.extraction.ExtractorRunner.processEvent(ExtractorRunner.scala:59) ~[classes/:na]
	at akka.actor.FSM$class.akka$actor$FSM$$processMsg(FSM.scala:581) ~[akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:575) ~[akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at akka.actor.Actor$class.aroundReceive(Actor.scala:467) ~[akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at org.deepdive.extraction.ExtractorRunner.aroundReceive(ExtractorRunner.scala:59) ~[classes/:na]
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:491) [akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at akka.actor.ActorCell.invoke(ActorCell.scala:462) [akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:237) [akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at akka.dispatch.Mailbox.run(Mailbox.scala:219) [akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:385) [akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [scala-library.jar:na]
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [scala-library.jar:na]
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [scala-library.jar:na]
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [scala-library.jar:na]
09:38:39.277 [ExtractorRunnerSpec-akka.actor.default-dispatcher-5][akka://ExtractorRunnerSpec/user/$n][ExtractorRunner] INFO  waiting for tasks
09:38:39.277 [ExtractorRunnerSpec-akka.actor.default-dispatcher-5][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "echo Hello" 
09:38:39.278 [ExtractorRunnerSpec-akka.actor.default-dispatcher-5][akka://ExtractorRunnerSpec/user/$n][ExtractorRunner] INFO  Received task=testExtractor. Executing
09:38:39.278 [ExtractorRunnerSpec-akka.actor.default-dispatcher-5][akka://ExtractorRunnerSpec/user/$n][ExtractorRunner] INFO  Executing before script.
09:38:39.284 [Thread-258][Helpers$(akka://deepdive)][Helpers$] INFO  Hello
09:38:39.285 [ExtractorRunnerSpec-akka.actor.default-dispatcher-5][akka://ExtractorRunnerSpec/user/$n][ExtractorRunner] INFO  Starting 1 children process workers
09:38:39.285 [ExtractorRunnerSpec-akka.actor.default-dispatcher-11][akka://ExtractorRunnerSpec/user/$n][ExtractorRunner] INFO  Getting data from the data store and sending it to the workers. query='DatastoreInputQuery(SELECT * FROM relation1)'
09:38:39.285 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][akka://ExtractorRunnerSpec/user/$n/processExecutor1][ProcessExecutor] INFO  started
09:38:39.285 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][akka://ExtractorRunnerSpec/user/$n/processExecutor1][ProcessExecutor] INFO  starting process with cmd="/bin/cat" and batch_size=1000
09:38:39.286 [ExtractorRunnerSpec-akka.actor.default-dispatcher-11][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG SELECT * FROM relation1
09:38:39.286 [ExtractorRunnerSpec-akka.actor.default-dispatcher-11][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG QUERY PLAN
09:38:39.286 [ExtractorRunnerSpec-akka.actor.default-dispatcher-11][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG Seq Scan on relation1  (cost=0.00..29.40 rows=1940 width=12)
09:38:39.286 [ExtractorRunnerSpec-akka.actor.default-dispatcher-11][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] WARN  query returned no results: SELECT * FROM relation1
09:38:39.287 [ExtractorRunnerSpec-akka.actor.default-dispatcher-11][akka://ExtractorRunnerSpec/user/$n][ExtractorRunner] DEBUG all data was sent to workers.
09:38:39.291 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][akka://ExtractorRunnerSpec/user/$n/processExecutor1][ProcessExecutor] DEBUG closing input stream
09:38:39.295 [Thread-261][akka://ExtractorRunnerSpec/user/$n/processExecutor1][ProcessExecutor] DEBUG closing output stream
09:38:39.295 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][akka://ExtractorRunnerSpec/user/$n/processExecutor1][ProcessExecutor] INFO  process exited with exit_value=0
09:38:39.295 [ExtractorRunnerSpec-akka.actor.default-dispatcher-5][akka://ExtractorRunnerSpec/user/$n][ExtractorRunner] DEBUG worker=processExecutor1 has terminated. Waiting for 0 others.
09:38:39.295 [ExtractorRunnerSpec-akka.actor.default-dispatcher-5][akka://ExtractorRunnerSpec/user/$n][ExtractorRunner] INFO  All workers are done. Finishing up.
09:38:39.295 [ExtractorRunnerSpec-akka.actor.default-dispatcher-5][akka://ExtractorRunnerSpec/user/$n][ExtractorRunner] INFO  Analyzing output relation.
09:38:39.296 [ExtractorRunnerSpec-akka.actor.default-dispatcher-5][akka://ExtractorRunnerSpec/user/$n][ExtractorRunner] INFO  Executing after script.
09:38:39.296 [ExtractorRunnerSpec-akka.actor.default-dispatcher-5][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/bin/OHNO!" 
09:38:39.301 [ExtractorRunnerSpec-akka.actor.default-dispatcher-5][akka://ExtractorRunnerSpec/user/$n][ExtractorRunner] ERROR java.io.IOException: Cannot run program "/bin/OHNO!": error=2, No such file or directory
09:38:39.302 [ExtractorRunnerSpec-akka.actor.default-dispatcher-6][akka://ExtractorRunnerSpec/user/$n][OneForOneStrategy] ERROR java.io.IOException: Cannot run program "/bin/OHNO!": error=2, No such file or directory
java.lang.RuntimeException: java.io.IOException: Cannot run program "/bin/OHNO!": error=2, No such file or directory
	at org.deepdive.extraction.ExtractorRunner.org$deepdive$extraction$ExtractorRunner$$executeScriptOrFail(ExtractorRunner.scala:298) ~[classes/:na]
	at org.deepdive.extraction.ExtractorRunner$$anonfun$4$$anonfun$applyOrElse$6.apply(ExtractorRunner.scala:211) ~[classes/:na]
	at org.deepdive.extraction.ExtractorRunner$$anonfun$4$$anonfun$applyOrElse$6.apply(ExtractorRunner.scala:207) ~[classes/:na]
	at scala.Option.foreach(Option.scala:236) ~[scala-library.jar:0.13.7]
	at org.deepdive.extraction.ExtractorRunner$$anonfun$4.applyOrElse(ExtractorRunner.scala:206) ~[classes/:na]
	at org.deepdive.extraction.ExtractorRunner$$anonfun$4.applyOrElse(ExtractorRunner.scala:203) ~[classes/:na]
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:33) ~[scala-library.jar:0.13.7]
	at akka.actor.FSM$class.processEvent(FSM.scala:587) ~[akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at org.deepdive.extraction.ExtractorRunner.processEvent(ExtractorRunner.scala:59) ~[classes/:na]
	at akka.actor.FSM$class.akka$actor$FSM$$processMsg(FSM.scala:581) ~[akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:575) ~[akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at akka.actor.Actor$class.aroundReceive(Actor.scala:467) ~[akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at org.deepdive.extraction.ExtractorRunner.aroundReceive(ExtractorRunner.scala:59) ~[classes/:na]
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:491) [akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at akka.actor.ActorCell.invoke(ActorCell.scala:462) [akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:237) [akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at akka.dispatch.Mailbox.run(Mailbox.scala:219) [akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:385) [akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [scala-library.jar:na]
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [scala-library.jar:na]
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [scala-library.jar:na]
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [scala-library.jar:na]
09:38:39.307 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG EXECUTING.... drop table if exists testtable ;
09:38:39.307 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG DONE!
09:38:39.307 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG EXECUTING.... create table testtable ( a text );
09:38:39.310 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG DONE!
09:38:39.310 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] INFO  /var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test7707385293490182277.sh
09:38:39.310 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG Writing to file /var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test7707385293490182277.sh:

 echo "I should be in the table" > /var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test2650114542611093336.tsv 
 echo "I should also be in the table" >> /var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test2650114542611093336.tsv
      
09:38:39.311 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG Writing to file /var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test1090992786756208077.py:
#! /usr/bin/python
import json
for l in open('/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test2650114542611093336.tsv'):
  print l.strip()


09:38:39.311 [ExtractorRunnerSpec-akka.actor.default-dispatcher-5][akka://ExtractorRunnerSpec/user/$o][ExtractorRunner] INFO  waiting for tasks
09:38:39.311 [ExtractorRunnerSpec-akka.actor.default-dispatcher-5][akka://ExtractorRunnerSpec/user/$o][ExtractorRunner] INFO  Received task=testExtractor. Executing
09:38:39.311 [ExtractorRunnerSpec-akka.actor.default-dispatcher-5][akka://ExtractorRunnerSpec/user/$o][ExtractorRunner] INFO  Executing before script.
09:38:39.311 [ExtractorRunnerSpec-akka.actor.default-dispatcher-5][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test7707385293490182277.sh" 
09:38:39.325 [ExtractorRunnerSpec-akka.actor.default-dispatcher-5][akka://ExtractorRunnerSpec/user/$o][ExtractorRunner] DEBUG Parallel Loading: false
09:38:39.325 [ExtractorRunnerSpec-akka.actor.default-dispatcher-5][akka://ExtractorRunnerSpec/user/$o][ExtractorRunner] INFO  /Users/jackywang/Desktop/341/project/deepdive/out/tmp/
09:38:39.325 [ExtractorRunnerSpec-akka.actor.default-dispatcher-5][akka://ExtractorRunnerSpec/user/$o][ExtractorRunner] INFO  Executing: find /Users/jackywang/Desktop/341/project/deepdive/out/tmp -name 'testtable.copy_query_func_testExtractor.tsv*' 2>/dev/null -print0 | xargs -0 rm -f
09:38:39.325 [ExtractorRunnerSpec-akka.actor.default-dispatcher-5][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/Users/jackywang/Desktop/341/project/deepdive/out/tmp/exec_delete.sh" 
09:38:39.357 [ExtractorRunnerSpec-akka.actor.default-dispatcher-5][Helpers$(akka://deepdive)][Helpers$] DEBUG Executing queries by file: psql  -d deepdive_test  -U jackywang  -p 5432  -h localhost  -c 'COPY (SELECT 5) TO STDOUT;'   > /Users/jackywang/Desktop/341/project/deepdive/out/tmp/testtable.copy_query_func_testExtractor.tsv
09:38:39.357 [ExtractorRunnerSpec-akka.actor.default-dispatcher-5][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/exec_sql8342364660466156886.sh" 
09:38:39.397 [ExtractorRunnerSpec-akka.actor.default-dispatcher-5][akka://ExtractorRunnerSpec/user/$o][ExtractorRunner] INFO  File dumped to /Users/jackywang/Desktop/341/project/deepdive/out/tmp/testtable.copy_query_func_testExtractor.tsv
09:38:39.398 [ExtractorRunnerSpec-akka.actor.default-dispatcher-5][akka://ExtractorRunnerSpec/user/$o][ExtractorRunner] INFO  Executing split command...
09:38:39.398 [ExtractorRunnerSpec-akka.actor.default-dispatcher-5][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "split -a 10 -l 1000 /Users/jackywang/Desktop/341/project/deepdive/out/tmp/testtable.copy_query_func_testExtractor.tsv /Users/jackywang/Desktop/341/project/deepdive/out/tmp/testtable.copy_query_func_testExtractor.tsv-" 
09:38:39.407 [ExtractorRunnerSpec-akka.actor.default-dispatcher-5][akka://ExtractorRunnerSpec/user/$o][ExtractorRunner] INFO  Executing parallel UDF command: find /Users/jackywang/Desktop/341/project/deepdive/out/tmp -name 'testtable.copy_query_func_testExtractor.tsv-*' 2>/dev/null -print0 | xargs -0 -P 1 -L 1 bash -c '/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test1090992786756208077.py < "$0" > "$0.out"'
09:38:39.407 [ExtractorRunnerSpec-akka.actor.default-dispatcher-5][akka://ExtractorRunnerSpec/user/$o][ExtractorRunner] DEBUG Temporary UDF file saved to /Users/jackywang/Desktop/341/project/deepdive/out/tmp/exec_parallel_udf.sh
09:38:39.407 [ExtractorRunnerSpec-akka.actor.default-dispatcher-5][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/Users/jackywang/Desktop/341/project/deepdive/out/tmp/exec_parallel_udf.sh" 
09:38:39.464 [ExtractorRunnerSpec-akka.actor.default-dispatcher-5][DataLoader(akka://deepdive)][DataLoader] INFO  find /Users/jackywang/Desktop/341/project/deepdive/out/tmp/testtable.copy_query_func_testExtractor.tsv-*.out -print0 | xargs -0 -P 1 -L 1 bash -c 'psql  -d deepdive_test  -U jackywang  -p 5432  -h localhost -c "COPY testtable FROM STDIN; " < $0'
09:38:39.464 [ExtractorRunnerSpec-akka.actor.default-dispatcher-5][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/testtable.copy5278843873925736883.sh" 
09:38:39.504 [Thread-279][Helpers$(akka://deepdive)][Helpers$] INFO  COPY 2
09:38:39.505 [ExtractorRunnerSpec-akka.actor.default-dispatcher-5][akka://ExtractorRunnerSpec/user/$o][ExtractorRunner] INFO  Analyzing output relation.
09:38:39.508 [ExtractorRunnerSpec-akka.actor.default-dispatcher-5][akka://ExtractorRunnerSpec/user/$o][ExtractorRunner] INFO  Removing temporary files...
09:38:39.508 [ExtractorRunnerSpec-akka.actor.default-dispatcher-5][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/Users/jackywang/Desktop/341/project/deepdive/out/tmp/exec_delete.sh" 
09:38:39.527 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG EXECUTING.... DELETE FROM testtable WHERE a='I should be in the table';
09:38:39.528 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG DONE!
09:38:39.528 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG EXECUTING.... DELETE FROM testtable WHERE a='I should also be in the table';
09:38:39.529 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG DONE!
09:38:39.536 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG EXECUTING.... drop table if exists testtable ;
09:38:39.536 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG DONE!
09:38:39.536 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG EXECUTING.... create table testtable ( a text );
09:38:39.538 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG DONE!
09:38:39.539 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] INFO  /var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test6173341252487717813.sh
09:38:39.539 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG Writing to file /var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test6173341252487717813.sh:

 psql  -d deepdive_test  -U jackywang  -p 5432  -h localhost  -c  "INSERT INTO testtable VALUES ('Mesasge_1'), ('Mesasge_2'), ('Mesasge_3'), ('Mesasge_4'), ('Mesasge_5'), ('Mesasge_6'), ('Mesasge_7'), ('Mesasge_8'), ('Mesasge_9'), ('Mesasge_10');"
      
09:38:39.539 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG Writing to file /var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test1541453810549543865.py:
#! /usr/bin/python
import json, sys
for l in sys.stdin:
  print l.strip()


09:38:39.540 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][akka://ExtractorRunnerSpec/user/$p][ExtractorRunner] INFO  waiting for tasks
09:38:39.540 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test6173341252487717813.sh" 
09:38:39.540 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][akka://ExtractorRunnerSpec/user/$p][ExtractorRunner] INFO  Received task=testExtractor. Executing
09:38:39.540 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][akka://ExtractorRunnerSpec/user/$p][ExtractorRunner] INFO  Executing before script.
09:38:39.573 [Thread-285][Helpers$(akka://deepdive)][Helpers$] INFO  INSERT 0 10
09:38:39.574 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][akka://ExtractorRunnerSpec/user/$p][ExtractorRunner] DEBUG Parallel Loading: false
09:38:39.574 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][akka://ExtractorRunnerSpec/user/$p][ExtractorRunner] INFO  /Users/jackywang/Desktop/341/project/deepdive/out/tmp/
09:38:39.574 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][akka://ExtractorRunnerSpec/user/$p][ExtractorRunner] INFO  Executing: find /Users/jackywang/Desktop/341/project/deepdive/out/tmp -name 'testtable.copy_query_func_testExtractor.tsv*' 2>/dev/null -print0 | xargs -0 rm -f
09:38:39.575 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/Users/jackywang/Desktop/341/project/deepdive/out/tmp/exec_delete.sh" 
09:38:39.588 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][Helpers$(akka://deepdive)][Helpers$] DEBUG Executing queries by file: psql  -d deepdive_test  -U jackywang  -p 5432  -h localhost  -c 'COPY (SELECT * FROM testtable) TO STDOUT;'   > /Users/jackywang/Desktop/341/project/deepdive/out/tmp/testtable.copy_query_func_testExtractor.tsv
09:38:39.588 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/exec_sql7290419407594681773.sh" 
09:38:39.621 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][akka://ExtractorRunnerSpec/user/$p][ExtractorRunner] INFO  File dumped to /Users/jackywang/Desktop/341/project/deepdive/out/tmp/testtable.copy_query_func_testExtractor.tsv
09:38:39.621 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][akka://ExtractorRunnerSpec/user/$p][ExtractorRunner] INFO  Executing split command...
09:38:39.622 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "split -a 10 -l 1000 /Users/jackywang/Desktop/341/project/deepdive/out/tmp/testtable.copy_query_func_testExtractor.tsv /Users/jackywang/Desktop/341/project/deepdive/out/tmp/testtable.copy_query_func_testExtractor.tsv-" 
09:38:39.630 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][akka://ExtractorRunnerSpec/user/$p][ExtractorRunner] INFO  Executing parallel UDF command: find /Users/jackywang/Desktop/341/project/deepdive/out/tmp -name 'testtable.copy_query_func_testExtractor.tsv-*' 2>/dev/null -print0 | xargs -0 -P 1 -L 1 bash -c '/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test1541453810549543865.py < "$0" > "$0.out"'
09:38:39.630 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][akka://ExtractorRunnerSpec/user/$p][ExtractorRunner] DEBUG Temporary UDF file saved to /Users/jackywang/Desktop/341/project/deepdive/out/tmp/exec_parallel_udf.sh
09:38:39.631 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/Users/jackywang/Desktop/341/project/deepdive/out/tmp/exec_parallel_udf.sh" 
09:38:39.688 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][DataLoader(akka://deepdive)][DataLoader] INFO  find /Users/jackywang/Desktop/341/project/deepdive/out/tmp/testtable.copy_query_func_testExtractor.tsv-*.out -print0 | xargs -0 -P 1 -L 1 bash -c 'psql  -d deepdive_test  -U jackywang  -p 5432  -h localhost -c "COPY testtable FROM STDIN; " < $0'
09:38:39.688 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/testtable.copy7742108314657443541.sh" 
09:38:39.726 [Thread-300][Helpers$(akka://deepdive)][Helpers$] INFO  COPY 10
09:38:39.727 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][akka://ExtractorRunnerSpec/user/$p][ExtractorRunner] INFO  Analyzing output relation.
09:38:39.728 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][akka://ExtractorRunnerSpec/user/$p][ExtractorRunner] INFO  Removing temporary files...
09:38:39.728 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/Users/jackywang/Desktop/341/project/deepdive/out/tmp/exec_delete.sh" 
09:38:39.747 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG EXECUTING.... DELETE FROM testtable WHERE a='Mesasge_1';
09:38:39.748 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG DONE!
09:38:39.748 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG EXECUTING.... DELETE FROM testtable WHERE a='Mesasge_2';
09:38:39.749 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG DONE!
09:38:39.749 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG EXECUTING.... DELETE FROM testtable WHERE a='Mesasge_3';
09:38:39.750 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG DONE!
09:38:39.750 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG EXECUTING.... DELETE FROM testtable WHERE a='Mesasge_4';
09:38:39.751 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG DONE!
09:38:39.751 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG EXECUTING.... DELETE FROM testtable WHERE a='Mesasge_5';
09:38:39.751 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG DONE!
09:38:39.751 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG EXECUTING.... DELETE FROM testtable WHERE a='Mesasge_6';
09:38:39.752 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG DONE!
09:38:39.752 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG EXECUTING.... DELETE FROM testtable WHERE a='Mesasge_7';
09:38:39.752 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG DONE!
09:38:39.752 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG EXECUTING.... DELETE FROM testtable WHERE a='Mesasge_8';
09:38:39.753 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG DONE!
09:38:39.753 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG EXECUTING.... DELETE FROM testtable WHERE a='Mesasge_9';
09:38:39.753 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG DONE!
09:38:39.753 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG EXECUTING.... DELETE FROM testtable WHERE a='Mesasge_10';
09:38:39.754 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG DONE!
09:38:39.764 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG EXECUTING.... drop table if exists testtable ;
09:38:39.764 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG DONE!
09:38:39.764 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG EXECUTING.... create table testtable ( a text, b text );
09:38:39.766 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG DONE!
09:38:39.766 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] INFO  /var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test3288436196512949053.sh
09:38:39.766 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG Writing to file /var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test3288436196512949053.sh:

 psql  -d deepdive_test  -U jackywang  -p 5432  -h localhost  -c  "INSERT INTO testtable VALUES ('Mesasge_1', '1'), ('Mesasge_2', '1'), ('Mesasge_3', '1'), ('Mesasge_4', '1'), ('Mesasge_5', '1'), ('Mesasge_6', '1'), ('Mesasge_7', '1'), ('Mesasge_8', '1'), ('Mesasge_9', '1'), ('Mesasge_10', '1');"
      
09:38:39.767 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG Writing to file /var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test1134480044052199146.py:
#! /usr/bin/python
import json, sys
for l in sys.stdin:
  print "	".join(['abcdefg', "2"])


09:38:39.767 [ExtractorRunnerSpec-akka.actor.default-dispatcher-5][akka://ExtractorRunnerSpec/user/$q][ExtractorRunner] INFO  waiting for tasks
09:38:39.767 [ExtractorRunnerSpec-akka.actor.default-dispatcher-5][akka://ExtractorRunnerSpec/user/$q][ExtractorRunner] INFO  Received task=testExtractor. Executing
09:38:39.767 [ExtractorRunnerSpec-akka.actor.default-dispatcher-5][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test3288436196512949053.sh" 
09:38:39.767 [ExtractorRunnerSpec-akka.actor.default-dispatcher-5][akka://ExtractorRunnerSpec/user/$q][ExtractorRunner] INFO  Executing before script.
09:38:39.798 [Thread-306][Helpers$(akka://deepdive)][Helpers$] INFO  INSERT 0 10
09:38:39.799 [ExtractorRunnerSpec-akka.actor.default-dispatcher-5][akka://ExtractorRunnerSpec/user/$q][ExtractorRunner] DEBUG Parallel Loading: false
09:38:39.799 [ExtractorRunnerSpec-akka.actor.default-dispatcher-5][akka://ExtractorRunnerSpec/user/$q][ExtractorRunner] INFO  /Users/jackywang/Desktop/341/project/deepdive/out/tmp/
09:38:39.799 [ExtractorRunnerSpec-akka.actor.default-dispatcher-5][akka://ExtractorRunnerSpec/user/$q][ExtractorRunner] INFO  Executing: find /Users/jackywang/Desktop/341/project/deepdive/out/tmp -name 'testtable.copy_query_func_testExtractor.tsv*' 2>/dev/null -print0 | xargs -0 rm -f
09:38:39.799 [ExtractorRunnerSpec-akka.actor.default-dispatcher-5][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/Users/jackywang/Desktop/341/project/deepdive/out/tmp/exec_delete.sh" 
09:38:39.812 [ExtractorRunnerSpec-akka.actor.default-dispatcher-5][Helpers$(akka://deepdive)][Helpers$] DEBUG Executing queries by file: psql  -d deepdive_test  -U jackywang  -p 5432  -h localhost  -c 'COPY (SELECT * FROM testtable) TO STDOUT;'   > /Users/jackywang/Desktop/341/project/deepdive/out/tmp/testtable.copy_query_func_testExtractor.tsv
09:38:39.812 [ExtractorRunnerSpec-akka.actor.default-dispatcher-5][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/exec_sql7329318555726118444.sh" 
09:38:39.845 [ExtractorRunnerSpec-akka.actor.default-dispatcher-5][akka://ExtractorRunnerSpec/user/$q][ExtractorRunner] INFO  File dumped to /Users/jackywang/Desktop/341/project/deepdive/out/tmp/testtable.copy_query_func_testExtractor.tsv
09:38:39.846 [ExtractorRunnerSpec-akka.actor.default-dispatcher-5][akka://ExtractorRunnerSpec/user/$q][ExtractorRunner] INFO  Executing split command...
09:38:39.846 [ExtractorRunnerSpec-akka.actor.default-dispatcher-5][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "split -a 10 -l 1000 /Users/jackywang/Desktop/341/project/deepdive/out/tmp/testtable.copy_query_func_testExtractor.tsv /Users/jackywang/Desktop/341/project/deepdive/out/tmp/testtable.copy_query_func_testExtractor.tsv-" 
09:38:39.856 [ExtractorRunnerSpec-akka.actor.default-dispatcher-5][akka://ExtractorRunnerSpec/user/$q][ExtractorRunner] INFO  Executing parallel UDF command: find /Users/jackywang/Desktop/341/project/deepdive/out/tmp -name 'testtable.copy_query_func_testExtractor.tsv-*' 2>/dev/null -print0 | xargs -0 -P 1 -L 1 bash -c '/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test1134480044052199146.py < "$0" > "$0.out"'
09:38:39.856 [ExtractorRunnerSpec-akka.actor.default-dispatcher-5][akka://ExtractorRunnerSpec/user/$q][ExtractorRunner] DEBUG Temporary UDF file saved to /Users/jackywang/Desktop/341/project/deepdive/out/tmp/exec_parallel_udf.sh
09:38:39.856 [ExtractorRunnerSpec-akka.actor.default-dispatcher-5][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/Users/jackywang/Desktop/341/project/deepdive/out/tmp/exec_parallel_udf.sh" 
09:38:39.915 [ExtractorRunnerSpec-akka.actor.default-dispatcher-5][DataLoader(akka://deepdive)][DataLoader] INFO  find /Users/jackywang/Desktop/341/project/deepdive/out/tmp/testtable.copy_query_func_testExtractor.tsv-*.out -print0 | xargs -0 -P 1 -L 1 bash -c 'psql  -d deepdive_test  -U jackywang  -p 5432  -h localhost -c "COPY testtable FROM STDIN; " < $0'
09:38:39.915 [ExtractorRunnerSpec-akka.actor.default-dispatcher-5][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/testtable.copy7142494500300244650.sh" 
09:38:39.962 [Thread-321][Helpers$(akka://deepdive)][Helpers$] INFO  COPY 10
09:38:39.963 [ExtractorRunnerSpec-akka.actor.default-dispatcher-5][akka://ExtractorRunnerSpec/user/$q][ExtractorRunner] INFO  Analyzing output relation.
09:38:39.964 [ExtractorRunnerSpec-akka.actor.default-dispatcher-5][akka://ExtractorRunnerSpec/user/$q][ExtractorRunner] INFO  Removing temporary files...
09:38:39.965 [ExtractorRunnerSpec-akka.actor.default-dispatcher-5][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/Users/jackywang/Desktop/341/project/deepdive/out/tmp/exec_delete.sh" 
09:38:39.983 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG EXECUTING.... DELETE FROM testtable WHERE b='2';
09:38:39.984 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG DONE!
09:38:39.993 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG EXECUTING.... drop table if exists testtable ;
09:38:39.993 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG DONE!
09:38:39.993 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG EXECUTING.... create table testtable ( a text, b text );
09:38:39.995 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG DONE!
09:38:39.995 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] INFO  /var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test5276434225407747683.sh
09:38:39.995 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG Writing to file /var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test5276434225407747683.sh:

 psql  -d deepdive_test  -U jackywang  -p 5432  -h localhost  -c  "INSERT INTO testtable VALUES ('Mesasge_1', '1'), ('Mesasge_2', '1'), ('Mesasge_3', '1'), ('Mesasge_4', '1'), ('Mesasge_5', '1'), ('Mesasge_6', '1'), ('Mesasge_7', '1'), ('Mesasge_8', '1'), ('Mesasge_9', '1'), ('Mesasge_10', '1');"
      
09:38:39.996 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG Writing to file /var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test5158649729764372577.py:
#! /usr/bin/python
import json, sys
for l in sys.stdin:
  print "	".join(['abcdefg', "2"])
  lkdfjlkajflksajflkajflkjsaflkjalfjsaflksajfflkajflkasjflkajfl


09:38:39.996 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][akka://ExtractorRunnerSpec/user/$r][ExtractorRunner] INFO  waiting for tasks
09:38:39.996 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][akka://ExtractorRunnerSpec/user/$r][ExtractorRunner] INFO  Received task=testExtractor. Executing
09:38:39.996 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][akka://ExtractorRunnerSpec/user/$r][ExtractorRunner] INFO  Executing before script.
09:38:39.996 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test5276434225407747683.sh" 
09:38:40.027 [Thread-327][Helpers$(akka://deepdive)][Helpers$] INFO  INSERT 0 10
09:38:40.028 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][akka://ExtractorRunnerSpec/user/$r][ExtractorRunner] INFO  Starting 1 children process workers
09:38:40.028 [ExtractorRunnerSpec-akka.actor.default-dispatcher-6][akka://ExtractorRunnerSpec/user/$r][ExtractorRunner] INFO  Getting data from the data store and sending it to the workers. query='DatastoreInputQuery(SELECT * FROM testtable)'
09:38:40.028 [ExtractorRunnerSpec-akka.actor.default-dispatcher-5][akka://ExtractorRunnerSpec/user/$r/processExecutor1][ProcessExecutor] INFO  started
09:38:40.028 [ExtractorRunnerSpec-akka.actor.default-dispatcher-5][akka://ExtractorRunnerSpec/user/$r/processExecutor1][ProcessExecutor] INFO  starting process with cmd="/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test5158649729764372577.py" and batch_size=1000
09:38:40.029 [ExtractorRunnerSpec-akka.actor.default-dispatcher-6][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG SELECT * FROM testtable
09:38:40.031 [ExtractorRunnerSpec-akka.actor.default-dispatcher-6][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG QUERY PLAN
09:38:40.031 [ExtractorRunnerSpec-akka.actor.default-dispatcher-6][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG Seq Scan on testtable  (cost=0.00..18.60 rows=860 width=64)
09:38:40.035 [ExtractorRunnerSpec-akka.actor.default-dispatcher-6][akka://ExtractorRunnerSpec/user/$r][ExtractorRunner] DEBUG all data was sent to workers.
09:38:40.035 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][akka://ExtractorRunnerSpec/user/$r/processExecutor1][ProcessExecutor] DEBUG closing input stream
09:38:40.067 [Thread-331][akka://ExtractorRunnerSpec/user/$r/processExecutor1][ProcessExecutor] INFO  Traceback (most recent call last):
09:38:40.067 [Thread-331][akka://ExtractorRunnerSpec/user/$r/processExecutor1][ProcessExecutor] INFO    File "/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test5158649729764372577.py", line 5, in <module>
09:38:40.067 [Thread-331][akka://ExtractorRunnerSpec/user/$r/processExecutor1][ProcessExecutor] INFO      lkdfjlkajflksajflkajflkjsaflkjalfjsaflksajfflkajflkasjflkajfl
09:38:40.067 [Thread-331][akka://ExtractorRunnerSpec/user/$r/processExecutor1][ProcessExecutor] INFO  NameError: name 'lkdfjlkajflksajflkajflkjsaflkjalfjsaflksajfflkajflkasjflkajfl' is not defined
09:38:40.069 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][akka://ExtractorRunnerSpec/user/$r][ExtractorRunner] DEBUG adding chunk of size=1 data store.
09:38:40.071 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][akka.dispatch.Dispatcher][Dispatcher] ERROR Unexpected character ('a' (code 97)): expected a valid value (number, String, array, object, 'true', 'false' or 'null')
 at [Source: java.io.StringReader@5454aa19; line: 1, column: 2]
com.fasterxml.jackson.core.JsonParseException: Unexpected character ('a' (code 97)): expected a valid value (number, String, array, object, 'true', 'false' or 'null')
 at [Source: java.io.StringReader@5454aa19; line: 1, column: 2]
	at com.fasterxml.jackson.core.JsonParser._constructError(JsonParser.java:1369) ~[jackson-core-2.2.2.jar:2.2.2]
	at com.fasterxml.jackson.core.base.ParserMinimalBase._reportError(ParserMinimalBase.java:599) ~[jackson-core-2.2.2.jar:2.2.2]
	at com.fasterxml.jackson.core.base.ParserMinimalBase._reportUnexpectedChar(ParserMinimalBase.java:520) ~[jackson-core-2.2.2.jar:2.2.2]
	at com.fasterxml.jackson.core.json.ReaderBasedJsonParser._handleUnexpectedValue(ReaderBasedJsonParser.java:1379) ~[jackson-core-2.2.2.jar:2.2.2]
	at com.fasterxml.jackson.core.json.ReaderBasedJsonParser.nextToken(ReaderBasedJsonParser.java:669) ~[jackson-core-2.2.2.jar:2.2.2]
	at com.fasterxml.jackson.databind.ObjectMapper._initForReading(ObjectMapper.java:2926) ~[jackson-databind-2.2.2.jar:2.2.2]
	at com.fasterxml.jackson.databind.ObjectMapper._readValue(ObjectMapper.java:2846) ~[jackson-databind-2.2.2.jar:2.2.2]
	at com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:1569) ~[jackson-databind-2.2.2.jar:2.2.2]
	at play.api.libs.json.JacksonJson$.parseJsValue(JsValue.scala:484) ~[play-json_2.10-2.2.1.jar:2.2.1]
	at play.api.libs.json.Json$.parse(Json.scala:16) ~[play-json_2.10-2.2.1.jar:2.2.1]
	at org.deepdive.extraction.ExtractorRunner$$anonfun$3$$anonfun$applyOrElse$2$$anonfun$5.apply(ExtractorRunner.scala:177) ~[classes/:na]
	at org.deepdive.extraction.ExtractorRunner$$anonfun$3$$anonfun$applyOrElse$2$$anonfun$5.apply(ExtractorRunner.scala:177) ~[classes/:na]
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244) ~[scala-library.jar:0.13.7]
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244) ~[scala-library.jar:0.13.7]
	at scala.collection.immutable.List.foreach(List.scala:318) ~[scala-library.jar:0.13.7]
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:244) ~[scala-library.jar:0.13.7]
	at scala.collection.AbstractTraversable.map(Traversable.scala:105) ~[scala-library.jar:0.13.7]
	at org.deepdive.extraction.ExtractorRunner$$anonfun$3$$anonfun$applyOrElse$2.apply$mcV$sp(ExtractorRunner.scala:177) ~[classes/:na]
	at org.deepdive.extraction.ExtractorRunner$$anonfun$3$$anonfun$applyOrElse$2.apply(ExtractorRunner.scala:175) ~[classes/:na]
	at org.deepdive.extraction.ExtractorRunner$$anonfun$3$$anonfun$applyOrElse$2.apply(ExtractorRunner.scala:175) ~[classes/:na]
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24) ~[scala-library.jar:na]
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24) ~[scala-library.jar:na]
	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:39) ~[akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:385) [akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [scala-library.jar:na]
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [scala-library.jar:na]
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [scala-library.jar:na]
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [scala-library.jar:na]
09:38:40.077 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG EXECUTING.... drop table if exists testtable ;
09:38:40.077 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG DONE!
09:38:40.077 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG EXECUTING.... create table testtable ( a text, b text );
09:38:40.079 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG DONE!
09:38:40.080 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] INFO  /var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test1941319654079870130.sh
09:38:40.080 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG Writing to file /var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test1941319654079870130.sh:

 psql  -d deepdive_test  -U jackywang  -p 5432  -h localhost  -c  "INSERT INTO testtable VALUES ('Mesasge_1', '1'), ('Mesasge_2', '1'), ('Mesasge_3', '1'), ('Mesasge_4', '1'), ('Mesasge_5', '1'), ('Mesasge_6', '1'), ('Mesasge_7', '1'), ('Mesasge_8', '1'), ('Mesasge_9', '1'), ('Mesasge_10', '1');"
        
09:38:40.080 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG Writing to file /var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test7474140831802381335.py:
#! /usr/bin/python
import json, sys
for l in sys.stdin:
  print "	".join(['abcdefg', "2"])


09:38:40.081 [ExtractorRunnerSpec-akka.actor.default-dispatcher-6][akka://ExtractorRunnerSpec/user/$s][ExtractorRunner] INFO  waiting for tasks
09:38:40.081 [ExtractorRunnerSpec-akka.actor.default-dispatcher-6][akka://ExtractorRunnerSpec/user/$s][ExtractorRunner] INFO  Received task=testExtractor. Executing
09:38:40.081 [ExtractorRunnerSpec-akka.actor.default-dispatcher-6][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test1941319654079870130.sh" 
09:38:40.081 [ExtractorRunnerSpec-akka.actor.default-dispatcher-6][akka://ExtractorRunnerSpec/user/$s][ExtractorRunner] INFO  Executing before script.
09:38:40.113 [Thread-333][Helpers$(akka://deepdive)][Helpers$] INFO  INSERT 0 10
09:38:40.114 [ExtractorRunnerSpec-akka.actor.default-dispatcher-6][akka://ExtractorRunnerSpec/user/$s][ExtractorRunner] INFO  Starting 1 children process workers
09:38:40.114 [ExtractorRunnerSpec-akka.actor.default-dispatcher-5][akka://ExtractorRunnerSpec/user/$s][ExtractorRunner] INFO  Getting data from the data store and sending it to the workers. query='DatastoreInputQuery(AAAAAAAAAAAAAAAAAAAAAAAAA * FROM testtable)'
09:38:40.114 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][akka://ExtractorRunnerSpec/user/$s/processExecutor1][ProcessExecutor] INFO  started
09:38:40.114 [ExtractorRunnerSpec-akka.actor.default-dispatcher-5][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] DEBUG AAAAAAAAAAAAAAAAAAAAAAAAA * FROM testtable
09:38:40.114 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][akka://ExtractorRunnerSpec/user/$s/processExecutor1][ProcessExecutor] INFO  starting process with cmd="/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test7474140831802381335.py" and batch_size=1000
09:38:40.115 [ExtractorRunnerSpec-akka.actor.default-dispatcher-5][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] ERROR org.postgresql.util.PSQLException: ERROR: syntax error at or near "AAAAAAAAAAAAAAAAAAAAAAAAA"
  Position: 9
09:38:40.115 [ExtractorRunnerSpec-akka.actor.default-dispatcher-5][akka://ExtractorRunnerSpec/user/$s][ExtractorRunner] ERROR org.postgresql.util.PSQLException: ERROR: syntax error at or near "AAAAAAAAAAAAAAAAAAAAAAAAA"
  Position: 9
09:38:40.130 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG EXECUTING.... drop table if exists testtable ;
09:38:40.130 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG DONE!
09:38:40.130 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG EXECUTING.... create table testtable ( a text, b text );
09:38:40.132 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG DONE!
09:38:40.132 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] INFO  /var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test6028322037059647472.sh
09:38:40.132 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG Writing to file /var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test6028322037059647472.sh:

 psql  -d deepdive_test  -U jackywang  -p 5432  -h localhost  -c  "INSERT INTO testtable VALUES ('Mesasge_1', '1'), ('Mesasge_2', '1'), ('Mesasge_3', '1'), ('Mesasge_4', '1'), ('Mesasge_5', '1'), ('Mesasge_6', '1'), ('Mesasge_7', '1'), ('Mesasge_8', '1'), ('Mesasge_9', '1'), ('Mesasge_10', '1');"
      
09:38:40.133 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG Writing to file /var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test3889195338066652887.py:
#! /usr/bin/python
import json, sys
for l in sys.stdin:
  print "	".join(['abcdefg', "2"])
  lkdfjlkajflksajflkajflkjsaflkjalfjsaflksajfflkajflkasjflkajfl


09:38:40.133 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][akka://ExtractorRunnerSpec/user/$t][ExtractorRunner] INFO  waiting for tasks
09:38:40.134 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][akka://ExtractorRunnerSpec/user/$t][ExtractorRunner] INFO  Received task=testExtractor. Executing
09:38:40.134 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test6028322037059647472.sh" 
09:38:40.134 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][akka://ExtractorRunnerSpec/user/$t][ExtractorRunner] INFO  Executing before script.
09:38:40.164 [Thread-339][Helpers$(akka://deepdive)][Helpers$] INFO  INSERT 0 10
09:38:40.165 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][akka://ExtractorRunnerSpec/user/$t][ExtractorRunner] DEBUG Parallel Loading: false
09:38:40.165 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][akka://ExtractorRunnerSpec/user/$t][ExtractorRunner] INFO  /Users/jackywang/Desktop/341/project/deepdive/out/tmp/
09:38:40.165 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][akka://ExtractorRunnerSpec/user/$t][ExtractorRunner] INFO  Executing: find /Users/jackywang/Desktop/341/project/deepdive/out/tmp -name 'testtable.copy_query_func_testExtractor.tsv*' 2>/dev/null -print0 | xargs -0 rm -f
09:38:40.165 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/Users/jackywang/Desktop/341/project/deepdive/out/tmp/exec_delete.sh" 
09:38:40.180 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][Helpers$(akka://deepdive)][Helpers$] DEBUG Executing queries by file: psql  -d deepdive_test  -U jackywang  -p 5432  -h localhost  -c 'COPY (SELECT * FROM testtable) TO STDOUT;'   > /Users/jackywang/Desktop/341/project/deepdive/out/tmp/testtable.copy_query_func_testExtractor.tsv
09:38:40.180 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/exec_sql2243690867850972711.sh" 
09:38:40.214 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][akka://ExtractorRunnerSpec/user/$t][ExtractorRunner] INFO  File dumped to /Users/jackywang/Desktop/341/project/deepdive/out/tmp/testtable.copy_query_func_testExtractor.tsv
09:38:40.214 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][akka://ExtractorRunnerSpec/user/$t][ExtractorRunner] INFO  Executing split command...
09:38:40.215 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "split -a 10 -l 1000 /Users/jackywang/Desktop/341/project/deepdive/out/tmp/testtable.copy_query_func_testExtractor.tsv /Users/jackywang/Desktop/341/project/deepdive/out/tmp/testtable.copy_query_func_testExtractor.tsv-" 
09:38:40.224 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][akka://ExtractorRunnerSpec/user/$t][ExtractorRunner] INFO  Executing parallel UDF command: find /Users/jackywang/Desktop/341/project/deepdive/out/tmp -name 'testtable.copy_query_func_testExtractor.tsv-*' 2>/dev/null -print0 | xargs -0 -P 1 -L 1 bash -c '/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test3889195338066652887.py < "$0" > "$0.out"'
09:38:40.224 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][akka://ExtractorRunnerSpec/user/$t][ExtractorRunner] DEBUG Temporary UDF file saved to /Users/jackywang/Desktop/341/project/deepdive/out/tmp/exec_parallel_udf.sh
09:38:40.224 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/Users/jackywang/Desktop/341/project/deepdive/out/tmp/exec_parallel_udf.sh" 
09:38:40.281 [Thread-352][Helpers$(akka://deepdive)][Helpers$] INFO  Traceback (most recent call last):
09:38:40.281 [Thread-352][Helpers$(akka://deepdive)][Helpers$] INFO    File "/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test3889195338066652887.py", line 5, in <module>
09:38:40.281 [Thread-352][Helpers$(akka://deepdive)][Helpers$] INFO      lkdfjlkajflksajflkajflkjsaflkjalfjsaflksajfflkajflkasjflkajfl
09:38:40.281 [Thread-352][Helpers$(akka://deepdive)][Helpers$] INFO  NameError: name 'lkdfjlkajflksajflkajflkjsaflkjalfjsaflksajfflkajflkasjflkajfl' is not defined
09:38:40.283 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][akka://ExtractorRunnerSpec/user/$t][ExtractorRunner] ERROR java.lang.RuntimeException: Failure when executing script: /Users/jackywang/Desktop/341/project/deepdive/out/tmp/exec_parallel_udf.sh
09:38:40.284 [ExtractorRunnerSpec-akka.actor.default-dispatcher-6][akka://ExtractorRunnerSpec/user/$t][OneForOneStrategy] ERROR java.lang.RuntimeException: Failure when executing script: /Users/jackywang/Desktop/341/project/deepdive/out/tmp/exec_parallel_udf.sh
java.lang.RuntimeException: java.lang.RuntimeException: Failure when executing script: /Users/jackywang/Desktop/341/project/deepdive/out/tmp/exec_parallel_udf.sh
	at org.deepdive.extraction.ExtractorRunner.org$deepdive$extraction$ExtractorRunner$$executeScriptOrFail(ExtractorRunner.scala:298) ~[classes/:na]
	at org.deepdive.extraction.ExtractorRunner.org$deepdive$extraction$ExtractorRunner$$runTsvExtractor(ExtractorRunner.scala:464) ~[classes/:na]
	at org.deepdive.extraction.ExtractorRunner$$anonfun$2.applyOrElse(ExtractorRunner.scala:131) ~[classes/:na]
	at org.deepdive.extraction.ExtractorRunner$$anonfun$2.applyOrElse(ExtractorRunner.scala:100) ~[classes/:na]
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:33) ~[scala-library.jar:0.13.7]
	at akka.actor.FSM$class.processEvent(FSM.scala:587) ~[akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at org.deepdive.extraction.ExtractorRunner.processEvent(ExtractorRunner.scala:59) ~[classes/:na]
	at akka.actor.FSM$class.akka$actor$FSM$$processMsg(FSM.scala:581) ~[akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:575) ~[akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at akka.actor.Actor$class.aroundReceive(Actor.scala:467) ~[akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at org.deepdive.extraction.ExtractorRunner.aroundReceive(ExtractorRunner.scala:59) ~[classes/:na]
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:491) [akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at akka.actor.ActorCell.invoke(ActorCell.scala:462) [akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:237) [akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at akka.dispatch.Mailbox.run(Mailbox.scala:219) [akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:385) [akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [scala-library.jar:na]
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [scala-library.jar:na]
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [scala-library.jar:na]
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [scala-library.jar:na]
09:38:40.289 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG EXECUTING.... drop table if exists testtable ;
09:38:40.290 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG DONE!
09:38:40.290 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG EXECUTING.... create table testtable ( a text, b text );
09:38:40.292 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG DONE!
09:38:40.292 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] INFO  /var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test8464262535021118151.sh
09:38:40.292 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG Writing to file /var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test8464262535021118151.sh:

 psql  -d deepdive_test  -U jackywang  -p 5432  -h localhost  -c  "INSERT INTO testtable VALUES ('Mesasge_1', '1'), ('Mesasge_2', '1'), ('Mesasge_3', '1'), ('Mesasge_4', '1'), ('Mesasge_5', '1'), ('Mesasge_6', '1'), ('Mesasge_7', '1'), ('Mesasge_8', '1'), ('Mesasge_9', '1'), ('Mesasge_10', '1');"
        
09:38:40.293 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG Writing to file /var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test1248289170153037750.py:
#! /usr/bin/python
import json, sys
for l in sys.stdin:
  print "	".join(['abcdefg', "2"])


09:38:40.293 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][akka://ExtractorRunnerSpec/user/$u][ExtractorRunner] INFO  waiting for tasks
09:38:40.293 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][akka://ExtractorRunnerSpec/user/$u][ExtractorRunner] INFO  Received task=testExtractor. Executing
09:38:40.293 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test8464262535021118151.sh" 
09:38:40.293 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][akka://ExtractorRunnerSpec/user/$u][ExtractorRunner] INFO  Executing before script.
09:38:40.324 [Thread-354][Helpers$(akka://deepdive)][Helpers$] INFO  INSERT 0 10
09:38:40.325 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][akka://ExtractorRunnerSpec/user/$u][ExtractorRunner] DEBUG Parallel Loading: false
09:38:40.325 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][akka://ExtractorRunnerSpec/user/$u][ExtractorRunner] INFO  /Users/jackywang/Desktop/341/project/deepdive/out/tmp/
09:38:40.325 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][akka://ExtractorRunnerSpec/user/$u][ExtractorRunner] INFO  Executing: find /Users/jackywang/Desktop/341/project/deepdive/out/tmp -name 'testtable.copy_query_func_testExtractor.tsv*' 2>/dev/null -print0 | xargs -0 rm -f
09:38:40.325 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/Users/jackywang/Desktop/341/project/deepdive/out/tmp/exec_delete.sh" 
09:38:40.341 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][Helpers$(akka://deepdive)][Helpers$] DEBUG Executing queries by file: psql  -d deepdive_test  -U jackywang  -p 5432  -h localhost  -c 'COPY (AAAAAAAAAAAAAAAAAAAAAAAAA * FROM testtable) TO STDOUT;'   > /Users/jackywang/Desktop/341/project/deepdive/out/tmp/testtable.copy_query_func_testExtractor.tsv
09:38:40.341 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/exec_sql1557836051895085816.sh" 
09:38:40.371 [Thread-361][Helpers$(akka://deepdive)][Helpers$] INFO  ERROR:  syntax error at or near "AAAAAAAAAAAAAAAAAAAAAAAAA"
09:38:40.371 [Thread-361][Helpers$(akka://deepdive)][Helpers$] INFO  LINE 1: COPY (AAAAAAAAAAAAAAAAAAAAAAAAA * FROM testtable) TO STDOUT;
09:38:40.371 [Thread-361][Helpers$(akka://deepdive)][Helpers$] INFO                ^
09:38:40.372 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][akka://ExtractorRunnerSpec/user/$u][ExtractorRunner] ERROR java.lang.RuntimeException: Failure when executing script: /var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/exec_sql1557836051895085816.sh
09:38:40.373 [ExtractorRunnerSpec-akka.actor.default-dispatcher-6][akka://ExtractorRunnerSpec/user/$u][OneForOneStrategy] ERROR Failure when executing script: /var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/exec_sql1557836051895085816.sh
java.lang.RuntimeException: Failure when executing script: /var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/exec_sql1557836051895085816.sh
	at org.deepdive.helpers.Helpers$.executeCmd(Helpers.scala:102) ~[classes/:na]
	at org.deepdive.helpers.Helpers$.executeSqlQueriesByFile(Helpers.scala:129) ~[classes/:na]
	at org.deepdive.datastore.DataLoader.unload(Dataloader.scala:87) ~[classes/:na]
	at org.deepdive.extraction.ExtractorRunner.org$deepdive$extraction$ExtractorRunner$$runTsvExtractor(ExtractorRunner.scala:430) ~[classes/:na]
	at org.deepdive.extraction.ExtractorRunner$$anonfun$2.applyOrElse(ExtractorRunner.scala:131) ~[classes/:na]
	at org.deepdive.extraction.ExtractorRunner$$anonfun$2.applyOrElse(ExtractorRunner.scala:100) ~[classes/:na]
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:33) ~[scala-library.jar:0.13.7]
	at akka.actor.FSM$class.processEvent(FSM.scala:587) ~[akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at org.deepdive.extraction.ExtractorRunner.processEvent(ExtractorRunner.scala:59) ~[classes/:na]
	at akka.actor.FSM$class.akka$actor$FSM$$processMsg(FSM.scala:581) ~[akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:575) ~[akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at akka.actor.Actor$class.aroundReceive(Actor.scala:467) ~[akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at org.deepdive.extraction.ExtractorRunner.aroundReceive(ExtractorRunner.scala:59) ~[classes/:na]
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:491) [akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at akka.actor.ActorCell.invoke(ActorCell.scala:462) [akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:237) [akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at akka.dispatch.Mailbox.run(Mailbox.scala:219) [akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:385) [akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [scala-library.jar:na]
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [scala-library.jar:na]
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [scala-library.jar:na]
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [scala-library.jar:na]
09:38:40.380 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG EXECUTING.... drop table if exists testtable ;
09:38:40.380 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG DONE!
09:38:40.380 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG EXECUTING.... create table testtable ( a text );
09:38:40.383 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG DONE!
09:38:40.383 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] INFO  /var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test5483936987647983345.sh
09:38:40.384 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG Writing to file /var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test5483936987647983345.sh:

 psql  -d deepdive_test  -U jackywang  -p 5432  -h localhost  -c  "INSERT INTO testtable VALUES ('I should be in the table');"
 psql  -d deepdive_test  -U jackywang  -p 5432  -h localhost  -c  "INSERT INTO testtable VALUES ('I should also be in the table');"
      
09:38:40.384 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][akka://ExtractorRunnerSpec/user/$v][ExtractorRunner] INFO  waiting for tasks
09:38:40.384 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][akka://ExtractorRunnerSpec/user/$v][ExtractorRunner] INFO  Received task=testExtractor. Executing
09:38:40.384 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][akka://ExtractorRunnerSpec/user/$v][ExtractorRunner] INFO  Executing before script.
09:38:40.384 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test5483936987647983345.sh" 
09:38:40.419 [Thread-363][Helpers$(akka://deepdive)][Helpers$] INFO  INSERT 0 1
09:38:40.444 [Thread-363][Helpers$(akka://deepdive)][Helpers$] INFO  INSERT 0 1
09:38:40.446 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][akka://ExtractorRunnerSpec/user/$v][ExtractorRunner] DEBUG Executing SQL query: DELETE FROM testtable WHERE a='I should be in the table';
09:38:40.457 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG EXECUTING.... drop table if exists testtable ;
09:38:40.457 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG DONE!
09:38:40.457 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG EXECUTING.... create table testtable ( a text );
09:38:40.461 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG DONE!
09:38:40.462 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] INFO  /var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test2794186519122944521.sh
09:38:40.462 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG Writing to file /var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test2794186519122944521.sh:

psql  -d deepdive_test  -U jackywang  -p 5432  -h localhost  -c  "INSERT INTO testtable VALUES ('I should be in the table');"
psql  -d deepdive_test  -U jackywang  -p 5432  -h localhost  -c  "INSERT INTO testtable VALUES ('I should also be in the table');"
      
09:38:40.463 [ExtractorRunnerSpec-akka.actor.default-dispatcher-12][akka://ExtractorRunnerSpec/user/$w][ExtractorRunner] INFO  waiting for tasks
09:38:40.463 [ExtractorRunnerSpec-akka.actor.default-dispatcher-12][akka://ExtractorRunnerSpec/user/$w][ExtractorRunner] INFO  Received task=testExtractor. Executing
09:38:40.463 [ExtractorRunnerSpec-akka.actor.default-dispatcher-12][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test2794186519122944521.sh" 
09:38:40.463 [ExtractorRunnerSpec-akka.actor.default-dispatcher-12][akka://ExtractorRunnerSpec/user/$w][ExtractorRunner] INFO  Executing before script.
09:38:40.496 [Thread-366][Helpers$(akka://deepdive)][Helpers$] INFO  INSERT 0 1
09:38:40.520 [Thread-366][Helpers$(akka://deepdive)][Helpers$] INFO  INSERT 0 1
09:38:40.521 [ExtractorRunnerSpec-akka.actor.default-dispatcher-12][akka://ExtractorRunnerSpec/user/$w][ExtractorRunner] DEBUG Executing SQL query: DELETEAAAAAA FROM testtable WHERE a='I should be in the table';
09:38:40.521 [ExtractorRunnerSpec-akka.actor.default-dispatcher-12][PostgresExtractionDataStore(akka://deepdive)][PostgresExtractionDataStore] ERROR org.postgresql.util.PSQLException: ERROR: syntax error at or near "DELETEAAAAAA"
  Position: 1
09:38:40.522 [ExtractorRunnerSpec-akka.actor.default-dispatcher-7][akka://ExtractorRunnerSpec/user/$w][OneForOneStrategy] ERROR org.postgresql.util.PSQLException: ERROR: syntax error at or near "DELETEAAAAAA"
  Position: 1
java.lang.RuntimeException: org.postgresql.util.PSQLException: ERROR: syntax error at or near "DELETEAAAAAA"
  Position: 1
	at org.deepdive.extraction.ExtractorRunner.executeSqlUpdateOrFail(ExtractorRunner.scala:313) ~[classes/:na]
	at org.deepdive.extraction.ExtractorRunner$$anonfun$2.applyOrElse(ExtractorRunner.scala:137) ~[classes/:na]
	at org.deepdive.extraction.ExtractorRunner$$anonfun$2.applyOrElse(ExtractorRunner.scala:100) ~[classes/:na]
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:33) ~[scala-library.jar:0.13.7]
	at akka.actor.FSM$class.processEvent(FSM.scala:587) ~[akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at org.deepdive.extraction.ExtractorRunner.processEvent(ExtractorRunner.scala:59) ~[classes/:na]
	at akka.actor.FSM$class.akka$actor$FSM$$processMsg(FSM.scala:581) ~[akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:575) ~[akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at akka.actor.Actor$class.aroundReceive(Actor.scala:467) ~[akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at org.deepdive.extraction.ExtractorRunner.aroundReceive(ExtractorRunner.scala:59) ~[classes/:na]
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:491) [akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at akka.actor.ActorCell.invoke(ActorCell.scala:462) [akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:237) [akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at akka.dispatch.Mailbox.run(Mailbox.scala:219) [akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:385) [akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [scala-library.jar:na]
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [scala-library.jar:na]
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [scala-library.jar:na]
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [scala-library.jar:na]
09:38:40.527 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG EXECUTING.... drop table if exists testtable ;
09:38:40.527 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG DONE!
09:38:40.528 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG EXECUTING.... create table testtable ( a text );
09:38:40.530 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG DONE!
09:38:40.531 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] INFO  /var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test2838296588736146859.sh
09:38:40.531 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG Writing to file /var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test2838296588736146859.sh:

psql  -d deepdive_test  -U jackywang  -p 5432  -h localhost  -c  "INSERT INTO testtable VALUES ('I should be in the table');"
psql  -d deepdive_test  -U jackywang  -p 5432  -h localhost  -c  "INSERT INTO testtable VALUES ('I should also be in the table');"
      
09:38:40.531 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG Writing to file /var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test4099094631288096207.sh:

psql  -d deepdive_test  -U jackywang  -p 5432  -h localhost  -c  "DELETE FROM testtable WHERE a='I should be in the table';"
      
09:38:40.532 [ExtractorRunnerSpec-akka.actor.default-dispatcher-6][akka://ExtractorRunnerSpec/user/$x][ExtractorRunner] INFO  waiting for tasks
09:38:40.532 [ExtractorRunnerSpec-akka.actor.default-dispatcher-6][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test2838296588736146859.sh" 
09:38:40.532 [ExtractorRunnerSpec-akka.actor.default-dispatcher-6][akka://ExtractorRunnerSpec/user/$x][ExtractorRunner] INFO  Received task=testExtractor. Executing
09:38:40.532 [ExtractorRunnerSpec-akka.actor.default-dispatcher-6][akka://ExtractorRunnerSpec/user/$x][ExtractorRunner] INFO  Executing before script.
09:38:40.563 [Thread-369][Helpers$(akka://deepdive)][Helpers$] INFO  INSERT 0 1
09:38:40.586 [Thread-369][Helpers$(akka://deepdive)][Helpers$] INFO  INSERT 0 1
09:38:40.588 [ExtractorRunnerSpec-akka.actor.default-dispatcher-6][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test4099094631288096207.sh" 
09:38:40.619 [Thread-372][Helpers$(akka://deepdive)][Helpers$] INFO  DELETE 1
09:38:40.628 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG EXECUTING.... drop table if exists testtable ;
09:38:40.628 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG DONE!
09:38:40.628 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG EXECUTING.... create table testtable ( a text );
09:38:40.630 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG DONE!
09:38:40.631 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] INFO  /var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test1923931580501799323.sh
09:38:40.631 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG Writing to file /var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test1923931580501799323.sh:

psql  -d deepdive_test  -U jackywang  -p 5432  -h localhost  -c  "INSERT INTO testtable VALUES ('I should be in the table');"
psql  -d deepdive_test  -U jackywang  -p 5432  -h localhost  -c  "INSERT INTO testtable VALUES ('I should also be in the table');"
      
09:38:40.631 [ScalaTest-running-ExtractorRunnerSpec][ExtractorRunnerSpec(akka://deepdive)][ExtractorRunnerSpec] DEBUG Writing to file /var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test2405991336328601746.sh:

psql  -d deepdive_test  -U jackywang  -p 5432  -h localhost  -c  "DELETEAAAAAAA FROM testtable WHERE a='I should be in the table';"
      
09:38:40.632 [ExtractorRunnerSpec-akka.actor.default-dispatcher-12][akka://ExtractorRunnerSpec/user/$y][ExtractorRunner] INFO  waiting for tasks
09:38:40.632 [ExtractorRunnerSpec-akka.actor.default-dispatcher-12][akka://ExtractorRunnerSpec/user/$y][ExtractorRunner] INFO  Received task=testExtractor. Executing
09:38:40.632 [ExtractorRunnerSpec-akka.actor.default-dispatcher-12][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test1923931580501799323.sh" 
09:38:40.632 [ExtractorRunnerSpec-akka.actor.default-dispatcher-12][akka://ExtractorRunnerSpec/user/$y][ExtractorRunner] INFO  Executing before script.
09:38:40.663 [Thread-375][Helpers$(akka://deepdive)][Helpers$] INFO  INSERT 0 1
09:38:40.686 [Thread-375][Helpers$(akka://deepdive)][Helpers$] INFO  INSERT 0 1
09:38:40.687 [ExtractorRunnerSpec-akka.actor.default-dispatcher-12][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test2405991336328601746.sh" 
09:38:40.717 [Thread-379][Helpers$(akka://deepdive)][Helpers$] INFO  ERROR:  syntax error at or near "DELETEAAAAAAA"
09:38:40.717 [Thread-379][Helpers$(akka://deepdive)][Helpers$] INFO  LINE 1: DELETEAAAAAAA FROM testtable WHERE a='I should be in the tab...
09:38:40.717 [Thread-379][Helpers$(akka://deepdive)][Helpers$] INFO          ^
09:38:40.718 [ExtractorRunnerSpec-akka.actor.default-dispatcher-12][akka://ExtractorRunnerSpec/user/$y][ExtractorRunner] ERROR java.lang.RuntimeException: Failure when executing script: /var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test2405991336328601746.sh
09:38:40.718 [ExtractorRunnerSpec-akka.actor.default-dispatcher-6][akka://ExtractorRunnerSpec/user/$y][OneForOneStrategy] ERROR java.lang.RuntimeException: Failure when executing script: /var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test2405991336328601746.sh
java.lang.RuntimeException: java.lang.RuntimeException: Failure when executing script: /var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test2405991336328601746.sh
	at org.deepdive.extraction.ExtractorRunner.org$deepdive$extraction$ExtractorRunner$$executeScriptOrFail(ExtractorRunner.scala:298) ~[classes/:na]
	at org.deepdive.extraction.ExtractorRunner$$anonfun$2$$anonfun$applyOrElse$4.apply(ExtractorRunner.scala:142) ~[classes/:na]
	at org.deepdive.extraction.ExtractorRunner$$anonfun$2$$anonfun$applyOrElse$4.apply(ExtractorRunner.scala:142) ~[classes/:na]
	at scala.Option.foreach(Option.scala:236) ~[scala-library.jar:0.13.7]
	at org.deepdive.extraction.ExtractorRunner$$anonfun$2.applyOrElse(ExtractorRunner.scala:141) ~[classes/:na]
	at org.deepdive.extraction.ExtractorRunner$$anonfun$2.applyOrElse(ExtractorRunner.scala:100) ~[classes/:na]
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:33) ~[scala-library.jar:0.13.7]
	at akka.actor.FSM$class.processEvent(FSM.scala:587) ~[akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at org.deepdive.extraction.ExtractorRunner.processEvent(ExtractorRunner.scala:59) ~[classes/:na]
	at akka.actor.FSM$class.akka$actor$FSM$$processMsg(FSM.scala:581) ~[akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:575) ~[akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at akka.actor.Actor$class.aroundReceive(Actor.scala:467) ~[akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at org.deepdive.extraction.ExtractorRunner.aroundReceive(ExtractorRunner.scala:59) ~[classes/:na]
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:491) [akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at akka.actor.ActorCell.invoke(ActorCell.scala:462) [akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:237) [akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at akka.dispatch.Mailbox.run(Mailbox.scala:219) [akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:385) [akka-actor_2.10-2.3-M2.jar:2.3-M2]
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [scala-library.jar:na]
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [scala-library.jar:na]
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [scala-library.jar:na]
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [scala-library.jar:na]
09:38:40.727 [ScalaTest-running-DataLoaderSpec][JdbcDataStore$(akka://deepdive)][JdbcDataStore$] INFO  Intializing all JDBC data stores
09:38:40.844 [ScalaTest-running-DataLoaderSpec][Helpers$(akka://deepdive)][Helpers$] DEBUG Executing queries by file: psql  -d deepdive_test  -U jackywang  -p 5432  -h localhost  -c 'COPY (select * from unloader) TO STDOUT;'   > /var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test_unloader4312762772233022462
09:38:40.844 [ScalaTest-running-DataLoaderSpec][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/exec_sql5631909912631931543.sh" 
09:38:40.877 [ScalaTest-running-DataLoaderSpec][JdbcDataStore$(akka://deepdive)][JdbcDataStore$] INFO  Closing all JDBC data stores
09:38:40.877 [ScalaTest-running-DataLoaderSpec][JdbcDataStore$(akka://deepdive)][JdbcDataStore$] INFO  Intializing all JDBC data stores
09:38:40.987 [ScalaTest-running-DataLoaderSpec][Helpers$(akka://deepdive)][Helpers$] DEBUG Executing queries by file: psql  -d deepdive_test  -U jackywang  -p 5432  -h localhost  -c 'COPY (select * from unloader) TO STDOUT;'   > /var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/test_unloader6110358861611574947
09:38:40.987 [ScalaTest-running-DataLoaderSpec][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/exec_sql573834750659536916.sh" 
09:38:41.020 [ScalaTest-running-DataLoaderSpec][JdbcDataStore$(akka://deepdive)][JdbcDataStore$] INFO  Closing all JDBC data stores
09:38:41.020 [ScalaTest-running-DataLoaderSpec][JdbcDataStore$(akka://deepdive)][JdbcDataStore$] INFO  Intializing all JDBC data stores
09:38:41.122 [ScalaTest-running-DataLoaderSpec][DataLoaderSpec(akka://deepdive)][DataLoaderSpec] DEBUG DEBUG start testing!!
09:38:41.126 [ScalaTest-running-DataLoaderSpec][DataLoader(akka://deepdive)][DataLoader] INFO  find /Users/jackywang/Desktop/341/project/deepdive/target/scala-2.10/test-classes/dataloader1.tsv -print0 | xargs -0 -P 1 -L 1 bash -c 'psql  -d deepdive_test  -U jackywang  -p 5432  -h localhost -c "COPY dataloader1 FROM STDIN; " < $0'
09:38:41.126 [ScalaTest-running-DataLoaderSpec][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/dataloader1.copy2576598326944189498.sh" 
09:38:41.165 [Thread-387][Helpers$(akka://deepdive)][Helpers$] INFO  COPY 2
09:38:41.167 [ScalaTest-running-DataLoaderSpec][JdbcDataStore$(akka://deepdive)][JdbcDataStore$] DEBUG Executing SQL with callback... SELECT * FROM dataloader1 WHERE id = 0
09:38:41.174 [ScalaTest-running-DataLoaderSpec][JdbcDataStore$(akka://deepdive)][JdbcDataStore$] DEBUG Executing SQL with callback... SELECT * FROM dataloader1 WHERE is_correct = false
09:38:41.175 [ScalaTest-running-DataLoaderSpec][DataLoaderSpec(akka://deepdive)][DataLoaderSpec] DEBUG DEBUG: GET RESULT hi
09:38:41.175 [ScalaTest-running-DataLoaderSpec][DataLoaderSpec(akka://deepdive)][DataLoaderSpec] DEBUG DEBUG: GET RESULT true
09:38:41.175 [ScalaTest-running-DataLoaderSpec][DataLoaderSpec(akka://deepdive)][DataLoaderSpec] DEBUG DEBUG: GET RESULT null
09:38:41.175 [ScalaTest-running-DataLoaderSpec][DataLoaderSpec(akka://deepdive)][DataLoaderSpec] DEBUG DEBUG: GET RESULT 100
09:38:41.175 [ScalaTest-running-DataLoaderSpec][JdbcDataStore$(akka://deepdive)][JdbcDataStore$] INFO  Closing all JDBC data stores
09:38:41.176 [ScalaTest-running-DataLoaderSpec][JdbcDataStore$(akka://deepdive)][JdbcDataStore$] INFO  Intializing all JDBC data stores
09:38:41.284 [ScalaTest-running-DataLoaderSpec][DataLoader(akka://deepdive)][DataLoader] INFO  find /Users/jackywang/Desktop/341/project/deepdive/target/scala-2.10/test-classes/dataloader*.tsv -print0 | xargs -0 -P 1 -L 1 bash -c 'psql  -d deepdive_test  -U jackywang  -p 5432  -h localhost -c "COPY dataloader1 FROM STDIN; " < $0'
09:38:41.284 [ScalaTest-running-DataLoaderSpec][Helpers$(akka://deepdive)][Helpers$] INFO  Executing command: "/var/folders/2f/pgh5dvbs1_s71k9nbgb8lzdr0000gn/T/dataloader1.copy5609416685171583616.sh" 
09:38:41.327 [Thread-390][Helpers$(akka://deepdive)][Helpers$] INFO  COPY 2
09:38:41.329 [ScalaTest-running-DataLoaderSpec][JdbcDataStore$(akka://deepdive)][JdbcDataStore$] DEBUG Executing SQL with callback... SELECT * FROM dataloader1 WHERE id = 0
09:38:41.336 [ScalaTest-running-DataLoaderSpec][JdbcDataStore$(akka://deepdive)][JdbcDataStore$] DEBUG Executing SQL with callback... SELECT * FROM dataloader1 WHERE is_correct = false
09:38:41.337 [ScalaTest-running-DataLoaderSpec][JdbcDataStore$(akka://deepdive)][JdbcDataStore$] INFO  Closing all JDBC data stores
09:38:41.337 [ScalaTest-running-DataLoaderSpec][JdbcDataStore$(akka://deepdive)][JdbcDataStore$] INFO  Intializing all JDBC data stores
09:38:41.439 [ScalaTest-running-DataLoaderSpec][JdbcDataStore$(akka://deepdive)][JdbcDataStore$] INFO  Closing all JDBC data stores
09:38:41.445 [][][Slf4jLogger] INFO  Slf4jLogger started
09:38:41.445 [pool-4-thread-6][EventStream(akka://FactorGraphBuilderSpec)][EventStream] DEBUG logger log1-Slf4jLogger started
09:38:41.445 [pool-4-thread-6][EventStream(akka://FactorGraphBuilderSpec)][EventStream] DEBUG Default Loggers started
09:38:41.513 [][][Slf4jLogger] INFO  Slf4jLogger started
09:38:41.513 [pool-4-thread-6][EventStream(akka://TaskManagerSpec)][EventStream] DEBUG logger log1-Slf4jLogger started
09:38:41.514 [pool-4-thread-6][EventStream(akka://TaskManagerSpec)][EventStream] DEBUG Default Loggers started
09:38:41.539 [ScalaTest-running-TaskManagerSpec][akka://TaskManagerSpec/user/$$g][TaskManager] INFO  starting at akka://TaskManagerSpec/user/$$g
09:38:41.553 [ScalaTest-running-TaskManagerSpec][akka://TaskManagerSpec/user/$$g][TaskManager] DEBUG 1/1 tasks eligible. Waiting tasks: Set()
09:38:41.554 [ScalaTest-running-TaskManagerSpec][akka://TaskManagerSpec/user/$$g][TaskManager] DEBUG Sending task_id=task1 to Actor[akka://TaskManagerSpec/system/testActor12#-1621793800]
09:38:41.556 [ScalaTest-running-TaskManagerSpec][akka://TaskManagerSpec/user/$$h][TaskManager] INFO  starting at akka://TaskManagerSpec/user/$$h
09:38:41.567 [ScalaTest-running-TaskManagerSpec][akka://TaskManagerSpec/user/$$h][TaskManager] DEBUG 0/1 tasks eligible. Waiting tasks: Set(task1)
09:38:41.568 [ScalaTest-running-TaskManagerSpec][akka://TaskManagerSpec/user/$$i][TaskManager] INFO  starting at akka://TaskManagerSpec/user/$$i
09:38:41.591 [ScalaTest-running-TaskManagerSpec][akka://TaskManagerSpec/user/$$i][TaskManager] DEBUG 1/1 tasks eligible. Waiting tasks: Set()
09:38:41.591 [ScalaTest-running-TaskManagerSpec][akka://TaskManagerSpec/user/$$i][TaskManager] DEBUG Sending task_id=task2 to Actor[akka://TaskManagerSpec/system/testActor15#1946056370]
09:38:41.593 [ScalaTest-running-TaskManagerSpec][akka://TaskManagerSpec/user/$$j][TaskManager] INFO  starting at akka://TaskManagerSpec/user/$$j
09:38:41.606 [ScalaTest-running-TaskManagerSpec][akka://TaskManagerSpec/user/$$j][TaskManager] INFO  Added task_id=task1
09:38:41.606 [ScalaTest-running-TaskManagerSpec][akka://TaskManagerSpec/user/$$j][TaskManager] DEBUG Sending task_id=task1 to Actor[akka://TaskManagerSpec/system/testActor16#533916699]
09:38:41.607 [ScalaTest-running-TaskManagerSpec][akka://TaskManagerSpec/user/$$k][TaskManager] INFO  starting at akka://TaskManagerSpec/user/$$k
09:38:41.618 [ScalaTest-running-TaskManagerSpec][akka://TaskManagerSpec/user/$$k][TaskManager] INFO  Added task_id=task1
09:38:41.618 [ScalaTest-running-TaskManagerSpec][akka://TaskManagerSpec/user/$$k][TaskManager] DEBUG Sending task_id=task1 to Actor[akka://TaskManagerSpec/system/testActor17#-606118477]
09:38:41.619 [ScalaTest-running-TaskManagerSpec][akka://TaskManagerSpec/user/$$k][TaskManager] INFO  Completed task_id=task1 with Success(Done!)
09:38:41.619 [ScalaTest-running-TaskManagerSpec][akka://TaskManagerSpec/user/$$k][TaskManager] DEBUG 0/0 tasks eligible. Waiting tasks: Set()
09:38:41.636 [][][Slf4jLogger] INFO  Slf4jLogger started
09:38:41.636 [pool-4-thread-6][EventStream(akka://ProcessExecutorSpec)][EventStream] DEBUG logger log1-Slf4jLogger started
09:38:41.637 [pool-4-thread-6][EventStream(akka://ProcessExecutorSpec)][EventStream] DEBUG Default Loggers started
09:38:41.652 [ProcessExecutorSpec-akka.actor.default-dispatcher-5][akka://ProcessExecutorSpec/user/$a][ProcessExecutor] INFO  started
09:38:41.664 [ProcessExecutorSpec-akka.actor.default-dispatcher-5][akka://ProcessExecutorSpec/user/$a][ProcessExecutor] INFO  starting process with cmd="/bin/cat" and batch_size=1
09:38:41.669 [ProcessExecutorSpec-akka.actor.default-dispatcher-5][akka://ProcessExecutorSpec/user/$a][ProcessExecutor] DEBUG closing input stream
09:38:41.672 [Thread-393][akka://ProcessExecutorSpec/user/$a][ProcessExecutor] DEBUG closing output stream
09:38:41.672 [ProcessExecutorSpec-akka.actor.default-dispatcher-5][akka://ProcessExecutorSpec/user/$a][ProcessExecutor] INFO  process exited with exit_value=0
09:38:41.674 [ProcessExecutorSpec-akka.actor.default-dispatcher-2][akka://ProcessExecutorSpec/user/$b][ProcessExecutor] INFO  started
09:38:41.685 [ProcessExecutorSpec-akka.actor.default-dispatcher-2][akka://ProcessExecutorSpec/user/$b][ProcessExecutor] INFO  starting process with cmd="/bin/cat" and batch_size=100
09:38:41.690 [ProcessExecutorSpec-akka.actor.default-dispatcher-2][akka://ProcessExecutorSpec/user/$b][ProcessExecutor] DEBUG closing input stream
09:38:41.693 [Thread-396][akka://ProcessExecutorSpec/user/$b][ProcessExecutor] DEBUG closing output stream
09:38:41.693 [ProcessExecutorSpec-akka.actor.default-dispatcher-2][akka://ProcessExecutorSpec/user/$b][ProcessExecutor] INFO  process exited with exit_value=0
09:38:41.694 [ProcessExecutorSpec-akka.actor.default-dispatcher-2][akka://ProcessExecutorSpec/user/$c][ProcessExecutor] INFO  started
09:38:41.694 [ProcessExecutorSpec-akka.actor.default-dispatcher-2][akka://ProcessExecutorSpec/user/$c][ProcessExecutor] INFO  starting process with cmd="/Users/jackywang/Desktop/341/project/deepdive/target/scala-2.10/test-classes/failing_extractor.py" and batch_size=100
09:38:41.702 [ProcessExecutorSpec-akka.actor.default-dispatcher-2][akka://ProcessExecutorSpec/user/$c][ProcessExecutor] DEBUG closing input stream
09:38:47.741 [Thread-399][akka://ProcessExecutorSpec/user/$c][ProcessExecutor] DEBUG closing output stream
09:38:47.741 [ProcessExecutorSpec-akka.actor.default-dispatcher-2][akka://ProcessExecutorSpec/user/$c][ProcessExecutor] INFO  process exited with exit_value=1
